{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Near AI","text":"<p>See the Near AI website for more information about how we will achieve Open Source and User-owned AGI..</p>"},{"location":"#warning-alpha-software","title":"\u26a0\ufe0f Warning: Alpha software","text":"<p>NearAI is alpha software. This means that it is not yet ready for production use. We are actively working on improving the software and would love your help.</p> <p>If you would like to help build our future, please see our contributing guide.</p>"},{"location":"#about","title":"About","text":"<p>The NearAI project is a toolkit to help build, measure, and deploy AI systems focused on agents.</p> <p>NearAI consists of:</p> <ol> <li>app.near.ai a place to share agents, environments, and datasets; powered by the NearAI API.</li> <li>A CLI tool to interact with the NearAI registry, download agents, run them in environments, and more.</li> <li>A library with access to the same tools as the CLI, but to be used programmatically.</li> </ol> <p>This intro is split into two parts:</p> <ol> <li>Web Usage Guide</li> <li>CLI Usage Guide</li> </ol>"},{"location":"#web-usage-guide","title":"Web Usage Guide","text":"<p>https://app.near.ai allows you to use NEAR AI Hub directly from your browser. It currently offers a subset of the features available from the full Hub API.</p> <p>Features:</p> <ul> <li>NEAR AI Login<ul> <li>Login with your NEAR account using your favourite wallet provider.</li> </ul> </li> <li>Inference using the provider of your choice<ul> <li>Chose between the best open source models.</li> </ul> </li> <li>Read the registry:<ul> <li>Datasets - https://app.near.ai/datasets</li> <li>Benchmarks - https://app.near.ai/benchmarks</li> <li>Models - https://app.near.ai/models</li> <li>Agents - https://app.near.ai/agents</li> </ul> </li> <li> <p>View and manage your NEAR AI access keys.</p> <ul> <li>https://app.near.ai/settings</li> </ul> </li> </ul> <p>Source code in: demo</p> <p>For the api specification see openapi.json</p>"},{"location":"#cli-usage-guide","title":"CLI Usage Guide","text":""},{"location":"#registry","title":"Registry","text":"<p>The registry is a place to store models, datasets, agents, and environments (more types to come). You can upload and download items from the registry using the <code>nearai registry</code> command.</p> <p>About the registry</p> <p>The registry is backed by an S3 bucket with metadata stored in a database.</p> <p>To upload an item to the registry, you need a directory containing a metadata.json file. The metadata.json file describes the item, and all the other files in the directory make up the item. For an agent that is one <code>agent.py</code> file, for a dataset it may be hundreds of files.</p> <p>The metadata_template command will create a template for you to fill in. <pre><code>nearai registry metadata_template &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> Fill in name, version, category and any other fields for which you have values. The current categories are: <code>model</code>, <code>dataset</code>, <code>agent</code>, <code>environment</code>.</p> <pre><code>{\n  \"category\": \"agent\",\n  \"description\": \"An example agent\",\n  \"tags\": [\n    \"python\"\n  ],\n  \"details\": {},\n  \"show_entry\": true,\n  \"name\": \"example-agent\",\n  \"version\": \"1\"\n}\n</code></pre> <p>Upload an element to the registry using:</p> <pre><code>nearai registry upload &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> <p>You can list elements in the registry using several filters:</p> <pre><code>nearai registry list  --namespace &lt;NAMESPACE&gt; \\\n                      --category &lt;CATEGORY&gt; \\\n                      --tags &lt;COMMA_SEPARTED_LIST_OF_TAGS&gt;\n                      --show_all\n</code></pre> <p>Check the item is available by listing all elements in the registry of that category:</p> <pre><code>nearai registry list --namespace near.ai --category agent\n</code></pre> <p>Show only items with the tag <code>quine</code> and <code>python</code>:</p> <pre><code>nearai registry list --tags quine,python\n</code></pre> <p>Download this element locally. To download refer to the item by //. Trying to download an item that was previously downloaded is a no-op. <pre><code>nearai registry download zavodil.near/hello-world-agent/1\n</code></pre> <p>Tip</p> <p>If you start downloading and item, and cancel the download midway, you should delete the folder at <code>~/.nearai/registry/</code> to trigger a new download.</p> <p>Update the metadata of an item with the registry update command <pre><code>nearai registry update &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> View info about an item with the registry info command <pre><code>nearai registry info &lt;ITEM_FULL_NAME&gt;\n</code></pre> <pre><code>nearai registry info zavodil.near/hello-world-agent/1\n</code></pre></p>"},{"location":"#agents","title":"Agents","text":"<p>See the Agents documentation and How to guide</p>"},{"location":"#benchmarking","title":"Benchmarking","text":"<p><code>nearai</code> includes a benchmarking tool to compare different agents and solvers on sets of reference evals (like <code>mpbb</code>).</p> Requirements for benchmarking with <code>nearai</code> <p>To create a benchmark, you need two things:</p> <pre><code>1. A dataset in your `nearai` dataset registry.\n2. A solver for the dataset implemented in the `nearai` library for said dataset.\n\nIf you have a dataset and a solver, you can run a benchmark.\n</code></pre> <p>To run a benchmark, you can use the <code>nearai benchmark</code> command. For example, to run the <code>mpbb</code> benchmark on the <code>llama-v3-70b-instruct</code>, you can use:</p> <pre><code>nearai benchmark run mbpp MBPPSolverStrategy \\\n    --model llama-v3-70b-instruct \\\n    --subset=train \\\n    --max_concurrent=1\n</code></pre>"},{"location":"#fine-tuning","title":"Fine tuning","text":"<p>We use <code>torchtune</code> for fine tuning models. The following command will start a fine tuning process using the <code>llama-3-8b-instruct</code> model and the <code>llama3</code> tokenizer.</p> <pre><code>poetry run python3 -m nearai finetune start \\\n    --model llama-3-8b-instruct \\\n    --format llama3-8b \\\n    --tokenizer tokenizers/llama-3 \\\n    --dataset &lt;your-dataset&gt; \\\n    --method nearai.finetune.text_completion.dataset \\\n    --column text \\\n    --split train \\\n    --num_procs 8\n</code></pre>"},{"location":"#submit-an-experiment","title":"Submit an experiment","text":"<p>To submit a new experiment run:</p> <pre><code>nearai submit --command &lt;COMMAND&gt; --name &lt;EXPERIMENT_NAME&gt; [--nodes &lt;NUMBER_OF_NODES&gt;] [--cluster &lt;CLUSTER&gt;]\n</code></pre> <p>This will submit a new experiment. The command must be executed from a folder that is a git repository (public github repositories, and private github repositories on the same organization as nearai are supported). The current commit will be used for running the command so make sure it is already available online. The diff with respect to the current commit will be applied remotely (new files are not included in the diff).</p> <p>On each node the environment variable <code>ASSIGNED_SUPERVISORS</code> will be available with a comma separated list of supervisors that are running the experiment. The current supervisor can be accessed via <code>nearai.CONFIG.supervisor_id</code>. See examples/prepare_data.py for an example.</p>"},{"location":"agents/","title":"Agents","text":"<p>Agents are programs of varying complexity that can combine capabilities from across NearAI:  authentication, inference, data stores, tools, apis, smart contract calls, reputation, compliance, proofs, and more.</p> <p>Agents run in response to messages, usually from a user or another agent. Messages can also be sent to an agent  from other systems such as a scheduler or indexer.</p>"},{"location":"agents/#how-to-build-and-run-a-python-agent-on-nearai","title":"How to build and run a python agent on NearAI","text":"<ul> <li>Install the NearAI CLI.</li> <li>Create a new folder for your agent; we recommend placing it inside your local registry <code>mkdir -p ~/.nearai/registry/example_agent</code>. </li> <li>Create a metadata.json file for your agent <code>nearai registry metadata_template ~/.nearai/registry/example_agent</code> and edit it.</li> <li>Create an <code>agent.py</code> file in that folder.</li> <li>Write your agent, in agent.py, using the environment API described below.</li> <li>Use your agent locally using the cli and passing it a folder to write output to. The execution folder is optional; by default, the initial agent's folder may be used instead.</li> <li>If you use a folder other than the local registry, provide the full path to the agent instead of just the agent name. <pre><code>nearai agent interactive AGENT [EXECUTION_FOLDER] --local\n</code></pre> <pre><code>nearai agent interactive example_agent /tmp/example_agent_run_1 --local\n</code></pre> <pre><code>nearai agent interactive example_agent --local\n</code></pre></li> </ul>"},{"location":"agents/#agent-operation-and-features","title":"Agent Operation and Features:","text":"<ul> <li><code>interactive</code> mode runs the agent in an infinite loop until it is forcibly exited with a code, stopped by the user with \"Ctrl+C,\" or terminated by typing \"exit\" in the chat.</li> <li>The agent can save temporary files to track the progress of a task from the user in case the dialogue execution is interrupted. By default, the entire message history is stored in a file named <code>chat.txt</code>. The agent can add messages there by using <code>env.add_message()</code>. Learn more about the environment API.</li> <li>During its operation, the agent creates a file named <code>.next_agent</code>, which stores the role of the next participant expected in the dialogue (either <code>user</code> or <code>agent</code>) during the next iteration of the loop. The agent can control this value using <code>env.set_next_actor()</code>.</li> <li>The agent can use local imports from the home folder or its subfolders. It is executed from a temporary folder within a temporary environment.</li> </ul>"},{"location":"agents/#example-agentpy","title":"Example agent.py","text":"<pre><code># In local interactive mode, the first user input is collected before the agent runs.\nprompt = {\"role\": \"system\", \"content\": \"You are a travel agent that helps users plan trips.\"}\nresult = env.completion('llama-v3-70b-instruct', [prompt] + env.list_messages())\nenv.add_message(\"agent\", result)\nenv.request_user_input()\n</code></pre>"},{"location":"agents/#running-an-existing-agent-from-the-registry","title":"Running an existing agent from the registry","text":"<p>List all agents <pre><code>nearai registry list --category agent\n</code></pre></p> <p>Download an agent by name <pre><code>nearai registry download flatirons.near/xela-agent/5\n</code></pre></p> <p>The <code>--force</code> flag allows you to overwrite the local agent with the version from the registry.</p> <p>\u26a0\ufe0f Warning: Review the agent code before running it!</p>"},{"location":"agents/#running-an-agent-interactively","title":"Running an agent interactively","text":"<p>Agents can be run interactively. The environment_path should be a folder where the agent chat record (chat.txt) and  other files can be written, usually <code>~/tmp/test-agents/&lt;AGENT_NAME&gt;-run-X</code>.</p> <ul> <li>command <code>nearai agent interactive AGENT ENVIRONMENT_PATH</code></li> <li>example  <pre><code>nearai agent interactive flatirons.near/xela-agent/5 /tmp/test-agents/xela-agent-run-1\n</code></pre></li> </ul>"},{"location":"agents/#running-an-agent-as-a-task","title":"Running an agent as a task","text":"<p>To run without user interaction pass the task input to the task</p> <ul> <li>command <code>nearai agent task &lt;AGENT&gt; &lt;INPUT&gt; &lt;ENVIRONMENT_PATH&gt;</code></li> <li>example  <pre><code>nearai agent task flatirons.near/xela-agent/5 \"Build a command line chess engine\" ~/tmp/test-agents/xela-agent/chess-engine\n</code></pre></li> </ul>"},{"location":"agents/#the-environment-api","title":"The Environment API","text":"<p>Your agent will receive an <code>env</code> object that has the following methods:</p> <ul> <li><code>request_user_input</code>: tell the agent that it is the user's turn, stop iterating.</li> <li> <p><code>completion</code>: request inference completions from a provider and model. The model format can be either <code>PROVIDER::MODEL</code> or simply <code>MODEL</code>. By default the provider is <code>Fireworks</code> and the model is <code>llama-v3-70b-instruct</code>.</p> </li> <li> <p><code>list_messages</code> - returns the list of messages in the conversation.  You have full control to add and remove messages from this list.</p> </li> <li><code>add_message</code> - adds a message to the conversation. Arguments are role and content.    <pre><code>env.add_message(\"user\", \"Hello, I would like to travel to Paris\")\n</code></pre>    Normal roles are: <ul> <li><code>system</code>: usually your starting prompt</li> <li><code>agent</code>: messages from the agent (i.e. llm responses, programmatic responses)</li> <li><code>user</code>: messages from the user</li> </ul> </li> </ul>"},{"location":"agents/#additional-environment-tools","title":"Additional environment tools","text":"<p>There are several variations for completions:</p> <ul> <li><code>completions</code>: returns the full llm response for more control</li> <li><code>completion_and_run_tools</code>: Allows tools to be passed and processes any returned tool_calls by running the tool</li> <li><code>completions_and_run_tools</code>: Both tool calls and returns the full llm response.</li> </ul> <p>For working with files and running commands the following functions are also available on <code>env</code>. You may call these directly or use them through the tool_registry and passing them to a completions method.</p> <ul> <li><code>list_terminal_commands</code> - list the history of terminal commands</li> <li><code>list_files</code> - list the files in the current directory</li> <li><code>get_path</code> - get the path of the current directory</li> <li><code>read_file</code> - read a file</li> <li><code>write_file</code> - write to a file</li> <li><code>exec_command</code> - execute a terminal command</li> </ul>"},{"location":"agents/#tool-registry","title":"Tool registry","text":"<ul> <li><code>get_tool_registry</code>: returns the tool registry, a dictionary of tools that can be called by the agent. By default it is populated with the tools listed above for working with files and commands plus <code>request_user_input</code>. To register a function as a new tool, call <code>register_tool</code> on the tool registry, passing it your function.  <pre><code>def my_tool():\n    \"\"\"A simple tool that returns a string. This docstring helps the LLM know when to call the tool.\"\"\"\n    return \"Hello from my tool\"\n\nenv.get_tool_registry().register_tool(my_tool)\n\nresponse = env.completions_and_run_tools(\"llama-v3p1-405b-instruct\", messages, tools=get_tool_registry().get_all_tools())\n</code></pre></li> </ul>"},{"location":"agents/#uploading-an-agent","title":"Uploading an agent","text":"<ul> <li>You need a folder with an <code>agent.py</code> file in it, <code>~/.nearai/registry/example_agent</code> in this example. </li> <li>The agent may consist of additional files in the folder.</li> </ul> <p>\u26a0\ufe0f Warning: All files in this folder will be uploaded to the registry!  * Add a metadata file <code>nearai registry metadata_template ~/.nearai/registry/example_agent</code>  * Edit the metadata file to include the agent details <pre><code>{\n  \"category\": \"agent\",\n  \"description\": \"An example agent that gives travel recommendations\",\n  \"tags\": [\n    \"python\",\n    \"travel\"\n  ],\n  \"details\": {},\n  \"show_entry\": true,\n  \"name\": \"example-travel-agent\",\n  \"version\": \"5\"\n}\n</code></pre></p> <ul> <li>You must be logged in with NEAR to upload, <code>nearai login</code></li> <li>Upload the agent <code>nearai registry upload ~/.nearai/registry/example_agent</code></li> </ul> <p>\u26a0\ufe0f You can't remove or overwrite a file once it's uploaded, but you can hide the entire agent by setting the <code>\"show_entry\": false</code> field.</p>"},{"location":"agents/#running-an-agent-remotely-through-the-cli","title":"Running an agent remotely through the CLI","text":"<p>Agents can be run through the CLI using the <code>nearai agent run_remote</code> command. A new message can be passed with the new_message argument. A starting environment (state) can be passed with the environment_id argument. <pre><code>  nearai agent run_remote flatirons.near/example-travel-agent/1 \\\n  new_message=\"I would like to travel to Paris\" \\\n  environment_id=\"flatirons.near/environment_run_example-travel-agent_541869e6753c41538c87cb6f681c6932/0\"\"\n ```\n\n## Running an agent through the API\nAgents can be run through the `/agent/runs` endpoint. You will need to pass a signed message to authenticate.\n\n```shell\ncurl \"https://api.near.ai/v1/agent/runs\" \\\n      -X POST \\\n      --header 'Content-Type: application/json' \\\n      --header 'Authorization: Bearer {\"account_id\":\"flatirons.near\",\"public_key\":\"ed25519:F5DeKFoyF1CQ6wG6jYaXxwQeoksgi8a677JkniDBGBTB\",\"signature\":\"kfiH7AStKrBaMXzwpE50yQ2TRTxksID9tNVEdazxtegEu6rwH6x575smcAJPAUfTtlT2l7xwXtapQkxd+vFUAg==\",\"callback_url\":\"http://localhost:3000/\",\"message\":\"Welcome to NEAR AI Hub!\",\"recipient\":\"ai.near\",\"nonce\":\"00000000000000000005722050769950\"}' \\\n-d @- &lt;&lt;'EOF'\n  {\n    \"agent_id\": \"flatirons.near/xela-agent/5\",\n    \"new_message\":\"Build a backgammon game\", \n    \"max_iterations\": \"2\"\n  }\nEOF\n</code></pre></p>"},{"location":"agents/#signed-messages","title":"Signed messages","text":"<p>NearAI authentication is through a Signed Message: a payload signed by a Near Account private key. (How to Login with NEAR)</p> <p>If you need one for manual testing, you can <code>nearai login</code> then copy the auth section from your <code>~/.nearai/config.json</code>.</p> <p>To add signed message login to an application, see the code in hub demo near.tsx.</p>"},{"location":"agents/#saving-and-loading-environment-runs","title":"Saving and loading environment runs","text":"<p>When you are logged in, by default, each environment run is saved to the registry. You can disable this by adding the cli flag <code>--record_run=False</code>.</p> <p>An environment run can be loaded by using the <code>--load_env</code> flag and passing it a registry identifier <code>--load_env=near.ai/environment_run_test_6a8393b51d4141c7846247bdf4086038/1.0.0</code>.</p> <p>To list environment identifiers use the command <code>nearai registry list --tags=environment</code>.</p> <p>A run can be named by passing a name to the record_run flag <code>--record_run=\"my special run\"</code>.</p> <p>Environment runs can be loaded by passing the name of a previous run to the --load_env flag like <code>--load_env=\"my special run\"</code>.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nearai.cli.CLI","title":"<code>nearai.cli.CLI</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class CLI:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.registry = RegistryCli()\n        self.login = LoginCLI()\n        self.hub = HubCLI()\n\n        self.config = ConfigCli()\n        self.benchmark = BenchmarkCli()\n        self.agent = AgentCli()\n        self.finetune = FinetuneCli()\n        self.tensorboard = TensorboardCli()\n        self.vllm = VllmCli()\n\n    def location(self) -&gt; None:  # noqa: D102\n        \"\"\"Show location where nearai is installed.\"\"\"\n        from nearai import cli_path\n\n        print(cli_path())\n\n    def version(self):\n        \"\"\"Show nearai version.\"\"\"\n        print(importlib.metadata.version(\"nearai\"))\n</code></pre>"},{"location":"api/#nearai.cli.CLI.location","title":"<code>location()</code>","text":"<p>Show location where nearai is installed.</p> Source code in <code>nearai/cli.py</code> <pre><code>def location(self) -&gt; None:  # noqa: D102\n    \"\"\"Show location where nearai is installed.\"\"\"\n    from nearai import cli_path\n\n    print(cli_path())\n</code></pre>"},{"location":"api/#nearai.cli.CLI.version","title":"<code>version()</code>","text":"<p>Show nearai version.</p> Source code in <code>nearai/cli.py</code> <pre><code>def version(self):\n    \"\"\"Show nearai version.\"\"\"\n    print(importlib.metadata.version(\"nearai\"))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli","title":"<code>nearai.cli.RegistryCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class RegistryCli:\n    def info(self, entry: str) -&gt; None:\n        \"\"\"Show information about an item.\"\"\"\n        entry_location = parse_location(entry)\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            print(f\"Entry {entry} not found.\")\n            return\n\n        print(metadata.model_dump_json(indent=2))\n\n    def metadata_template(self, local_path: str = \".\"):\n        \"\"\"Create a metadata template.\"\"\"\n        path = Path(local_path)\n\n        metadata_path = path / \"metadata.json\"\n\n        with open(metadata_path, \"w\") as f:\n            json.dump(\n                {\n                    \"name\": \"foobar\",\n                    \"version\": \"0.0.1\",\n                    \"description\": \"Template metadata\",\n                    \"category\": \"model\",\n                    \"tags\": [\"foo\", \"bar\"],\n                    \"details\": {},\n                    \"show_entry\": True,\n                },\n                f,\n                indent=2,\n            )\n\n    def list(\n        self,\n        namespace: str = \"\",\n        category: str = \"\",\n        tags: str = \"\",\n        total: int = 32,\n        show_all: bool = False,\n    ) -&gt; None:\n        \"\"\"List available items.\"\"\"\n        # Make sure tags is a comma-separated list of tags\n        tags_l = parse_tags(tags)\n        tags = \",\".join(tags_l)\n\n        entries = registry.list(namespace, category, tags, total, show_all)\n\n        for entry in entries:\n            print(entry)\n\n    def update(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Update metadata of a registry item.\"\"\"\n        path = Path(local_path)\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n        check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.account_id\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=metadata.pop(\"name\"),\n                version=metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(metadata)\n        result = registry.update(entry_location, entry_metadata)\n        print(json.dumps(result, indent=2))\n\n    def upload(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Upload item to the registry.\"\"\"\n        registry.upload(Path(local_path), show_progress=True)\n\n    def download(self, entry_location: str, force: bool = False) -&gt; None:\n        \"\"\"Download item.\"\"\"\n        registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.download","title":"<code>download(entry_location, force=False)</code>","text":"<p>Download item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def download(self, entry_location: str, force: bool = False) -&gt; None:\n    \"\"\"Download item.\"\"\"\n    registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.info","title":"<code>info(entry)</code>","text":"<p>Show information about an item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def info(self, entry: str) -&gt; None:\n    \"\"\"Show information about an item.\"\"\"\n    entry_location = parse_location(entry)\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        print(f\"Entry {entry} not found.\")\n        return\n\n    print(metadata.model_dump_json(indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.list","title":"<code>list(namespace='', category='', tags='', total=32, show_all=False)</code>","text":"<p>List available items.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    namespace: str = \"\",\n    category: str = \"\",\n    tags: str = \"\",\n    total: int = 32,\n    show_all: bool = False,\n) -&gt; None:\n    \"\"\"List available items.\"\"\"\n    # Make sure tags is a comma-separated list of tags\n    tags_l = parse_tags(tags)\n    tags = \",\".join(tags_l)\n\n    entries = registry.list(namespace, category, tags, total, show_all)\n\n    for entry in entries:\n        print(entry)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.metadata_template","title":"<code>metadata_template(local_path='.')</code>","text":"<p>Create a metadata template.</p> Source code in <code>nearai/cli.py</code> <pre><code>def metadata_template(self, local_path: str = \".\"):\n    \"\"\"Create a metadata template.\"\"\"\n    path = Path(local_path)\n\n    metadata_path = path / \"metadata.json\"\n\n    with open(metadata_path, \"w\") as f:\n        json.dump(\n            {\n                \"name\": \"foobar\",\n                \"version\": \"0.0.1\",\n                \"description\": \"Template metadata\",\n                \"category\": \"model\",\n                \"tags\": [\"foo\", \"bar\"],\n                \"details\": {},\n                \"show_entry\": True,\n            },\n            f,\n            indent=2,\n        )\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.update","title":"<code>update(local_path='.')</code>","text":"<p>Update metadata of a registry item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def update(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Update metadata of a registry item.\"\"\"\n    path = Path(local_path)\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n    check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.account_id\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=metadata.pop(\"name\"),\n            version=metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(metadata)\n    result = registry.update(entry_location, entry_metadata)\n    print(json.dumps(result, indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.upload","title":"<code>upload(local_path='.')</code>","text":"<p>Upload item to the registry.</p> Source code in <code>nearai/cli.py</code> <pre><code>def upload(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Upload item to the registry.\"\"\"\n    registry.upload(Path(local_path), show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli","title":"<code>nearai.cli.ConfigCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class ConfigCli:\n    def set(self, key: str, value: str, local: bool = False) -&gt; None:\n        \"\"\"Add key-value pair to the config file.\"\"\"\n        update_config(key, value, local)\n\n    def get(self, key: str) -&gt; None:\n        \"\"\"Get value of a key in the config file.\"\"\"\n        print(CONFIG.get(key))\n\n    def show(self) -&gt; None:  # noqa: D102\n        for key, value in asdict(CONFIG).items():\n            print(f\"{key}: {value}\")\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.get","title":"<code>get(key)</code>","text":"<p>Get value of a key in the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def get(self, key: str) -&gt; None:\n    \"\"\"Get value of a key in the config file.\"\"\"\n    print(CONFIG.get(key))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.set","title":"<code>set(key, value, local=False)</code>","text":"<p>Add key-value pair to the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def set(self, key: str, value: str, local: bool = False) -&gt; None:\n    \"\"\"Add key-value pair to the config file.\"\"\"\n    update_config(key, value, local)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli","title":"<code>nearai.cli.BenchmarkCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class BenchmarkCli:\n    def run(\n        self,\n        dataset: str,\n        solver_strategy: str,\n        max_concurrent: int = -1,\n        force: bool = False,\n        subset: Optional[str] = None,\n        **solver_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Run benchmark on a dataset with a solver strategy.\n\n        It will cache the results in the database and subsequent runs will pull the results from the cache.\n        If force is set to True, it will run the benchmark again and update the cache.\n        \"\"\"\n        from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n        from nearai.dataset import load_dataset\n        from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n        # TODO(db-api): Expose an interface to cache the result of the benchmarks\n        # benchmark_id = db.get_benchmark_id(dataset, solver_strategy, force, subset=subset, **solver_kwargs)\n        benchmark_id = -1\n\n        name, subset, dataset = dataset, subset, load_dataset(dataset)\n\n        solver_strategy_: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n        assert (\n            solver_strategy\n        ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n        solver_strategy_obj: SolverStrategy = solver_strategy_(dataset_ref=dataset, **solver_kwargs)  # type: ignore\n        assert (\n            name in solver_strategy_obj.compatible_datasets()\n        ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n        be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n        cpu_count = os.cpu_count()\n        max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n        be.run(max_concurrent=max_concurrent)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.run","title":"<code>run(dataset, solver_strategy, max_concurrent=-1, force=False, subset=None, **solver_kwargs)</code>","text":"<p>Run benchmark on a dataset with a solver strategy.</p> <p>It will cache the results in the database and subsequent runs will pull the results from the cache. If force is set to True, it will run the benchmark again and update the cache.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run(\n    self,\n    dataset: str,\n    solver_strategy: str,\n    max_concurrent: int = -1,\n    force: bool = False,\n    subset: Optional[str] = None,\n    **solver_kwargs: Any,\n) -&gt; None:\n    \"\"\"Run benchmark on a dataset with a solver strategy.\n\n    It will cache the results in the database and subsequent runs will pull the results from the cache.\n    If force is set to True, it will run the benchmark again and update the cache.\n    \"\"\"\n    from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n    from nearai.dataset import load_dataset\n    from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n    # TODO(db-api): Expose an interface to cache the result of the benchmarks\n    # benchmark_id = db.get_benchmark_id(dataset, solver_strategy, force, subset=subset, **solver_kwargs)\n    benchmark_id = -1\n\n    name, subset, dataset = dataset, subset, load_dataset(dataset)\n\n    solver_strategy_: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n    assert (\n        solver_strategy\n    ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n    solver_strategy_obj: SolverStrategy = solver_strategy_(dataset_ref=dataset, **solver_kwargs)  # type: ignore\n    assert (\n        name in solver_strategy_obj.compatible_datasets()\n    ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n    be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n    cpu_count = os.cpu_count()\n    max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n    be.run(max_concurrent=max_concurrent)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli","title":"<code>nearai.cli.AgentCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class AgentCli:\n    def inspect(self, path: str) -&gt; None:\n        \"\"\"Inspect environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.inspect()\n\n    def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n        \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.save_folder(name)\n\n    def save_from_history(self, name: Optional[str] = None) -&gt; None:\n        \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.\n\n        This command:\n        1. Finds agent task runs (must contain non-empty chat.txt)\n        2. Writes start_command.log files\n        3. Saves to registry\n\n        Only 'interactive' is supported.\n        Assumes format:\n        ' &lt;line_number&gt;  &lt;program_name&gt; agent interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n        Run:\n        $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00\n        \"\"\"  # noqa: E501\n        from nearai.environment import Environment\n\n        env = Environment(\"/\", [], CONFIG, create_files=False)\n        # Read from stdin (piped input)\n        lines = sys.stdin.readlines()\n        env.save_from_history(lines, name)\n\n    def interactive(\n        self, agents: str, path: Optional[str] = \"\", record_run: str = \"true\", load_env: str = \"\", local: bool = False\n    ) -&gt; None:\n        \"\"\"Runs agent interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n        if not path:\n            if len(_agents) == 1:\n                path = _agents[0].path\n            else:\n                raise ValueError(\"Local path is required when running multiple agents\")\n        env = Environment(path, _agents, CONFIG)\n        env.run_interactive(record_run, load_env)\n\n    def task(\n        self,\n        agents: str,\n        task: str,\n        path: str,\n        max_iterations: int = 10,\n        record_run: str = \"true\",\n        load_env: str = \"\",\n    ) -&gt; None:\n        \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent) for agent in agents.split(\",\")]\n        env = Environment(path, _agents, CONFIG)\n        env.run_task(task, record_run, load_env, max_iterations)\n\n    def run_remote(\n        self,\n        agents: str,\n        new_message: str = \"\",\n        environment_id: str = \"\",\n        provider: str = \"aws_lambda\",\n        params: object = None,\n    ) -&gt; None:\n        \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n        if not CONFIG.auth:\n            print(\"Please login with `nearai login`\")\n            return\n        if provider != \"aws_lambda\":\n            print(f\"Provider {provider} is not supported.\")\n            return\n        if not params:\n            params = {\"max_iterations\": 2}\n        wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n        try:\n            new_environment = wrapper.invoke_function(\n                \"agent-runner-docker\",\n                {\n                    \"agents\": agents,\n                    \"environment_id\": environment_id,\n                    \"auth\": CONFIG.auth.model_dump(),\n                    \"new_message\": new_message,\n                    \"params\": params,\n                },\n            )\n            print(f\"Agent run finished. New environment is {new_environment}\")\n        except Exception as e:\n            print(f\"Error running agent remotely: {e}\")\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.inspect","title":"<code>inspect(path)</code>","text":"<p>Inspect environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def inspect(self, path: str) -&gt; None:\n    \"\"\"Inspect environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.inspect()\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.interactive","title":"<code>interactive(agents, path='', record_run='true', load_env='', local=False)</code>","text":"<p>Runs agent interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def interactive(\n    self, agents: str, path: Optional[str] = \"\", record_run: str = \"true\", load_env: str = \"\", local: bool = False\n) -&gt; None:\n    \"\"\"Runs agent interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n    if not path:\n        if len(_agents) == 1:\n            path = _agents[0].path\n        else:\n            raise ValueError(\"Local path is required when running multiple agents\")\n    env = Environment(path, _agents, CONFIG)\n    env.run_interactive(record_run, load_env)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.run_remote","title":"<code>run_remote(agents, new_message='', environment_id='', provider='aws_lambda', params=None)</code>","text":"<p>Invoke a Container based AWS lambda function to run agents on a given environment.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run_remote(\n    self,\n    agents: str,\n    new_message: str = \"\",\n    environment_id: str = \"\",\n    provider: str = \"aws_lambda\",\n    params: object = None,\n) -&gt; None:\n    \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n    if not CONFIG.auth:\n        print(\"Please login with `nearai login`\")\n        return\n    if provider != \"aws_lambda\":\n        print(f\"Provider {provider} is not supported.\")\n        return\n    if not params:\n        params = {\"max_iterations\": 2}\n    wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n    try:\n        new_environment = wrapper.invoke_function(\n            \"agent-runner-docker\",\n            {\n                \"agents\": agents,\n                \"environment_id\": environment_id,\n                \"auth\": CONFIG.auth.model_dump(),\n                \"new_message\": new_message,\n                \"params\": params,\n            },\n        )\n        print(f\"Agent run finished. New environment is {new_environment}\")\n    except Exception as e:\n        print(f\"Error running agent remotely: {e}\")\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.save_folder","title":"<code>save_folder(path, name=None)</code>","text":"<p>Saves all subfolders with agent task runs (must contain non-empty chat.txt).</p> Source code in <code>nearai/cli.py</code> <pre><code>def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n    \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.save_folder(name)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.save_from_history","title":"<code>save_from_history(name=None)</code>","text":"<p>Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.</p> <p>This command: 1. Finds agent task runs (must contain non-empty chat.txt) 2. Writes start_command.log files 3. Saves to registry</p> <p>Only 'interactive' is supported. Assumes format: '   agent interactive  ' Run: $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00 Source code in <code>nearai/cli.py</code> <pre><code>def save_from_history(self, name: Optional[str] = None) -&gt; None:\n    \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.\n\n    This command:\n    1. Finds agent task runs (must contain non-empty chat.txt)\n    2. Writes start_command.log files\n    3. Saves to registry\n\n    Only 'interactive' is supported.\n    Assumes format:\n    ' &lt;line_number&gt;  &lt;program_name&gt; agent interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n    Run:\n    $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00\n    \"\"\"  # noqa: E501\n    from nearai.environment import Environment\n\n    env = Environment(\"/\", [], CONFIG, create_files=False)\n    # Read from stdin (piped input)\n    lines = sys.stdin.readlines()\n    env.save_from_history(lines, name)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.task","title":"<code>task(agents, task, path, max_iterations=10, record_run='true', load_env='')</code>","text":"<p>Runs agent non interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def task(\n    self,\n    agents: str,\n    task: str,\n    path: str,\n    max_iterations: int = 10,\n    record_run: str = \"true\",\n    load_env: str = \"\",\n) -&gt; None:\n    \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent) for agent in agents.split(\",\")]\n    env = Environment(path, _agents, CONFIG)\n    env.run_task(task, record_run, load_env, max_iterations)\n</code></pre>"},{"location":"api/#nearai.cli.VllmCli","title":"<code>nearai.cli.VllmCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class VllmCli:\n    def run(self, *args: Any, **kwargs: Any) -&gt; None:  # noqa: D102\n        original_argv = sys.argv.copy()\n        sys.argv = [\n            sys.argv[0],\n        ]\n        for key, value in kwargs.items():\n            sys.argv.extend([f\"--{key.replace('_', '-')}\", str(value)])\n        print(sys.argv)\n\n        try:\n            runpy.run_module(\"vllm.entrypoints.openai.api_server\", run_name=\"__main__\", alter_sys=True)\n        finally:\n            sys.argv = original_argv\n</code></pre>"},{"location":"api/#nearai.tensorboard_feed.TensorboardCli","title":"<code>nearai.tensorboard_feed.TensorboardCli</code>","text":"Source code in <code>nearai/tensorboard_feed.py</code> <pre><code>class TensorboardCli:\n    def start(self, logdir: str, limit: int = 100, timeout: int = 1) -&gt; None:  # noqa: D102\n        import tensorboardX\n\n        experiments: Dict[str, tensorboardX.SummaryWriter] = {}\n\n        logdir_path = Path(logdir)\n        logdir_path.mkdir(parents=True, exist_ok=True)\n        next_id_path = logdir_path / \".next_id\"\n\n        if not next_id_path.exists():\n            next_id_path.write_text(\"0\")\n\n        while True:\n            next_id = int(next_id_path.read_text())\n            result = get_logs(\"tensorboard\", next_id, limit)\n\n            if not result:\n                time.sleep(timeout)\n                continue\n\n            for row in result:\n                when = row.time.timestamp()\n                content = json.loads(row.content)\n\n                experiment_id = content.pop(\"experiment_id\", None)\n                step = content.pop(\"step\", None)\n\n                if experiment_id is None or step is None:\n                    continue\n\n                if experiment_id not in experiments:\n                    experiments[experiment_id] = tensorboardX.SummaryWriter(logdir_path / experiment_id)\n\n                writer = experiments[experiment_id]\n\n                for key, value in content.items():\n                    writer.add_scalar(key, value, step, walltime=when)\n\n                next_id = max(next_id, row.id + 1)\n\n            new_num_logs = len(result)\n            print(f\"Downloaded {new_num_logs} new logs\")\n            next_id_path.write_text(str(next_id))\n</code></pre>"},{"location":"api/#nearai.agent.Agent","title":"<code>nearai.agent.Agent</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/agent.py</code> <pre><code>class Agent(object):\n    def __init__(self, path: str):  # noqa: D107\n        self.name: str = \"\"\n        self.version: str = \"\"\n\n        self.path = path\n        self.load_agent_metadata()\n\n        temp_dir = os.path.join(tempfile.gettempdir(), str(int(time.time())))\n\n        # Copy all agent files including subfolders\n        shutil.copytree(path, temp_dir, dirs_exist_ok=True)\n\n        self.temp_dir = temp_dir\n\n    def load_agent_metadata(self) -&gt; None:\n        \"\"\"Load agent details from metadata.json.\"\"\"\n        metadata_path = os.path.join(self.path, \"metadata.json\")\n        check_metadata(Path(metadata_path))\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n            try:\n                self.name = metadata[\"name\"]\n                self.version = metadata[\"version\"]\n            except KeyError as e:\n                raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n        if not self.version or not self.name:\n            raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n\n    def run(self, env: Any, task: Optional[str] = None) -&gt; None:  # noqa: D102\n        context = {\"env\": env, \"agent\": self, \"task\": task}\n\n        original_cwd = os.getcwd()\n        try:\n            os.chdir(self.temp_dir)\n            sys.path.insert(0, self.temp_dir)\n            runpy.run_path(AGENT_FILENAME, init_globals=context, run_name=\"__main__\")\n        finally:\n            os.chdir(original_cwd)\n            sys.path.pop(0)\n</code></pre>"},{"location":"api/#nearai.agent.Agent.load_agent_metadata","title":"<code>load_agent_metadata()</code>","text":"<p>Load agent details from metadata.json.</p> Source code in <code>nearai/agent.py</code> <pre><code>def load_agent_metadata(self) -&gt; None:\n    \"\"\"Load agent details from metadata.json.\"\"\"\n    metadata_path = os.path.join(self.path, \"metadata.json\")\n    check_metadata(Path(metadata_path))\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n        try:\n            self.name = metadata[\"name\"]\n            self.version = metadata[\"version\"]\n        except KeyError as e:\n            raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n    if not self.version or not self.name:\n        raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n</code></pre>"},{"location":"api/#nearai.benchmark.DatasetInfo","title":"<code>nearai.benchmark.DatasetInfo</code>  <code>dataclass</code>","text":"Source code in <code>nearai/benchmark.py</code> <pre><code>@dataclass\nclass DatasetInfo:\n    name: str\n    subset: Optional[str]\n    dataset: Union[Dataset, DatasetDict]\n\n    def get_dataset(self) -&gt; Dataset:  # noqa: D102\n        if isinstance(self.dataset, DatasetDict):\n            assert self.subset is not None, f\"Subset must be: {', '.join(self.dataset.keys())}\"\n            return self.dataset[self.subset]\n        elif isinstance(self.dataset, Dataset):\n            return self.dataset\n        else:\n            raise ValueError(f\"Expected a Dataset or DatasetDict, got {type(self.dataset)}\")\n</code></pre>"},{"location":"api/#nearai.benchmark.BenchmarkExecutor","title":"<code>nearai.benchmark.BenchmarkExecutor</code>","text":"Source code in <code>nearai/benchmark.py</code> <pre><code>class BenchmarkExecutor:\n    def __init__(self, dataset_info: DatasetInfo, solver_strategy: SolverStrategy, benchmark_id: int):  # noqa: D107\n        self.dataset_info = dataset_info\n        self.solver_strategy = solver_strategy\n        self.benchmark_id = benchmark_id\n\n    def run(self, progress: bool = True, max_concurrent: int = 32) -&gt; None:  # noqa: D102\n        dataset = self.dataset_info.get_dataset()\n\n        # TODO(db-api): Fetch the cache from the API\n        # cache = db.get_benchmark_status(self.benchmark_id)\n        cache: Dict[int, bool] = {}\n\n        correct = 0\n        remaining = len(dataset)\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            task_ctor = partial(\n                solve_task, benchmark_id=self.benchmark_id, cache=cache, solve_fn=self.solver_strategy.solve\n            )\n            tasks = iter(executor.submit(task_ctor, index=index, datum=datum) for index, datum in enumerate(dataset))\n\n            total = len(dataset)\n            bar = tqdm(total=total, disable=not progress)\n            futures = list(islice(tasks, max_concurrent))\n            while futures:\n                completed, ongoing_futures = concurrent.futures.wait(\n                    futures, return_when=concurrent.futures.FIRST_COMPLETED\n                )\n                futures = list(ongoing_futures)\n                for completed_future in completed:\n                    bar.update(1)\n                    remaining -= 1\n\n                    result = completed_future.result()\n                    if result:\n                        correct += 1\n                    bar.set_description(\n                        f\"Correct/Seen - {correct}/{total - remaining} - {correct/(total - remaining):.2%}\"\n                    )\n\n                    try:\n                        next_task = next(tasks)\n                        futures.append(next_task)\n                    except StopIteration:\n                        continue\n\n        print(f\"Final score: {correct}/{total} - {correct/total:.2%}\")\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter","title":"<code>nearai.completion.InferenceRouter</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/completion.py</code> <pre><code>class InferenceRouter(object):\n    def __init__(self, config: Config) -&gt; None:  # noqa: D107\n        self._config = config\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n        self._endpoint: Any\n\n    def completions(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        stream: bool = False,\n        temperature: Optional[float] = None,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Takes a model `provider:model_name` and a list of messages and returns all completions.\"\"\"\n        if self._config.nearai_hub is None:\n            raise ValueError(\"Missing NearAI Hub config\")\n        provider, model = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n        auth = self._config.auth\n        bearer_data = {\n            key: getattr(auth, key)\n            for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n        }\n        auth_bearer_token = json.dumps(bearer_data)\n\n        self._endpoint = lambda model, messages, stream, temperature, **kwargs: litellm_completion(\n            model,\n            messages,\n            stream=stream,\n            custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n            input_cost_per_token=0,\n            output_cost_per_token=0,\n            temperature=temperature,\n            base_url=self._config.nearai_hub.base_url,\n            provider=provider,\n            api_key=auth_bearer_token,\n            **kwargs,\n        )\n\n        result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n            model=model, messages=messages, stream=stream, temperature=temperature, **kwargs\n        )\n        return result\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter.completions","title":"<code>completions(model, messages, stream=False, temperature=None, **kwargs)</code>","text":"<p>Takes a model <code>provider:model_name</code> and a list of messages and returns all completions.</p> Source code in <code>nearai/completion.py</code> <pre><code>def completions(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    stream: bool = False,\n    temperature: Optional[float] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Takes a model `provider:model_name` and a list of messages and returns all completions.\"\"\"\n    if self._config.nearai_hub is None:\n        raise ValueError(\"Missing NearAI Hub config\")\n    provider, model = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n    auth = self._config.auth\n    bearer_data = {\n        key: getattr(auth, key)\n        for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n    }\n    auth_bearer_token = json.dumps(bearer_data)\n\n    self._endpoint = lambda model, messages, stream, temperature, **kwargs: litellm_completion(\n        model,\n        messages,\n        stream=stream,\n        custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n        input_cost_per_token=0,\n        output_cost_per_token=0,\n        temperature=temperature,\n        base_url=self._config.nearai_hub.base_url,\n        provider=provider,\n        api_key=auth_bearer_token,\n        **kwargs,\n    )\n\n    result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n        model=model, messages=messages, stream=stream, temperature=temperature, **kwargs\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry","title":"<code>nearai.tool_registry.ToolRegistry</code>","text":"Source code in <code>nearai/tool_registry.py</code> <pre><code>class ToolRegistry:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.tools: Dict[str, Callable] = {}\n\n    def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n        self.tools[tool.__name__] = tool\n\n    def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n        return self.tools.get(name)\n\n    def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n        return self.tools\n\n    def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n        tool = self.get_tool(name)\n        if tool is None:\n            raise ValueError(f\"Tool '{name}' not found.\")\n        return tool(**kwargs)\n\n    def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n        tool = self.get_tool(name)\n        if tool is None:\n            return None\n\n        assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n        docstring = tool.__doc__.strip().split(\"\\n\")\n\n        # The first line of the docstring is the function description\n        function_description = docstring[0].strip()\n\n        # The rest of the lines contain parameter descriptions\n        param_descriptions = docstring[1:]\n\n        # Extract parameter names and types\n        signature = inspect.signature(tool)\n        type_hints = get_type_hints(tool)\n\n        parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n        # Iterate through function parameters\n        for param in signature.parameters.values():\n            param_name = param.name\n            param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n            param_description = \"\"\n\n            # Find the parameter description in the docstring\n            for line in param_descriptions:\n                if line.strip().startswith(param_name):\n                    param_description = line.strip().split(\":\", 1)[1].strip()\n                    break\n\n            # Convert type hint to JSON Schema type\n            if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n                json_type = \"string\"\n            else:\n                json_type = param_type.__name__.lower()\n\n            json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n                json_type, json_type\n            )\n\n            # Add parameter to the definition\n            parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n            # Params without default values are required params\n            if param.default == inspect.Parameter.empty:\n                parameters[\"required\"].append(param_name)\n\n        return {\n            \"type\": \"function\",\n            \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n        }\n\n    def get_all_tool_definitions(self) -&gt; list[Dict]:  # noqa: D102\n        definitions = []\n        for tool_name, _tool in self.tools.items():\n            definition = self.get_tool_definition(tool_name)\n            if definition is not None:\n                definitions.append(definition)\n        return definitions\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment","title":"<code>nearai.solvers.ddot_v0_solver.DDOTSEnvironment</code>","text":"<p>               Bases: <code>Environment</code></p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSEnvironment(Environment):\n    def __init__(self, agents: List[Agent], problem_id: str, description: str, config: Config):  # noqa: D107\n        self.tdir = TemporaryDirectory()\n        super().__init__(self.tdir.name, agents, config)\n\n        self.problem_id = problem_id\n        self.solved = False\n\n        files = {\n            \".id\": problem_id,\n            \"PROBLEM.txt\": description,\n            \"solution.py\": \"\",\n            \"test.in\": \"\",\n            \"test.sh\": \"#!/bin/bash\\npython3 solution.py &lt; test.in\",\n        }\n        for fname, content in files.items():\n            with open(self.tdir.name + \"/\" + fname, \"w\") as f:\n                f.write(content)\n\n    async def async_submit(self, code: str) -&gt; Tuple[bool, str]:  # noqa: D102\n        submission_id = await submit_problem(self.problem_id, code, Extensions.PYTHON)\n\n        try:\n            await is_output_ready(submission_id)\n        except Exception:\n            print(\"WARNING: Submission took too long to execute on DDOTS\")\n            self.mark_done()\n            return False, \"Submission took too long to execute on the platform\"\n\n        ok = await submission_accepted(submission_id)\n\n        if ok:\n            self.solved = True\n            self.mark_done()\n            return True, \"\"\n\n        output = await get_output(submission_id)\n\n        return False, output\n\n    def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n        \"\"\"Returns True if the submission was accepted, False otherwise.\n\n        The second element of the tuple is the output of the checker if the submission was rejected.\n        \"\"\"\n        return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment.submit_python","title":"<code>submit_python(code)</code>","text":"<p>Returns True if the submission was accepted, False otherwise.</p> <p>The second element of the tuple is the output of the checker if the submission was rejected.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n    \"\"\"Returns True if the submission was accepted, False otherwise.\n\n    The second element of the tuple is the output of the checker if the submission was rejected.\n    \"\"\"\n    return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSV0Solver","title":"<code>nearai.solvers.ddot_v0_solver.DDOTSV0Solver</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        self.agents = [load_agent(agent) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        config = deepcopy(CONFIG)\n        config.confirm_commands = False\n\n        env = DDOTSEnvironment(self.agents, problem_id, description, config)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run_task(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_agent_solver.MBPPSolverAgent","title":"<code>nearai.solvers.mbpp_agent_solver.MBPPSolverAgent</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_agent_solver.py</code> <pre><code>class MBPPSolverAgent(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], agent: str, num_iterations: int = 16, verbose: bool = False\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.agent = load_agent(agent)\n        self.verbose = verbose\n        self.num_iterations = num_iterations\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n        function_name = get_function_name(datum[\"code\"])\n\n        path = os.path.join(\n            \"/tmp\",\n            \"mbpp\",\n            str(datum[\"task_id\"]),\n            str(int(time.time() * 1000)),\n            str(random.randint(0, 1000)),\n        )\n        CONFIG.confirm_commands = False\n        env = Environment(path, [self.agent], CONFIG)\n\n        new_line = \"\\n\"\n        task = f\"\"\"{datum[\"text\"]}\nWrite a single file with python function named `{function_name}` that solves the above problem and satisfied the following tests:\n```python\\n{new_line.join(datum[\"test_list\"])}\\n```\"\"\"  # noqa: E501\n        if self.verbose:\n            print(task)\n            print(path)\n        env.run_task(task, max_iterations=self.num_iterations)\n\n        code = \"\"\n        for filename in env.list_files(\".\"):\n            if filename.endswith(\".py\"):\n                code += env.read_file(filename) + \"\\n\"\n\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code, {}, {})\n            return True\n        except Exception as e:\n            if self.verbose:\n                print(e)\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver.MBPPDatum","title":"<code>nearai.solvers.mbpp_solver.MBPPDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPDatum(BaseModel):\n    task_id: int\n    text: str\n    code: str\n    test_list: List[str]\n    challenge_test_list: List[str]\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver.MBPPSolverStrategy","title":"<code>nearai.solvers.mbpp_solver.MBPPSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    SHOTS = 3\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.SHOTS))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver.MMLUDatum","title":"<code>nearai.solvers.mmlu_solver.MMLUDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUDatum(BaseModel):\n    question: str\n    subject: str\n    choices: List[str]\n    answer: int\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver.MMLUSolverStrategy","title":"<code>nearai.solvers.mmlu_solver.MMLUSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.2,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagDatum","title":"<code>nearai.solvers.hellaswag_solver.HellaswagDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagDatum(BaseModel):\n    activity_label: str\n    ctx: str\n    ctx_a: str\n    ctx_b: str\n    endings: List[str]\n    ind: int\n    label: str\n    source_id: str\n    split: str\n    split_type: str\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagSolverStrategy","title":"<code>nearai.solvers.hellaswag_solver.HellaswagSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.registry.Registry","title":"<code>nearai.registry.Registry</code>","text":"Source code in <code>nearai/registry.py</code> <pre><code>class Registry:\n    def __init__(self):\n        \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n        self.download_folder = DATA_FOLDER / \"registry\"\n        self.api = RegistryApi()\n\n        if not self.download_folder.exists():\n            self.download_folder.mkdir(parents=True, exist_ok=True)\n\n    def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n        \"\"\"Update metadata of a entry in the registry.\"\"\"\n        result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n            BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n        )\n        return result\n\n    def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n        \"\"\"Get metadata of a entry in the registry.\"\"\"\n        try:\n            return self.api.download_metadata_v1_registry_download_metadata_post(\n                BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n            )\n        except NotFoundException:\n            return None\n\n    def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n        \"\"\"Upload a file to the registry.\"\"\"\n        with open(local_path, \"rb\") as file:\n            data = file.read()\n\n            try:\n                self.api.upload_file_v1_registry_upload_file_post(\n                    path=str(path),\n                    file=data,\n                    namespace=entry_location.namespace,\n                    name=entry_location.name,\n                    version=entry_location.version,\n                )\n                return True\n            except BadRequestException as e:\n                if isinstance(e.body, str) and \"already exists\" in e.body:\n                    return False\n\n                raise e\n\n    def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n        \"\"\"Download a file from the registry.\"\"\"\n        result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n            BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n                dict(\n                    entry_location=entry_location,\n                    path=str(path),\n                )\n            )\n        )\n\n        local_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(local_path, \"wb\") as f:\n            copyfileobj(result, f)\n\n    def download(\n        self, entry_location: Union[str, EntryLocation], force: bool = False, show_progress: bool = False\n    ) -&gt; Path:\n        \"\"\"Download entry from the registry locally.\"\"\"\n        if isinstance(entry_location, str):\n            entry_location = parse_location(entry_location)\n\n        download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n        if download_path.exists():\n            if not force:\n                print(f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\")\n                return download_path\n\n        files = registry.list_files(entry_location)\n\n        download_path.mkdir(parents=True, exist_ok=True)\n\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            raise ValueError(f\"Entry {entry_location} not found.\")\n\n        metadata_path = download_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n        for file in (pbar := tqdm(files, disable=not show_progress)):\n            pbar.set_description(file)\n            registry.download_file(entry_location, file, download_path / file)\n\n        return download_path\n\n    def upload(\n        self,\n        local_path: Path,\n        metadata: Optional[EntryMetadata] = None,\n        show_progress: bool = False,\n    ) -&gt; EntryLocation:\n        \"\"\"Upload entry to the registry.\n\n        If metadata is provided it will overwrite the metadata in the directory,\n        otherwise it will use the metadata.json found on the root of the directory.\n        \"\"\"\n        path = Path(local_path).absolute()\n\n        if not path.exists():\n            # try path in local registry if original path not exists\n            path = get_registry_folder() / local_path\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n\n        if metadata is not None:\n            with open(metadata_path, \"w\") as f:\n                f.write(metadata.model_dump_json(indent=2))\n\n        check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            plain_metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.account_id\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=plain_metadata.pop(\"name\"),\n                version=plain_metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n        source = entry_metadata.details.get(\"_source\", None)\n\n        if source is not None:\n            print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n            exit(1)\n\n        registry.update(entry_location, entry_metadata)\n\n        all_files = []\n        total_size = 0\n\n        # Traverse all files in the directory `path`\n        for file in path.rglob(\"*\"):\n            if not file.is_file():\n                continue\n\n            relative = file.relative_to(path)\n\n            # Don't upload metadata file.\n            if file == metadata_path:\n                continue\n\n            # Don't upload backup files.\n            if file.name.endswith(\"~\"):\n                continue\n\n            # Don't upload configuration files.\n            if relative.parts[0] == \".nearai\":\n                continue\n\n            size = file.stat().st_size\n            total_size += size\n\n            all_files.append((file, relative, size))\n\n        pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n        for file, relative, size in all_files:\n            registry.upload_file(entry_location, file, relative)\n            pbar.update(size)\n\n        return entry_location\n\n    def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n        \"\"\"List files in from an entry in the registry.\n\n        Return the relative paths to all files with respect to the root of the entry.\n        \"\"\"\n        return self.api.list_files_v1_registry_list_files_post(\n            BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n        )\n\n    def list(\n        self,\n        namespace: str,\n        category: str,\n        tags: str,\n        total: int,\n        show_hidden: bool,\n    ) -&gt; List[EntryLocation]:\n        \"\"\"List and filter entries in the registry.\"\"\"\n        return self.api.list_entries_v1_registry_list_entries_post(\n            namespace=namespace,\n            category=category,\n            tags=tags,\n            total=total,\n            show_hidden=show_hidden,\n        )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.__init__","title":"<code>__init__()</code>","text":"<p>Create Registry object to interact with the registry programmatically.</p> Source code in <code>nearai/registry.py</code> <pre><code>def __init__(self):\n    \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n    self.download_folder = DATA_FOLDER / \"registry\"\n    self.api = RegistryApi()\n\n    if not self.download_folder.exists():\n        self.download_folder.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download","title":"<code>download(entry_location, force=False, show_progress=False)</code>","text":"<p>Download entry from the registry locally.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download(\n    self, entry_location: Union[str, EntryLocation], force: bool = False, show_progress: bool = False\n) -&gt; Path:\n    \"\"\"Download entry from the registry locally.\"\"\"\n    if isinstance(entry_location, str):\n        entry_location = parse_location(entry_location)\n\n    download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n    if download_path.exists():\n        if not force:\n            print(f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\")\n            return download_path\n\n    files = registry.list_files(entry_location)\n\n    download_path.mkdir(parents=True, exist_ok=True)\n\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        raise ValueError(f\"Entry {entry_location} not found.\")\n\n    metadata_path = download_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        f.write(metadata.model_dump_json(indent=2))\n\n    for file in (pbar := tqdm(files, disable=not show_progress)):\n        pbar.set_description(file)\n        registry.download_file(entry_location, file, download_path / file)\n\n    return download_path\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download_file","title":"<code>download_file(entry_location, path, local_path)</code>","text":"<p>Download a file from the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n    \"\"\"Download a file from the registry.\"\"\"\n    result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n        BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n            dict(\n                entry_location=entry_location,\n                path=str(path),\n            )\n        )\n    )\n\n    local_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(local_path, \"wb\") as f:\n        copyfileobj(result, f)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.info","title":"<code>info(entry_location)</code>","text":"<p>Get metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n    \"\"\"Get metadata of a entry in the registry.\"\"\"\n    try:\n        return self.api.download_metadata_v1_registry_download_metadata_post(\n            BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n        )\n    except NotFoundException:\n        return None\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list","title":"<code>list(namespace, category, tags, total, show_hidden)</code>","text":"<p>List and filter entries in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list(\n    self,\n    namespace: str,\n    category: str,\n    tags: str,\n    total: int,\n    show_hidden: bool,\n) -&gt; List[EntryLocation]:\n    \"\"\"List and filter entries in the registry.\"\"\"\n    return self.api.list_entries_v1_registry_list_entries_post(\n        namespace=namespace,\n        category=category,\n        tags=tags,\n        total=total,\n        show_hidden=show_hidden,\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_files","title":"<code>list_files(entry_location)</code>","text":"<p>List files in from an entry in the registry.</p> <p>Return the relative paths to all files with respect to the root of the entry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n    \"\"\"List files in from an entry in the registry.\n\n    Return the relative paths to all files with respect to the root of the entry.\n    \"\"\"\n    return self.api.list_files_v1_registry_list_files_post(\n        BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.update","title":"<code>update(entry_location, metadata)</code>","text":"<p>Update metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n    \"\"\"Update metadata of a entry in the registry.\"\"\"\n    result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n        BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload","title":"<code>upload(local_path, metadata=None, show_progress=False)</code>","text":"<p>Upload entry to the registry.</p> <p>If metadata is provided it will overwrite the metadata in the directory, otherwise it will use the metadata.json found on the root of the directory.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload(\n    self,\n    local_path: Path,\n    metadata: Optional[EntryMetadata] = None,\n    show_progress: bool = False,\n) -&gt; EntryLocation:\n    \"\"\"Upload entry to the registry.\n\n    If metadata is provided it will overwrite the metadata in the directory,\n    otherwise it will use the metadata.json found on the root of the directory.\n    \"\"\"\n    path = Path(local_path).absolute()\n\n    if not path.exists():\n        # try path in local registry if original path not exists\n        path = get_registry_folder() / local_path\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n\n    if metadata is not None:\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n    check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        plain_metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.account_id\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=plain_metadata.pop(\"name\"),\n            version=plain_metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n    source = entry_metadata.details.get(\"_source\", None)\n\n    if source is not None:\n        print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n        exit(1)\n\n    registry.update(entry_location, entry_metadata)\n\n    all_files = []\n    total_size = 0\n\n    # Traverse all files in the directory `path`\n    for file in path.rglob(\"*\"):\n        if not file.is_file():\n            continue\n\n        relative = file.relative_to(path)\n\n        # Don't upload metadata file.\n        if file == metadata_path:\n            continue\n\n        # Don't upload backup files.\n        if file.name.endswith(\"~\"):\n            continue\n\n        # Don't upload configuration files.\n        if relative.parts[0] == \".nearai\":\n            continue\n\n        size = file.stat().st_size\n        total_size += size\n\n        all_files.append((file, relative, size))\n\n    pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n    for file, relative, size in all_files:\n        registry.upload_file(entry_location, file, relative)\n        pbar.update(size)\n\n    return entry_location\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload_file","title":"<code>upload_file(entry_location, local_path, path)</code>","text":"<p>Upload a file to the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n    \"\"\"Upload a file to the registry.\"\"\"\n    with open(local_path, \"rb\") as file:\n        data = file.read()\n\n        try:\n            self.api.upload_file_v1_registry_upload_file_post(\n                path=str(path),\n                file=data,\n                namespace=entry_location.namespace,\n                name=entry_location.name,\n                version=entry_location.version,\n            )\n            return True\n        except BadRequestException as e:\n            if isinstance(e.body, str) and \"already exists\" in e.body:\n                return False\n\n            raise e\n</code></pre>"},{"location":"api/#nearai.environment.Environment","title":"<code>nearai.environment.Environment</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/environment.py</code> <pre><code>class Environment(object):\n    def __init__(  # noqa: D107\n        self, path: str, agents: List[Agent], config: Config, create_files: bool = True\n    ) -&gt; None:\n        self._path = path\n        self._agents = agents\n        self._done = False\n        self._config = config\n        self._inference = InferenceRouter(config)\n        self._user_name = config.user_name\n        self._tools = ToolRegistry()\n        self.register_standard_tools()\n\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        if create_files:\n            os.makedirs(self._path, exist_ok=True)\n            open(os.path.join(self._path, CHAT_FILENAME), \"a\").close()\n        os.chdir(self._path)\n\n    @staticmethod\n    def _generate_run_id() -&gt; str:\n        return uuid.uuid4().hex\n\n    def get_tool_registry(self) -&gt; ToolRegistry:  # noqa: D102\n        return self._tools\n\n    def register_standard_tools(self) -&gt; None:  # noqa: D102\n        reg = self.get_tool_registry()\n        reg.register_tool(self.exec_command)\n        reg.register_tool(self.read_file)\n        reg.register_tool(self.write_file)\n        reg.register_tool(self.request_user_input)\n        reg.register_tool(self.list_files)\n\n    def add_message(self, role: str, message: str, filename: str = CHAT_FILENAME, **kwargs: Any) -&gt; None:  # noqa: D102\n        with open(os.path.join(self._path, filename), \"a\") as f:\n            f.write(json.dumps({\"role\": role, \"content\": message, **kwargs}) + DELIMITER)\n\n    def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:  # noqa: D102\n        return self.list_messages(filename)\n\n    def list_messages(self, filename: str = CHAT_FILENAME) -&gt; List[Any]:  # noqa: D102\n        path = os.path.join(self._path, filename)\n\n        if not os.path.exists(path):\n            return []\n\n        with open(path, \"r\") as f:\n            return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n\n    def list_files(self, path: str) -&gt; List[str]:\n        \"\"\"Lists files in the environment.\n\n        path: The path to list files from.\n        \"\"\"\n        return os.listdir(os.path.join(self._path, path))\n\n    def get_path(self) -&gt; str:  # noqa: D102\n        return self._path\n\n    def read_file(self, filename: str) -&gt; str:\n        \"\"\"Read a file from the environment.\n\n        filename: The name of the file to read.\n        \"\"\"\n        if not os.path.exists(os.path.join(self._path, filename)):\n            return \"\"\n        try:\n            with open(os.path.join(self._path, filename), \"r\") as f:\n                return f.read()\n        except Exception as e:\n            return f\"failed to read file: {e}\"\n\n    def write_file(self, filename: str, content: str) -&gt; str:\n        \"\"\"Writes a file to the environment.\n\n        filename: The name of the file to write to\n        content: The content to write to the file.\n        \"\"\"\n        path = Path(self._path) / filename\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with open(path, \"w\") as f:\n            f.write(content)\n        return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n\n    def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"Executes a command in the environment and logs the output.\n\n        The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n        command: The command to execute, like 'ls -l' or 'python3 tests.py'\n        \"\"\"  # noqa: E501\n        if self._config.get(\"confirm_commands\", True):\n            yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n            if yes_no != \"\" and yes_no.lower() != \"y\":\n                return {\n                    \"command\": command,\n                    \"returncode\": 999,\n                    \"stdout\": \"\",\n                    \"stderr\": \"declined by user\",\n                }\n\n        try:\n            process = subprocess.Popen(\n                shlex.split(command),\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                bufsize=0,\n                universal_newlines=True,\n                cwd=self._path,\n            )\n        except Exception as e:\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"Failed to execute: \" + str(e),\n            }\n\n        msg = \"\"\n\n        def kill_process_tree(p: Any) -&gt; None:\n            nonlocal msg\n            msg = \"Killing process due to timeout\"\n\n            process = psutil.Process(p.pid)\n            for proc in process.children(recursive=True):\n                proc.kill()\n            process.kill()\n\n        timer = threading.Timer(2, kill_process_tree, (process,))\n        timer.start()\n        process.wait()\n        timer.cancel()\n\n        result = {\n            \"command\": command,\n            \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n            \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n            \"returncode\": process.returncode,\n            \"msg\": msg,\n        }\n        with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n            f.write(json.dumps(result) + DELIMITER)\n        return result\n\n    def completions(\n        self, model: str, messages: Iterable[ChatCompletionMessageParam], stream: bool = False, **kwargs: Any\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Returns all completions for given messages using the given model.\"\"\"\n        return self._inference.completions(model, messages, stream=stream, **kwargs)\n\n    def completions_and_run_tools(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; ModelResponse:\n        \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n        raw_response = self._inference.completions(model, messages, stream=False, tools=tools, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message\n        if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n            for tool_call in response_message.tool_calls:\n                function_name = tool_call.function.name\n                assert function_name, \"Tool call must have a function name\"\n                function_args = json.loads(tool_call.function.arguments)\n                function_response = self._tools.call_tool(function_name, **function_args)\n\n                if function_response:\n                    function_response_json = json.dumps(function_response) if function_response else \"\"\n                    self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n        return response\n\n    def completion(self, model: str, messages: Iterable[ChatCompletionMessageParam]) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n        raw_response = self.completions(model, messages)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def completion_and_run_tools(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n        completion_tools_response = self.completions_and_run_tools(model, messages, tools, **kwargs)\n        assert all(\n            map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n        ), \"Expected Choices\"\n        choices: List[Choices] = completion_tools_response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def call_agent(self, agent_path: int, task: str) -&gt; None:\n        \"\"\"Calls agent with given task.\"\"\"\n        self._agents[agent_path].run(self, task=task)\n\n    def get_agents(self) -&gt; List[Agent]:\n        \"\"\"Returns list of agents available in environment.\"\"\"\n        return self._agents\n\n    def is_done(self) -&gt; bool:  # noqa: D102\n        return self._done\n\n    def mark_done(self) -&gt; None:  # noqa: D102\n        self._done = True\n\n    def create_snapshot(self) -&gt; bytes:\n        \"\"\"Create an in memory snapshot.\"\"\"\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(self._path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n        return snapshot\n\n    def save_to_registry(\n        self,\n        path: str,\n        run_type: str,\n        run_id: str,\n        base_id: Optional[Union[str, int]] = None,\n        run_name: Optional[str] = None,\n    ) -&gt; Optional[bytes]:\n        \"\"\"Save Environment to Registry.\"\"\"\n        author = self._user_name\n        if not author:\n            print(\"Warning: You are not logged in, run not saved to registry.\" \" To log in run `nearai login`\")\n            return None\n\n        agent_name = self._agents[0].name if self._agents else \"unknown\"\n        generated_name = f\"environment_run_{agent_name}_{run_id}\"\n        name = run_name or generated_name\n\n        tempdir = Path(tempfile.mkdtemp())\n        environment_path = tempdir / \"environment.tar.gz\"\n\n        if os.path.exists(environment_path):\n            with open(environment_path, \"r+b\") as f:\n                with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                    tar.add(path, arcname=\".\")\n                f.flush()\n                f.seek(0)\n                snapshot = f.read()\n                tar_filename = f.name\n\n                timestamp = datetime.now(timezone.utc).isoformat()\n\n                entry_location = registry.upload(\n                    tempdir,\n                    EntryMetadata.from_dict(\n                        {\n                            \"name\": name,\n                            \"version\": \"0.0.1\",\n                            \"description\": f\"Agent {run_type} run {agent_name}\",\n                            \"category\": \"environment\",\n                            \"tags\": [\"environment\"],\n                            \"details\": {\n                                \"base_id\": base_id,\n                                \"timestamp\": timestamp,\n                                \"agents\": [agent.name for agent in self._agents],\n                                \"run_id\": run_id,\n                                \"run_type\": run_type,\n                                \"filename\": tar_filename,\n                            },\n                            \"show_entry\": True,\n                        }\n                    ),\n                    show_progress=True,\n                )\n\n                location_str = plain_location(entry_location)\n\n                print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n            rmtree(tempdir)\n            return snapshot\n        else:\n            print(f\"The file {environment_path} does not exist.\")\n            return None\n\n    def load_snapshot(self, snapshot: bytes) -&gt; None:\n        \"\"\"Load Environment from Snapshot.\"\"\"\n        shutil.rmtree(self._path, ignore_errors=True)\n\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            f.write(snapshot)\n            f.flush()\n            f.seek(0)\n\n            with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n                tar.extractall(self._path)\n\n    def load_from_registry(self, load_env: str) -&gt; str:  # noqa: D102\n        print(f\"Loading environment from {load_env} to {self._path}\")\n\n        directory = registry.download(load_env)\n        assert directory is not None, \"Failed to download environment\"\n\n        files = os.listdir(directory)\n        tarfile_file = next(f for f in files if f.endswith(\".tar.gz\"))\n\n        with tarfile.open(directory / tarfile_file, \"r\") as tar:\n            tar.extractall(self._path)\n        return directory.name\n\n    def __str__(self) -&gt; str:  # noqa: D105\n        return f\"Environment({self._path})\"\n\n    def run_agent(self, task: Optional[str]) -&gt; None:  # noqa: D102\n        self._agents[0].run(self, task=task)\n\n    def request_user_input(self) -&gt; None:\n        \"\"\"Must be called to request input from the user.\"\"\"\n        self.set_next_actor(\"user\")\n\n    def clear_temp_agent_files(self) -&gt; None:  # noqa: D102\n        \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n        shutil.rmtree(self._agents[0].temp_dir)\n\n    def set_next_actor(self, who: str) -&gt; None:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        with open(next_action_fn, \"w\") as f:\n            f.write(who)\n\n    def get_next_actor(self) -&gt; str:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        if os.path.exists(next_action_fn):\n            with open(next_action_fn) as f:\n                return f.read().strip(\" \\n\")\n        else:\n            # By default the user starts the conversation.\n            return \"user\"\n\n    def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n        \"\"\"Run an interactive session within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        last_message_idx = 0\n\n        def print_messages(last_message_idx: int) -&gt; int:\n            messages = self.list_messages()\n            for item in messages[last_message_idx:]:\n                print(f\"[{item['role']}]: {item['content']}\", flush=True)\n            return len(messages)\n\n        last_message_idx = print_messages(last_message_idx)\n\n        iteration_count = 0\n        while True:\n            if self.get_next_actor() != \"user\":\n                messages = self.list_messages()\n                new_message = None if not messages else messages[-1][\"content\"]\n\n                iteration_count += 1\n                self.run_agent(new_message)\n\n                last_message_idx = print_messages(last_message_idx)\n                if self.is_done():\n                    break\n\n            else:\n                new_message = input(\"&gt; \")\n                if new_message == \"exit\":\n                    break\n                self.add_message(\"user\", new_message)\n\n                self.set_next_actor(\"agent\")\n\n        self.clear_temp_agent_files()\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n\n    def run_task(\n        self,\n        task: str,\n        record_run: str = \"\",\n        load_env: str = \"\",\n        max_iterations: int = 10,\n    ) -&gt; None:\n        \"\"\"Runs a task within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        iteration = 0\n\n        if task:\n            self.add_message(\"user\", task)\n\n        while iteration &lt; max_iterations and not self.is_done():\n            iteration += 1\n            self._agents[0].run(self, task=task)\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n\n    def inspect(self) -&gt; None:  # noqa: D102\n        filename = Path(os.path.abspath(__file__)).parent / \"streamlit_inspect.py\"\n        subprocess.call([\"streamlit\", \"run\", filename, \"--\", self._path])\n\n    def contains_non_empty_chat_txt(self, directory: str) -&gt; bool:  # noqa: D102\n        chat_txt_path = os.path.join(directory, \"chat.txt\")\n        return os.path.isfile(chat_txt_path) and os.path.getsize(chat_txt_path) &gt; 0\n\n    def save_folder(self, name: Optional[str] = None) -&gt; None:  # noqa: D102\n        path = self._path\n        temp_dir = None\n\n        def copy_relevant_folders(src: str, dest: str) -&gt; None:\n            for item in os.listdir(src):\n                s = os.path.join(src, item)\n                d = os.path.join(dest, item)\n                if os.path.isdir(s):\n                    if self.contains_non_empty_chat_txt(s):\n                        shutil.copytree(s, d)\n                    else:\n                        os.makedirs(d, exist_ok=True)\n                        copy_relevant_folders(s, d)\n                        if not os.listdir(d):\n                            os.rmdir(d)\n\n        if not self.contains_non_empty_chat_txt(path):\n            temp_dir = tempfile.mkdtemp()\n            copy_relevant_folders(path, temp_dir)\n            path = temp_dir\n\n        try:\n            if not os.listdir(path):\n                raise ValueError(f\"No files found in {path}\")\n\n            self.save_to_registry(\n                path, \"folders\" if temp_dir else \"folder\", self.generate_folder_hash_id(path), None, name\n            )\n        finally:\n            if temp_dir:\n                shutil.rmtree(temp_dir)\n\n    def save_from_history(self, lines: List[str], name: Optional[str] = None) -&gt; None:  # noqa: D102\n        # Parse lines and extract relevant information\n        pattern = r\"^\\s*(?:\\d+\\s+)?(\\S+)\\s+environment\\s+interactive\\s+(\\S+)\\s+(\\S+)(.*?)$\"\n        relevant_paths = {}\n        for line in lines:\n            match = re.match(pattern, line)\n            if match:\n                program_name, agents, path, other_args = match.groups()\n                path = path.strip(\"/\")\n                if self.contains_non_empty_chat_txt(path):\n                    command = f\"{program_name} environment interactive {agents} {path} {other_args}\"\n                    relevant_paths[path] = {\"command\": command.strip()}\n\n        if not relevant_paths:\n            raise ValueError(\"No relevant paths with non-empty chat.txt files found in history\")\n\n        for path, info in relevant_paths.items():\n            print(path)\n            # Write start_command.log\n            with open(os.path.join(path, \"start_command.log\"), \"w\") as f:\n                f.write(info[\"command\"])\n\n        # Create temporary directory and copy relevant folders\n        temp_dir = tempfile.mkdtemp()\n        try:\n            for path, _info in relevant_paths.items():\n                dest = os.path.join(temp_dir, path.replace(\"/\", \"_\").strip(\"_\"))\n                shutil.copytree(path, dest)\n            self.save_to_registry(temp_dir, \"folders\", self.generate_folder_hash_id(temp_dir), None, name)\n\n        finally:\n            shutil.rmtree(temp_dir)\n\n    def generate_folder_hash_id(self, path: str) -&gt; str:\n        \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n        hash_obj = hashlib.md5()\n\n        for root, _dirs, files in os.walk(path):\n            for file in sorted(files):\n                file_path = os.path.join(root, file)\n                with open(file_path, \"rb\") as f:\n                    while chunk := f.read(8192):\n                        hash_obj.update(chunk)\n\n        return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.call_agent","title":"<code>call_agent(agent_path, task)</code>","text":"<p>Calls agent with given task.</p> Source code in <code>nearai/environment.py</code> <pre><code>def call_agent(self, agent_path: int, task: str) -&gt; None:\n    \"\"\"Calls agent with given task.\"\"\"\n    self._agents[agent_path].run(self, task=task)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.clear_temp_agent_files","title":"<code>clear_temp_agent_files()</code>","text":"<p>Remove temp agent files created to be used in <code>runpy</code>.</p> Source code in <code>nearai/environment.py</code> <pre><code>def clear_temp_agent_files(self) -&gt; None:  # noqa: D102\n    \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n    shutil.rmtree(self._agents[0].temp_dir)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion","title":"<code>completion(model, messages)</code>","text":"<p>Returns a completion for the given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion(self, model: str, messages: Iterable[ChatCompletionMessageParam]) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n    raw_response = self.completions(model, messages)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion_and_run_tools","title":"<code>completion_and_run_tools(model, messages, tools=None, **kwargs)</code>","text":"<p>Returns a completion for the given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion_and_run_tools(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n    completion_tools_response = self.completions_and_run_tools(model, messages, tools, **kwargs)\n    assert all(\n        map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n    ), \"Expected Choices\"\n    choices: List[Choices] = completion_tools_response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions","title":"<code>completions(model, messages, stream=False, **kwargs)</code>","text":"<p>Returns all completions for given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions(\n    self, model: str, messages: Iterable[ChatCompletionMessageParam], stream: bool = False, **kwargs: Any\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Returns all completions for given messages using the given model.\"\"\"\n    return self._inference.completions(model, messages, stream=stream, **kwargs)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions_and_run_tools","title":"<code>completions_and_run_tools(model, messages, tools=None, **kwargs)</code>","text":"<p>Returns all completions for given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions_and_run_tools(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; ModelResponse:\n    \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n    raw_response = self._inference.completions(model, messages, stream=False, tools=tools, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message\n    if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n        for tool_call in response_message.tool_calls:\n            function_name = tool_call.function.name\n            assert function_name, \"Tool call must have a function name\"\n            function_args = json.loads(tool_call.function.arguments)\n            function_response = self._tools.call_tool(function_name, **function_args)\n\n            if function_response:\n                function_response_json = json.dumps(function_response) if function_response else \"\"\n                self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n    return response\n</code></pre>"},{"location":"api/#nearai.environment.Environment.create_snapshot","title":"<code>create_snapshot()</code>","text":"<p>Create an in memory snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def create_snapshot(self) -&gt; bytes:\n    \"\"\"Create an in memory snapshot.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(self._path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.environment.Environment.exec_command","title":"<code>exec_command(command)</code>","text":"<p>Executes a command in the environment and logs the output.</p> <p>The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input. command: The command to execute, like 'ls -l' or 'python3 tests.py'</p> Source code in <code>nearai/environment.py</code> <pre><code>def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Executes a command in the environment and logs the output.\n\n    The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n    command: The command to execute, like 'ls -l' or 'python3 tests.py'\n    \"\"\"  # noqa: E501\n    if self._config.get(\"confirm_commands\", True):\n        yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n        if yes_no != \"\" and yes_no.lower() != \"y\":\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"declined by user\",\n            }\n\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            bufsize=0,\n            universal_newlines=True,\n            cwd=self._path,\n        )\n    except Exception as e:\n        return {\n            \"command\": command,\n            \"returncode\": 999,\n            \"stdout\": \"\",\n            \"stderr\": \"Failed to execute: \" + str(e),\n        }\n\n    msg = \"\"\n\n    def kill_process_tree(p: Any) -&gt; None:\n        nonlocal msg\n        msg = \"Killing process due to timeout\"\n\n        process = psutil.Process(p.pid)\n        for proc in process.children(recursive=True):\n            proc.kill()\n        process.kill()\n\n    timer = threading.Timer(2, kill_process_tree, (process,))\n    timer.start()\n    process.wait()\n    timer.cancel()\n\n    result = {\n        \"command\": command,\n        \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n        \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n        \"returncode\": process.returncode,\n        \"msg\": msg,\n    }\n    with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n        f.write(json.dumps(result) + DELIMITER)\n    return result\n</code></pre>"},{"location":"api/#nearai.environment.Environment.generate_folder_hash_id","title":"<code>generate_folder_hash_id(path)</code>","text":"<p>Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.</p> Source code in <code>nearai/environment.py</code> <pre><code>def generate_folder_hash_id(self, path: str) -&gt; str:\n    \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n    hash_obj = hashlib.md5()\n\n    for root, _dirs, files in os.walk(path):\n        for file in sorted(files):\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                while chunk := f.read(8192):\n                    hash_obj.update(chunk)\n\n    return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_agents","title":"<code>get_agents()</code>","text":"<p>Returns list of agents available in environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_agents(self) -&gt; List[Agent]:\n    \"\"\"Returns list of agents available in environment.\"\"\"\n    return self._agents\n</code></pre>"},{"location":"api/#nearai.environment.Environment.list_files","title":"<code>list_files(path)</code>","text":"<p>Lists files in the environment.</p> <p>path: The path to list files from.</p> Source code in <code>nearai/environment.py</code> <pre><code>def list_files(self, path: str) -&gt; List[str]:\n    \"\"\"Lists files in the environment.\n\n    path: The path to list files from.\n    \"\"\"\n    return os.listdir(os.path.join(self._path, path))\n</code></pre>"},{"location":"api/#nearai.environment.Environment.load_snapshot","title":"<code>load_snapshot(snapshot)</code>","text":"<p>Load Environment from Snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def load_snapshot(self, snapshot: bytes) -&gt; None:\n    \"\"\"Load Environment from Snapshot.\"\"\"\n    shutil.rmtree(self._path, ignore_errors=True)\n\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        f.write(snapshot)\n        f.flush()\n        f.seek(0)\n\n        with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n            tar.extractall(self._path)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.read_file","title":"<code>read_file(filename)</code>","text":"<p>Read a file from the environment.</p> <p>filename: The name of the file to read.</p> Source code in <code>nearai/environment.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n    \"\"\"Read a file from the environment.\n\n    filename: The name of the file to read.\n    \"\"\"\n    if not os.path.exists(os.path.join(self._path, filename)):\n        return \"\"\n    try:\n        with open(os.path.join(self._path, filename), \"r\") as f:\n            return f.read()\n    except Exception as e:\n        return f\"failed to read file: {e}\"\n</code></pre>"},{"location":"api/#nearai.environment.Environment.request_user_input","title":"<code>request_user_input()</code>","text":"<p>Must be called to request input from the user.</p> Source code in <code>nearai/environment.py</code> <pre><code>def request_user_input(self) -&gt; None:\n    \"\"\"Must be called to request input from the user.\"\"\"\n    self.set_next_actor(\"user\")\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_interactive","title":"<code>run_interactive(record_run='', load_env='')</code>","text":"<p>Run an interactive session within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n    \"\"\"Run an interactive session within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    last_message_idx = 0\n\n    def print_messages(last_message_idx: int) -&gt; int:\n        messages = self.list_messages()\n        for item in messages[last_message_idx:]:\n            print(f\"[{item['role']}]: {item['content']}\", flush=True)\n        return len(messages)\n\n    last_message_idx = print_messages(last_message_idx)\n\n    iteration_count = 0\n    while True:\n        if self.get_next_actor() != \"user\":\n            messages = self.list_messages()\n            new_message = None if not messages else messages[-1][\"content\"]\n\n            iteration_count += 1\n            self.run_agent(new_message)\n\n            last_message_idx = print_messages(last_message_idx)\n            if self.is_done():\n                break\n\n        else:\n            new_message = input(\"&gt; \")\n            if new_message == \"exit\":\n                break\n            self.add_message(\"user\", new_message)\n\n            self.set_next_actor(\"agent\")\n\n    self.clear_temp_agent_files()\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_task","title":"<code>run_task(task, record_run='', load_env='', max_iterations=10)</code>","text":"<p>Runs a task within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_task(\n    self,\n    task: str,\n    record_run: str = \"\",\n    load_env: str = \"\",\n    max_iterations: int = 10,\n) -&gt; None:\n    \"\"\"Runs a task within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    iteration = 0\n\n    if task:\n        self.add_message(\"user\", task)\n\n    while iteration &lt; max_iterations and not self.is_done():\n        iteration += 1\n        self._agents[0].run(self, task=task)\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.save_to_registry","title":"<code>save_to_registry(path, run_type, run_id, base_id=None, run_name=None)</code>","text":"<p>Save Environment to Registry.</p> Source code in <code>nearai/environment.py</code> <pre><code>def save_to_registry(\n    self,\n    path: str,\n    run_type: str,\n    run_id: str,\n    base_id: Optional[Union[str, int]] = None,\n    run_name: Optional[str] = None,\n) -&gt; Optional[bytes]:\n    \"\"\"Save Environment to Registry.\"\"\"\n    author = self._user_name\n    if not author:\n        print(\"Warning: You are not logged in, run not saved to registry.\" \" To log in run `nearai login`\")\n        return None\n\n    agent_name = self._agents[0].name if self._agents else \"unknown\"\n    generated_name = f\"environment_run_{agent_name}_{run_id}\"\n    name = run_name or generated_name\n\n    tempdir = Path(tempfile.mkdtemp())\n    environment_path = tempdir / \"environment.tar.gz\"\n\n    if os.path.exists(environment_path):\n        with open(environment_path, \"r+b\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n            tar_filename = f.name\n\n            timestamp = datetime.now(timezone.utc).isoformat()\n\n            entry_location = registry.upload(\n                tempdir,\n                EntryMetadata.from_dict(\n                    {\n                        \"name\": name,\n                        \"version\": \"0.0.1\",\n                        \"description\": f\"Agent {run_type} run {agent_name}\",\n                        \"category\": \"environment\",\n                        \"tags\": [\"environment\"],\n                        \"details\": {\n                            \"base_id\": base_id,\n                            \"timestamp\": timestamp,\n                            \"agents\": [agent.name for agent in self._agents],\n                            \"run_id\": run_id,\n                            \"run_type\": run_type,\n                            \"filename\": tar_filename,\n                        },\n                        \"show_entry\": True,\n                    }\n                ),\n                show_progress=True,\n            )\n\n            location_str = plain_location(entry_location)\n\n            print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n        rmtree(tempdir)\n        return snapshot\n    else:\n        print(f\"The file {environment_path} does not exist.\")\n        return None\n</code></pre>"},{"location":"api/#nearai.environment.Environment.write_file","title":"<code>write_file(filename, content)</code>","text":"<p>Writes a file to the environment.</p> <p>filename: The name of the file to write to content: The content to write to the file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def write_file(self, filename: str, content: str) -&gt; str:\n    \"\"\"Writes a file to the environment.\n\n    filename: The name of the file to write to\n    content: The content to write to the file.\n    \"\"\"\n    path = Path(self._path) / filename\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with open(path, \"w\") as f:\n        f.write(content)\n    return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n</code></pre>"},{"location":"api/#nearai.config.Config","title":"<code>nearai.config.Config</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/config.py</code> <pre><code>class Config(BaseModel):\n    origin: Optional[str] = None\n    user_name: Optional[str] = None\n    user_email: Optional[str] = None\n    api_url: Optional[str] = \"https://api.near.ai\"\n    inference_url: str = \"http://localhost:5000/v1/\"\n    inference_api_key: str = \"n/a\"\n    nearai_hub: Optional[NearAiHubConfig] = NearAiHubConfig()\n    confirm_commands: bool = True\n    auth: Optional[AuthData] = None\n\n    def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n        \"\"\"Update the config with the given dictionary.\"\"\"\n        dict_repr = self.model_dump()\n        keys = list(map(map_key, dict_repr.keys()))\n\n        for key in keys:\n            value = extra_config.get(key, None)\n\n            if value:\n                # This will skip empty values, even if they are set in the `extra_config`\n                dict_repr[key] = value\n\n        return Config.model_validate(dict_repr)\n\n    def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n        \"\"\"Get the value of a key in the config if it exists.\"\"\"\n        return getattr(self, key, default)\n\n    def get_user_name(self) -&gt; str:\n        \"\"\"Get the user name from the config.\n\n        Prompt the user to set the user name if it is not set.\n        \"\"\"\n        if self.user_name is None:\n            print(\"Please set user_name with `nearai config set user_name &lt;name&gt;`\")\n            exit(1)\n        return self.user_name\n</code></pre>"},{"location":"api/#nearai.config.Config.get","title":"<code>get(key, default=None)</code>","text":"<p>Get the value of a key in the config if it exists.</p> Source code in <code>nearai/config.py</code> <pre><code>def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n    \"\"\"Get the value of a key in the config if it exists.\"\"\"\n    return getattr(self, key, default)\n</code></pre>"},{"location":"api/#nearai.config.Config.get_user_name","title":"<code>get_user_name()</code>","text":"<p>Get the user name from the config.</p> <p>Prompt the user to set the user name if it is not set.</p> Source code in <code>nearai/config.py</code> <pre><code>def get_user_name(self) -&gt; str:\n    \"\"\"Get the user name from the config.\n\n    Prompt the user to set the user name if it is not set.\n    \"\"\"\n    if self.user_name is None:\n        print(\"Please set user_name with `nearai config set user_name &lt;name&gt;`\")\n        exit(1)\n    return self.user_name\n</code></pre>"},{"location":"api/#nearai.config.Config.update_with","title":"<code>update_with(extra_config, map_key=lambda x: x)</code>","text":"<p>Update the config with the given dictionary.</p> Source code in <code>nearai/config.py</code> <pre><code>def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n    \"\"\"Update the config with the given dictionary.\"\"\"\n    dict_repr = self.model_dump()\n    keys = list(map(map_key, dict_repr.keys()))\n\n    for key in keys:\n        value = extra_config.get(key, None)\n\n        if value:\n            # This will skip empty values, even if they are set in the `extra_config`\n            dict_repr[key] = value\n\n    return Config.model_validate(dict_repr)\n</code></pre>"},{"location":"contributing/","title":"Contribute to <code>nearai</code>","text":"<p>Everyone is welcome to contribute, and we value everybody's contribution. Code contributions are not the only way to help the community. Answering questions, helping others, and improving documentation are also immensely valuable.</p> <p>It also helps us if you spread the word! Reference the library in blog posts about the awesome projects it made possible, or even simply \u2b50\ufe0f the repository to say thank you.</p> <p>This guide was heavily inspired by the huggingface transformers guide to contributing.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to contribute","text":"<p>There are several ways you can contribute to <code>nearai</code>:</p> <ul> <li>Fix outstanding issues with the existing code.</li> <li>Submit issues related to bugs or desired new features.</li> <li>Implement new features (including but not limited to solvers, agents, or benchmarks).</li> <li>Contribute to the examples or to the documentation.</li> </ul>"},{"location":"contributing/#fixing-outstanding-issues","title":"Fixing outstanding issues","text":"<p>If you notice an issue with the existing code and have a fix in mind, feel free to start contributing and open a Pull Request!</p>"},{"location":"contributing/#submitting-a-bug-related-issue-or-feature-request","title":"Submitting a bug-related issue or feature request","text":"<p>Do your best to follow these guidelines when submitting a bug-related issue or a feature request. It will make it easier for us to come back to you quickly and with good feedback.</p>"},{"location":"contributing/#did-you-find-a-bug","title":"Did you find a bug?","text":"<p><code>nearai</code> is alpha software. This means there is a possibility of encountering issues in the code. With help from users like you who report problems, we can make it more robust and reliable.</p> <p>Before you report an issue, we would really appreciate it if you could make sure the bug was not already reported (use the search bar on GitHub under Issues). Your issue should also be related to bugs in the library itself, and not your code.</p> <p>Once you've confirmed the bug hasn't already been reported, please include the following information in your issue so we can quickly resolve it:</p> <ul> <li>What did you do?</li> <li>What did you expect to happen?</li> <li>What happened instead?</li> <li>Your OS type and version and Python, PyTorch and versions where applicable.</li> <li>A short, self-contained, code snippet that allows us to reproduce the bug in   less than 30s.</li> <li>The full traceback if an exception is raised.</li> <li>Attach any other additional information, like screenshots, you think may help.</li> </ul> <p>To get the OS and software versions automatically, run the following command:</p> <pre><code>uname -a\n</code></pre>"},{"location":"contributing/#do-you-want-a-new-feature","title":"Do you want a new feature?","text":"<p>If there is a new feature you'd like to see in <code>nearai</code>, please open an issue and describe:</p> <ol> <li>What is the motivation behind this feature? Is it related to a problem or frustration with the library? Is it a feature related to something you need for a project? Is it something you worked on and think it could benefit the community?</li> </ol> <p>Whatever it is, we'd love to hear about it!</p> <ol> <li>Describe your requested feature in as much detail as possible. The more you can tell us about it, the better we'll be able to help you.</li> <li>Provide a code snippet that demonstrates the feature usage.</li> <li>If the feature is related to a paper, please include a link.</li> </ol>"},{"location":"contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Before writing any code, we strongly advise you to search through the existing PRs or issues to make sure nobody is already working on the same thing. If you are unsure, it is always a good idea to open an issue to get some feedback.</p> <p>You will need basic <code>git</code> proficiency to contribute to <code>nearai</code>. While <code>git</code> is not the easiest tool to use, it has the greatest manual. Type <code>git --help</code> in a shell and enjoy! If you prefer books, Pro Git is a very good reference. We also recommend asking any available AGI to help you with <code>git</code>.</p> <p>Follow the steps below to start contributing:</p> <ol> <li> <p>Fork the repository by    clicking on the Fork button on the repository's page. This creates a copy of the code    under your GitHub user account.</p> </li> <li> <p>Clone your fork to your local disk, and add the base repository as a remote:</p> </li> </ol> <pre><code>git clone git@github.com:&lt;your Github handle&gt;/nearai.git\ncd nearai\ngit remote add upstream https://github.com/nearai/nearai.git\n</code></pre> <ol> <li>Create a new branch to hold your development changes:</li> </ol> <pre><code>git checkout -b a-descriptive-name-for-my-changes\n</code></pre> <p>\ud83d\udea8 Do not work on the <code>main</code> branch!</p> <ol> <li> <p>Set up a development environment (follow steps in the README):</p> </li> <li> <p>Develop the features in your branch.</p> </li> </ol> <p>As you work on your code, you should make sure it functions as intended.</p> <p><code>nearai</code> relies on <code>ruff</code> and <code>mypy</code> to format and type check its source code    consistently. After you make your changes and are ready to PR them, ensure that    your code is formatted and type-checked by running:</p> <pre><code>./scripts/lint_format.sh\n</code></pre> <pre><code>./scripts/typecheck.sh\n</code></pre> <p>Once you're happy with your changes, add the changed files with <code>git add</code> and    record your changes locally with <code>git commit</code>:</p> <pre><code>git add modified_file.py\ngit commit\n</code></pre> <p>Please remember to write good commit    messages to clearly communicate the changes you made!</p> <p>To keep your copy of the code up to date with the original    repository, rebase your branch on <code>upstream/branch</code> before you open a pull request or if requested by a maintainer:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> <p>Push your changes to your branch:</p> <pre><code>git push -u origin a-descriptive-name-for-my-changes\n</code></pre> <p>If you've already opened a pull request, you'll need to force push with the <code>--force</code> flag. Otherwise, if the pull request hasn't been opened yet, you can just push your changes normally.</p> <ol> <li> <p>Now you can go to your fork of the repository on GitHub and click on Pull Request to open a pull request. Make sure you tick off all the boxes on our checklist below. When you're ready, you can send your changes to the project maintainers for review.</p> </li> <li> <p>It's ok if maintainers request changes, it happens to our core contributors    too! So everyone can see the changes in the pull request, work in your local    branch and push the changes to your fork. They will automatically appear in    the pull request.</p> </li> </ol>"},{"location":"contributing/#pull-request-checklist","title":"Pull request checklist","text":"<ul> <li>The pull request title should summarize your contribution.</li> <li>If your pull request addresses an issue, please mention the issue number in the pull request description to make sure they are linked (and people viewing the issue know you are working on it).</li> <li>To indicate a work in progress please prefix the title with <code>[WIP]</code>. These are useful to avoid duplicated work, and to differentiate it from PRs ready to be merged.</li> <li>Don't add any images, videos and other non-text files that'll significantly weigh down the repository. Instead, reference them by URL.</li> </ul>"},{"location":"contributing/#sync-a-forked-repository-with-upstream-main","title":"Sync a forked repository with upstream main","text":"<p>When updating the main branch of a forked repository, please follow these steps to avoid pinging the upstream repository which adds reference notes to each upstream PR, and sends unnecessary notifications to the developers involved in these PRs.</p> <ol> <li>When possible, avoid syncing with the upstream using a branch and PR on the forked repository. Instead, merge directly into the forked main.</li> <li>If a PR is absolutely necessary, use the following steps after checking out your branch:</li> </ol> <pre><code>git checkout -b your-branch-for-syncing\ngit pull --squash --no-commit upstream main\ngit commit -m '&lt;your message without GitHub references&gt;'\ngit push --set-upstream origin your-branch-for-syncing\n</code></pre>"},{"location":"login/","title":"NEAR Login","text":"<p>The NEAR Login feature accommodates various authentication scenarios, simplifying the process of signing NearAI requests using your NEAR Account.</p>"},{"location":"login/#scenarios","title":"Scenarios","text":""},{"location":"login/#1-web-login","title":"1. Web Login","text":"<p>This scenario sets up a local server on the user's machine. A <code>callbackUrl</code> is created to handle the response, and the user is redirected to <code>auth.near.ai</code>. The authentication signature is then saved upon receiving the callback. This is the simplest option for logging in from a machine where you are already signed in with your NEAR account, such as in a web browser.</p> <p>Command: <pre><code>nearai login\n</code></pre></p>"},{"location":"login/#2-remote-web-login","title":"2. Remote Web Login","text":"<p>In this scenario, a login link to <code>auth.near.ai</code> is generated without a callbackUrl. The NearAI CLI will display instructions to complete the login process. This option is convenient if you haven't used your NEAR account on the current machine but can copy the authorization link, complete the authorization on another machine, and then return to the original machine to execute the command for finalizing the login.</p> <p>Command: <pre><code>nearai login --remote\n</code></pre></p>"},{"location":"login/#3-login-with-near-account-id-only","title":"3. Login with NEAR Account ID Only","text":"<p>If you have previously logged in with a NEAR account using near-cli and have NEAR account credentials stored in the <code>~/.near-credentials/mainnet directory</code>, you can generate a signature and save the authentication data based on the stored NEAR keys.</p> <p>Command:: <pre><code>nearai login --accountId name.near\n</code></pre></p>"},{"location":"login/#4-login-with-account-id-and-private-key","title":"4. Login with Account ID and Private Key","text":"<p>Similar to the previous scenario, but allows for manual entry of the private key. This is useful if you want to authenticate without relying on stored credentials.</p> <p>Command::</p> <pre><code>nearai login --accountId name.near --privateKey key\n</code></pre>"},{"location":"login/#getting-started","title":"Getting Started","text":"<ul> <li> <p>Install the NearAI CLI: you can install it by following the instructions in the NearAI CLI documentation.</p> </li> <li> <p>Choose Your Login Scenario: Depending on your needs, use one of the commands above to Login with NEAR.</p> </li> <li> <p>Follow the Prompts: Follow any additional prompts or instructions provided by the NearAI CLI during the authentication process.</p> </li> </ul>"},{"location":"login/#login-status","title":"Login Status","text":"<p>To verify the current login status, you can use the following command:</p> <pre><code>nearai login status\n</code></pre>"}]}