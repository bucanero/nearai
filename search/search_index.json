{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Near AI","text":"<p>See the Near AI website for more on how we will achieve Open Source and User-owned AGI..</p>"},{"location":"#warning-alpha-software","title":"\u26a0\ufe0f Warning: Alpha software","text":"<p>NearAI is alpha software. This means that it is not yet ready for production use. We are actively working on improving the software and would love your help.</p> <p>If you would like to help build our future, please see our contributing guide.</p>"},{"location":"#about","title":"About","text":"<p>The NearAI project is a toolkit to help build, measure, and deploy AI systems focused on agents.</p> <p>NearAI consists of:</p> <ol> <li>app.near.ai a place to share agents, environments, and datasets; powered by the NearAI API.</li> <li>A CLI tool to interact with the NearAI registry, download agents, run them in environments, and more.</li> <li>A library with access to the same tools as the CLI, but to be used programmatically.</li> </ol> <p>This intro is split into two parts:</p> <ol> <li>Web Usage Guide</li> <li>CLI Usage Guide</li> </ol>"},{"location":"#web-usage-guide","title":"Web Usage Guide","text":"<p>https://app.near.ai allows you to use NEAR AI Hub directly from your browser. It currently offers a subset of the features available from the full Hub API.</p> <p>Features:</p> <ul> <li>NEAR AI Login<ul> <li>Login with your NEAR account using your favourite wallet provider.</li> </ul> </li> <li>Inference using the provider of your choice<ul> <li>Chose between the best open source models.</li> </ul> </li> <li>Read the registry:<ul> <li>Datasets - https://app.near.ai/datasets</li> <li>Benchmarks - https://app.near.ai/benchmarks</li> <li>Models - https://app.near.ai/models</li> <li>Agents - https://app.near.ai/agents</li> </ul> </li> <li> <p>View and manage your NEAR AI access keys.</p> <ul> <li>https://app.near.ai/settings</li> </ul> </li> </ul> <p>Source code in: demo</p> <p>For the api specification see openapi.json</p>"},{"location":"#cli-usage-guide","title":"CLI Usage Guide","text":""},{"location":"#registry","title":"Registry","text":"<p>The registry is a place to store models, datasets, agents, and environments (more types to come). You can upload and download items from the registry using the <code>nearai registry</code> command.</p> <p>About the registry</p> <p>The registry is backed by an S3 bucket with metadata stored in a database.</p> <p>To upload an item to the registry, you need a directory containing a metadata.json file. The metadata.json file describes the item, and all the other files in the directory make up the item. For an agent that is one <code>agent.py</code> file, for a dataset it may be hundreds of files.</p> <p>The metadata_template command will create a template for you to fill in. <pre><code>nearai registry metadata_template &lt;ITEM_LOCAL_DIRECTORY_PATH&gt; &lt;CATEGORY&gt; &lt;DESCRIPTION&gt;\n</code></pre> Fill in name, version, category and any other fields for which you have values. The notable categories are: <code>model</code>, <code>dataset</code>, <code>agent</code>.</p> <pre><code>{\n  \"category\": \"agent\",\n  \"description\": \"An example agent\",\n  \"tags\": [\n    \"python\"\n  ],\n  \"details\": {},\n  \"show_entry\": true,\n  \"name\": \"example-agent\",\n  \"version\": \"1\"\n}\n</code></pre> <p>Upload an element to the registry using:</p> <pre><code>nearai registry upload &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> <p>You can list elements in the registry using several filters:</p> <pre><code>nearai registry list  --namespace &lt;NAMESPACE&gt; \\\n                      --category &lt;CATEGORY&gt; \\\n                      --tags &lt;COMMA_SEPARTED_LIST_OF_TAGS&gt;\n                      --show_all\n</code></pre> <p>Check the item is available by listing all elements in the registry of that category:</p> <pre><code>nearai registry list --namespace near.ai --category agent\n</code></pre> <p>Show only items with the tag <code>quine</code> and <code>python</code>:</p> <pre><code>nearai registry list --tags quine,python\n</code></pre> <p>Download this element locally. To download refer to the item by //. Trying to download an item that was previously downloaded is a no-op. <pre><code>nearai registry download zavodil.near/hello-world-agent/1\n</code></pre> <p>Tip</p> <p>If you start downloading and item, and cancel the download midway, you should delete the folder at <code>~/.nearai/registry/</code> to trigger a new download.</p> <p>Update the metadata of an item with the registry update command <pre><code>nearai registry update &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> View info about an item with the registry info command <pre><code>nearai registry info &lt;ITEM_FULL_NAME&gt;\n</code></pre> <pre><code>nearai registry info zavodil.near/hello-world-agent/1\n</code></pre></p>"},{"location":"#agents","title":"Agents","text":"<p>See the Agents documentation and How to guide</p> <ul> <li>QUICKSTART: build and run a python agent on NearAI<ul> <li>Example agent.py</li> </ul> </li> <li>About Agents</li> <li>Agent Operation and Features</li> <li>Running an existing agent from the registry<ul> <li>Running an agent interactively</li> <li>Running an agent as a task</li> </ul> </li> <li>The Environment API<ul> <li>Additional environment tools</li> <li>Tool registry</li> </ul> </li> <li>Uploading an agent</li> <li>Running an agent remotely through the CLI</li> <li>Running an agent through the API</li> <li>Remote results<ul> <li>Signed messages</li> </ul> </li> </ul>"},{"location":"#benchmarking","title":"Benchmarking","text":"<p><code>nearai</code> includes a benchmarking tool to compare different agents and solvers on sets of reference evals (like <code>mpbb</code>).</p> Requirements for benchmarking with <code>nearai</code> <p>To create a benchmark, you need two things:</p> <pre><code>1. A dataset in your `nearai` dataset registry.\n2. A solver for the dataset implemented in the `nearai` library for said dataset.\n\nIf you have a dataset and a solver, you can run a benchmark.\n</code></pre> <p>To run a benchmark, you can use the <code>nearai benchmark</code> command. For example, to run the <code>mpbb</code> benchmark on the <code>llama-v3-70b-instruct</code>, you can use:</p> <pre><code>nearai benchmark run mbpp MBPPSolverStrategy \\\n    --model llama-v3-70b-instruct \\\n    --subset=train \\\n    --max_concurrent=1\n</code></pre>"},{"location":"#fine-tuning","title":"Fine tuning","text":"<p>We use <code>torchtune</code> for fine tuning models. The following command will start a fine tuning process using the <code>llama-3-8b-instruct</code> model and the <code>llama3</code> tokenizer.</p> <pre><code>poetry run python3 -m nearai finetune start \\\n    --model llama-3-8b-instruct \\\n    --format llama3-8b \\\n    --tokenizer tokenizers/llama-3 \\\n    --dataset &lt;your-dataset&gt; \\\n    --method nearai.finetune.text_completion.dataset \\\n    --column text \\\n    --split train \\\n    --num_procs 8\n</code></pre>"},{"location":"#submit-an-experiment","title":"Submit an experiment","text":"<p>To submit a new experiment run:</p> <pre><code>nearai submit --command &lt;COMMAND&gt; --name &lt;EXPERIMENT_NAME&gt; [--nodes &lt;NUMBER_OF_NODES&gt;] [--cluster &lt;CLUSTER&gt;]\n</code></pre> <p>This will submit a new experiment. The command must be executed from a folder that is a git repository (public github repositories, and private github repositories on the same organization as nearai are supported). The current commit will be used for running the command so make sure it is already available online. The diff with respect to the current commit will be applied remotely (new files are not included in the diff).</p> <p>On each node the environment variable <code>ASSIGNED_SUPERVISORS</code> will be available with a comma separated list of supervisors that are running the experiment. The current supervisor can be accessed via <code>nearai.CONFIG.supervisor_id</code>. See examples/prepare_data.py for an example.</p>"},{"location":"agents/","title":"Agents","text":"<p>Quickest start, this script runs the Quickstart commands below. <pre><code>docs/agent_quickstart.sh\n</code></pre></p>"},{"location":"agents/#quickstart-build-and-run-a-python-agent-on-nearai","title":"QUICKSTART: build and run a python agent on NearAI","text":"<ol> <li> <p>Install the NearAI CLI.</p> </li> <li> <p>Create a new folder for your agent; </p> <p>we recommend placing it inside your local registry <code>mkdir -p ~/.nearai/registry/example_agent</code>. </p> </li> <li> <p>Create a metadata.json file for your agent</p> </li> </ol> <p><code>nearai registry metadata_template ~/.nearai/registry/example_agent agent \"Example agent\"</code> and edit it.</p> <ol> <li> <p>Create an <code>agent.py</code> file in that folder.</p> <ul> <li>Write your agent, in agent.py, using the environment API described below.</li> <li>Or paste in the example agent.py below.</li> </ul> </li> <li> <p>Run your agent locally using the cli and passing it a folder to write output to.  <pre><code>nearai agent interactive example_agent /tmp/example_agent_run_1 --local\n</code></pre></p> </li> </ol>"},{"location":"agents/#example-agentpy","title":"Example agent.py","text":"<pre><code># In local interactive mode, the first user input is collected before the agent runs.\nprompt = {\"role\": \"system\", \"content\": \"You are a travel agent that helps users plan trips.\"}\nresult = env.completion([prompt] + env.list_messages())\nenv.add_message(\"agent\", result)\nenv.request_user_input()\n</code></pre>"},{"location":"agents/#about-agents","title":"About Agents","text":"<p>Agents are programs of varying complexity that can combine capabilities from across NearAI: authentication, inference, data stores, tools, apis, smart contract calls, reputation, compliance, proofs, and more.</p> <p>Agents run in response to messages, usually from a user or another agent. Messages can also be sent to an agent from other systems such as a scheduler or indexer.</p>"},{"location":"agents/#agent-operation-and-features","title":"Agent Operation and Features:","text":"<ul> <li><code>interactive</code> mode runs the agent in an infinite loop until: it is terminated by typing \"exit\" in the chat; is forcibly exited with a code; or stopped by the user with \"Ctrl+C\".</li> <li>The execution folder is optional; by default, the initial agent's folder may be used instead.</li> <li>If you use a folder other than the local registry, provide the full path to the agent instead of just the agent name.</li> </ul> <p>Command:  <pre><code>nearai agent interactive AGENT [EXECUTION_FOLDER] --local\n</code></pre> Example: <pre><code>nearai agent interactive example_agent --local\n</code></pre></p> <ul> <li>The agent can save temporary files to track the progress of a task from the user in case the dialogue execution is interrupted. By default, the entire message history is stored in a file named <code>chat.txt</code>. The agent can add messages there by using <code>env.add_message()</code>. Learn more about the environment API.</li> <li>During its operation, the agent creates a file named <code>.next_agent</code>, which stores the role of the next participant expected in the dialogue (either <code>user</code> or <code>agent</code>) during the next iteration of the loop. The agent can control this value using <code>env.set_next_actor()</code>.</li> <li>The agent can use local imports from the home folder or its subfolders. It is executed from a temporary folder within a temporary environment.</li> </ul>"},{"location":"agents/#running-an-existing-agent-from-the-registry","title":"Running an existing agent from the registry","text":"<p>List all agents <pre><code>nearai registry list --category agent\n</code></pre></p> <p>Download an agent by name <pre><code>nearai registry download flatirons.near/xela-agent/5\n</code></pre></p> <p>The <code>--force</code> flag allows you to overwrite the local agent with the version from the registry.</p> <p>\u26a0\ufe0f Warning: Review the agent code before running it!</p>"},{"location":"agents/#running-an-agent-interactively","title":"Running an agent interactively","text":"<p>Agents can be run interactively. The environment_path should be a folder where the agent chat record (chat.txt) and  other files can be written, usually <code>~/tmp/test-agents/&lt;AGENT_NAME&gt;-run-X</code>.</p> <ul> <li>command <code>nearai agent interactive AGENT ENVIRONMENT_PATH</code></li> <li>example  <pre><code>nearai agent interactive flatirons.near/xela-agent/5 /tmp/test-agents/xela-agent-run-1\n</code></pre></li> </ul>"},{"location":"agents/#running-an-agent-as-a-task","title":"Running an agent as a task","text":"<p>To run without user interaction pass the task input to the task</p> <ul> <li>command <code>nearai agent task &lt;AGENT&gt; &lt;INPUT&gt; &lt;ENVIRONMENT_PATH&gt;</code></li> <li>example  <pre><code>nearai agent task flatirons.near/xela-agent/5 \"Build a command line chess engine\" ~/tmp/test-agents/xela-agent/chess-engine\n</code></pre></li> </ul>"},{"location":"agents/#the-environment-api","title":"The Environment API","text":"<p>Your agent will receive an <code>env</code> object that has the following methods:</p> <ul> <li><code>request_user_input</code>: tell the agent that it is the user's turn, stop iterating.</li> <li><code>completion</code>: request inference completions from a provider and model. The model format can be either <code>PROVIDER::MODEL</code> or simply <code>MODEL</code>. By default the provider is <code>fireworks</code> and the model is <code>llama-v3p1-405b-instruct-long</code>. The model can be passed into <code>completion</code> function or as an agent metadata:    <pre><code>\"details\": {\n  \"agent\": {\n    \"defaults\": {\n      // All fields below are optional.\n      \"model\": \"llama-v3p1-405b-instruct-long\",\n      \"model_max_tokens\": 16384,\n      \"model_provider\": \"fireworks\",\n      \"model_temperature\": 1.0\n    }\n  }\n}\n</code></pre></li> <li><code>list_messages</code>: returns the list of messages in the conversation.  You have full control to add and remove messages from this list.</li> <li><code>add_message</code>: adds a message to the conversation. Arguments are role and content.    <pre><code>env.add_message(\"user\", \"Hello, I would like to travel to Paris\")\n</code></pre>    Normal roles are: <ul> <li><code>system</code>: usually your starting prompt</li> <li><code>agent</code>: messages from the agent (i.e. llm responses, programmatic responses)</li> <li><code>user</code>: messages from the user</li> </ul> </li> </ul>"},{"location":"agents/#additional-environment-tools","title":"Additional environment tools","text":"<p>There are several variations for completions:</p> <ul> <li><code>completions</code>: returns the full llm response for more control</li> <li><code>completion_and_run_tools</code>: Allows tools to be passed and processes any returned tool_calls by running the tool</li> <li><code>completions_and_run_tools</code>: Both tool calls and returns the full llm response.</li> </ul> <p>For working with files and running commands the following functions are also available on <code>env</code>. You may call these directly or use them through the tool_registry and passing them to a completions method.</p> <ul> <li><code>list_terminal_commands</code>: list the history of terminal commands</li> <li><code>list_files</code>: list the files in the current directory</li> <li><code>get_path</code>: get the path of the current directory</li> <li><code>read_file</code>: read a file</li> <li><code>write_file</code>: write to a file</li> <li><code>exec_command</code>: execute a terminal command</li> </ul>"},{"location":"agents/#tool-registry","title":"Tool registry","text":"<ul> <li><code>get_tool_registry</code>: returns the tool registry, a dictionary of tools that can be called by the agent. By default it is populated with the tools listed above for working with files and commands plus <code>request_user_input</code>. To register a function as a new tool, call <code>register_tool</code> on the tool registry, passing it your function.  <pre><code>def my_tool():\n    \"\"\"A simple tool that returns a string. This docstring helps the LLM know when to call the tool.\"\"\"\n    return \"Hello from my tool\"\n\nenv.get_tool_registry().register_tool(my_tool)\n\nresponse = env.completions_and_run_tools(\"llama-v3p1-405b-instruct-long\", messages, tools=get_tool_registry().get_all_tools())\n</code></pre></li> </ul>"},{"location":"agents/#logging","title":"Logging","text":"<ul> <li><code>add_system_log</code>: adds a system or environment log that is then saved into \"system_log.txt\".</li> <li><code>add_agent_log</code>: any agent logs may go here. Saved into \"agent_log.txt\".</li> </ul>"},{"location":"agents/#uploading-an-agent","title":"Uploading an agent","text":"<ul> <li>You need a folder with an <code>agent.py</code> file in it, <code>~/.nearai/registry/example_agent</code> in this example. </li> <li>The agent may consist of additional files in the folder.</li> </ul> <p>\u26a0\ufe0f Warning: All files in this folder will be uploaded to the registry!  * Add a metadata file <code>nearai registry metadata_template ~/.nearai/registry/example_agent</code>  * Edit the metadata file to include the agent details <pre><code>{\n  \"category\": \"agent\",\n  \"description\": \"An example agent that gives travel recommendations\",\n  \"tags\": [\n    \"python\",\n    \"travel\"\n  ],\n  \"details\": {\n    \"agent\": {\n       \"defaults\": {\n         // All fields below are optional.\n         \"model\": \"llama-v3p1-405b-instruct-long\",\n         \"model_max_tokens\": 16384,\n         \"model_provider\": \"fireworks\",\n         \"model_temperature\": 1.0\n       }\n     }\n  },\n  \"show_entry\": true,\n  \"name\": \"example-travel-agent\",\n  \"version\": \"0.0.5\"\n}\n</code></pre></p> <ul> <li>You must be logged in with NEAR to upload, <code>nearai login</code></li> <li>Upload the agent <code>nearai registry upload ~/.nearai/registry/example_agent</code></li> </ul> <p>\u26a0\ufe0f You can't remove or overwrite a file once it's uploaded, but you can hide the entire agent by setting the <code>\"show_entry\": false</code> field.</p>"},{"location":"agents/#running-an-agent-remotely-through-the-cli","title":"Running an agent remotely through the CLI","text":"<p>Agents can be run through the CLI using the <code>nearai agent run_remote</code> command. A new message can be passed with the new_message argument. A starting environment (state) can be passed with the environment_id argument.</p> <pre><code>  nearai agent run_remote flatirons.near/example-travel-agent/1 \\\n  new_message=\"I would like to travel to Brazil\"\n</code></pre> <p>This environment already contains a request to travel to Paris and an agent response. A new_message could be included to further refine the request. In this example without a new_message the agent will reprocess the previous response and follow up about travel to Paris.</p> <pre><code>  nearai agent run_remote flatirons.near/example-travel-agent/1 \\\n  environment_id=\"flatirons.near/environment_run_flatirons.near_example-travel-agent_1_1c82938c55fc43e492882ee938c6356a/0\"\n</code></pre>"},{"location":"agents/#running-an-agent-through-the-api","title":"Running an agent through the API","text":"<p>Agents can be run through the <code>/agent/runs</code> endpoint.  You will need to pass a signed message to authenticate. This example uses the credentials written by <code>nearai login</code> to your <code>~/.nearai/config.json</code> file.</p> <pre><code>auth_json=$(jq -c '.auth' ~/.nearai/config.json);\n\ncurl \"https://api.near.ai/v1/agent/runs\" \\\n      -X POST \\\n      --header 'Content-Type: application/json' \\\n      --header \"Authorization: Bearer $auth_json\" \\\n-d @- &lt;&lt;'EOF'\n  {\n    \"agent_id\": \"flatirons.near/xela-agent/5\",\n    \"new_message\":\"Build a backgammon game\",\n    \"max_iterations\": \"2\"\n  }\nEOF\n</code></pre> <p>The full message will look like this. An <code>environment_id</code> param can also be passed to continue a previous run.  <pre><code>curl \"https://api.near.ai/v1/agent/runs\" \\\n      -X POST \\\n      --header 'Content-Type: application/json' \\\n      --header 'Authorization: Bearer {\"account_id\":\"your_account.near\",\"public_key\":\"ed25519:YOUR_PUBLIC_KEY\",\"signature\":\"A_REAL_SIGNATURE\",\"callback_url\":\"https://app.near.ai/\",\"message\":\"Welcome to NEAR AI Hub!\",\"recipient\":\"ai.near\",\"nonce\":\"A_UNIQUE_NONCE_FOR_THIS_SIGNATURE\"}' \\\n-d @- &lt;&lt;'EOF'\n  {\n    \"agent_id\": \"flatirons.near/xela-agent/5\",\n    \"environment_id\": \"a_previous_environment_id\",\n    \"new_message\":\"Build a backgammon game\", \n    \"max_iterations\": \"2\"\n  }\nEOF\n</code></pre></p>"},{"location":"agents/#remote-results","title":"Remote results","text":"<p>The results of both run_remote and the /agent/runs endpoint are either an error or the resulting environment state.</p> <p>Agent run finished. New environment is \"flatirons.near/environment_run_flatirons.near_example-travel-agent_1_1c82938c55fc43e492882ee938c6356a/0\"</p> <p>To view the resulting state, download the <code>environment.tar.gz</code> file from the registry and extract it. <pre><code>nearai registry download flatirons.near/environment_run_flatirons.near_example-travel-agent_1_1c82938c55fc43e492882ee938c6356a/0\n</code></pre></p>"},{"location":"agents/#signed-messages","title":"Signed messages","text":"<p>NearAI authentication is through a Signed Message: a payload signed by a Near Account private key. (How to Login with NEAR)</p> <p>If you need one for manual testing, you can <code>nearai login</code> then copy the auth section from your <code>~/.nearai/config.json</code>.</p> <p>To add signed message login to an application, see the code in hub demo near.tsx.</p>"},{"location":"agents/#saving-and-loading-environment-runs","title":"Saving and loading environment runs","text":"<p>When you are logged in, by default, each environment run is saved to the registry. You can disable this by adding the cli flag <code>--record_run=False</code>.</p> <p>An environment run can be loaded by using the <code>--load_env</code> flag and passing it a registry identifier <code>--load_env=near.ai/environment_run_test_6a8393b51d4141c7846247bdf4086038/1.0.0</code>.</p> <p>To list environment identifiers use the command <code>nearai registry list --tags=environment</code>.</p> <p>A run can be named by passing a name to the record_run flag <code>--record_run=\"my special run\"</code>.</p> <p>Environment runs can be loaded by passing the name of a previous run to the --load_env flag like <code>--load_env=\"my special run\"</code>.</p>"},{"location":"agents/#running-an-agent-with-environment-variables","title":"Running an agent with Environment Variables","text":"<p>When working with agents, managing configuration parameters through environment variables can provide a flexible way to adjust settings without altering the underlying code. This approach is particularly useful when dealing with sensitive information or configuration that needs to be customized without modifying the agent's codebase.</p>"},{"location":"agents/#storing-environment-variables","title":"Storing Environment Variables","text":"<p>Environment variables can be stored in a metadata.json file. Here\u2019s an example of how to structure this file:</p> <pre><code>{\n  \"details\": {\n    \"env_vars\": {\n      \"id\": \"id_from_env\",\n      \"key\": \"key_from_env\"\n    }\n  }\n}\n</code></pre>"},{"location":"agents/#accessing-environment-variables-in-code","title":"Accessing Environment Variables in Code","text":"<p>In your agent\u2019s code, you can access these environment variables using Python\u2019s os module or by accessing the env_vars dictionary directly.</p> <p>To retrieve an environment variable in the agent code:</p> <pre><code># Using os.environ\nimport os\nvalue = os.environ.get('VARIABLE_NAME', None)\n\n# Or using globals()\nvalue = globals()['env'].env_vars.get('VARIABLE_NAME')\n</code></pre> <p>This allows users to fork the agent, modify the environment variables in <code>metadata.json</code>, and achieve the desired behavior without changing the code itself.</p>"},{"location":"agents/#running-the-agent-with-environment-variables","title":"Running the agent with Environment Variables","text":"<p>You can also pass environment variables directly when launching the agent. This can be useful for overriding or extending the variables defined in <code>metadata.json</code> and handling Sensitive Information: If your agent needs to interact with APIs or services that require secret keys or credentials, you can pass these as environment variables instead of hardcoding them. This ensures that sensitive information is not exposed in publicly accessible code.</p> <p>To run the agent with environment variables, use the following command:</p> <pre><code>nearai agent interactive user.near/agent/1 --local --env_vars='{\"foo\":\"bar\"}'\n</code></pre>"},{"location":"agents/#example","title":"Example","text":"<p>Consider an agent <code>zavodil.near/test-env-agent/1</code> that has configurable environment variables.</p>"},{"location":"agents/#agent-frameworks","title":"Agent Frameworks","text":"<p>Agents can be built using a variety of frameworks and libraries. A particular bundle of libraries is given a name, such as <code>langgraph-1-4</code>. To run your agent remotely with a particular framework, set the framework name in the agent's metadata.json file. <pre><code>{\n  \"details\": {\n    \"agent\": {\n      \"framework\": \"langgraph-1-4\"\n    }\n  }\n}\n</code></pre> For local development, you can install any libraries you would like to use by adding them to top level <code>pyproject.toml</code>.</p> <p>Current frameworks can be found in the repo's frameworks folder.</p>"},{"location":"agents/#langchain-langgraph","title":"LangChain / LangGraph","text":"<p>The example agent langgraph-min-example has metadata that specifies the <code>langgraph-1-4</code> framework to run on langgraph version 1.4. In addition, the agent.py  code contains an adaptor class, <code>AgentChatModel</code> that maps LangChain inference operations to <code>env.completions</code> calls.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nearai","title":"nearai","text":""},{"location":"api/#nearai.parse_location","title":"parse_location","text":"<pre><code>parse_location(entry_location: str) -&gt; EntryLocation\n</code></pre> <p>Create a EntryLocation from a string in the format namespace/name/version.</p> Source code in <code>nearai/lib.py</code> <pre><code>def parse_location(entry_location: str) -&gt; EntryLocation:\n    \"\"\"Create a EntryLocation from a string in the format namespace/name/version.\"\"\"\n    match = entry_location_pattern.match(entry_location)\n\n    if match is None:\n        raise ValueError(f\"Invalid entry format: {entry_location}. Should have the format &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;\")\n\n    return EntryLocation(\n        namespace=match.group(\"namespace\"),\n        name=match.group(\"name\"),\n        version=match.group(\"version\"),\n    )\n</code></pre>"},{"location":"api/#nearai.agent","title":"agent","text":""},{"location":"api/#nearai.agent.Agent","title":"Agent","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/agent.py</code> <pre><code>class Agent(object):\n    def __init__(self, path: str):  # noqa: D107\n        self.name: str = \"\"\n        self.version: str = \"\"\n        self.env_vars: Dict[str, Any] = {}\n\n        self.model = \"\"\n        self.model_provider = \"\"\n        self.model_temperature: Optional[float] = None\n        self.model_max_tokens: Optional[int] = None\n        self.welcome_title: Optional[str] = None\n        self.welcome_description: Optional[str] = None\n\n        self.path = path\n        self.load_agent_metadata()\n        self.namespace = get_namespace(Path(self.path))\n\n        temp_dir = os.path.join(tempfile.gettempdir(), str(int(time.time())))\n\n        # Copy all agent files including subfolders\n        shutil.copytree(path, temp_dir, dirs_exist_ok=True)\n\n        self.temp_dir = temp_dir\n\n    def load_agent_metadata(self) -&gt; None:\n        \"\"\"Load agent details from metadata.json.\"\"\"\n        metadata_path = os.path.join(self.path, \"metadata.json\")\n        check_metadata(Path(metadata_path))\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n            self.metadata = metadata\n\n            try:\n                self.name = metadata[\"name\"]\n                self.version = metadata[\"version\"]\n            except KeyError as e:\n                raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n            details = metadata.get(\"details\", {})\n            agent = details.get(\"agent\", {})\n            welcome = agent.get(\"welcome\", {})\n\n            self.env_vars = details.get(\"env_vars\", {})\n            self.welcome_title = welcome.get(\"title\")\n            self.welcome_description = welcome.get(\"description\")\n\n            if agent_metadata := details.get(\"agent\", None):\n                if defaults := agent_metadata.get(\"defaults\", None):\n                    self.model = defaults.get(\"model\", self.model)\n                    self.model_provider = defaults.get(\"model_provider\", self.model_provider)\n                    self.model_temperature = defaults.get(\"model_temperature\", self.model_temperature)\n                    self.model_max_tokens = defaults.get(\"model_max_tokens\", self.model_max_tokens)\n\n        if not self.version or not self.name:\n            raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n\n    def run(self, env: Any, task: Optional[str] = None) -&gt; None:  # noqa: D102\n        if not os.path.exists(os.path.join(self.path, AGENT_FILENAME)):\n            raise ValueError(\"Agent run error: {AGENT_FILENAME} does not exist\")\n\n        # combine agent.env_vars and env.env_vars\n        total_env_vars = {**self.env_vars, **env.env_vars}\n\n        # save os env vars\n        os.environ.update(total_env_vars)\n        # save env.env_vars\n        env.env_vars = total_env_vars\n\n        context = {\"env\": env, \"agent\": self, \"task\": task}\n\n        original_cwd = os.getcwd()\n        try:\n            os.chdir(self.temp_dir)\n            sys.path.insert(0, self.temp_dir)\n            runpy.run_path(AGENT_FILENAME, init_globals=context, run_name=\"__main__\")\n        finally:\n            os.chdir(original_cwd)\n            sys.path.pop(0)\n</code></pre>"},{"location":"api/#nearai.agent.Agent.load_agent_metadata","title":"load_agent_metadata","text":"<pre><code>load_agent_metadata() -&gt; None\n</code></pre> <p>Load agent details from metadata.json.</p> Source code in <code>nearai/agent.py</code> <pre><code>def load_agent_metadata(self) -&gt; None:\n    \"\"\"Load agent details from metadata.json.\"\"\"\n    metadata_path = os.path.join(self.path, \"metadata.json\")\n    check_metadata(Path(metadata_path))\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n        self.metadata = metadata\n\n        try:\n            self.name = metadata[\"name\"]\n            self.version = metadata[\"version\"]\n        except KeyError as e:\n            raise ValueError(f\"Missing key in metadata: {e}\") from None\n\n        details = metadata.get(\"details\", {})\n        agent = details.get(\"agent\", {})\n        welcome = agent.get(\"welcome\", {})\n\n        self.env_vars = details.get(\"env_vars\", {})\n        self.welcome_title = welcome.get(\"title\")\n        self.welcome_description = welcome.get(\"description\")\n\n        if agent_metadata := details.get(\"agent\", None):\n            if defaults := agent_metadata.get(\"defaults\", None):\n                self.model = defaults.get(\"model\", self.model)\n                self.model_provider = defaults.get(\"model_provider\", self.model_provider)\n                self.model_temperature = defaults.get(\"model_temperature\", self.model_temperature)\n                self.model_max_tokens = defaults.get(\"model_max_tokens\", self.model_max_tokens)\n\n    if not self.version or not self.name:\n        raise ValueError(\"Both 'version' and 'name' must be non-empty in metadata.\")\n</code></pre>"},{"location":"api/#nearai.cli","title":"cli","text":""},{"location":"api/#nearai.cli.AgentCli","title":"AgentCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class AgentCli:\n    def inspect(self, path: str) -&gt; None:\n        \"\"\"Inspect environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.inspect()\n\n    def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n        \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.save_folder(name)\n\n    def save_from_history(self, name: Optional[str] = None) -&gt; None:\n        \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.\n\n        This command:\n        1. Finds agent task runs (must contain non-empty chat.txt)\n        2. Writes start_command.log files\n        3. Saves to registry\n\n        Only 'interactive' is supported.\n        Assumes format:\n        ' &lt;line_number&gt;  &lt;program_name&gt; agent interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n        Run:\n        $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00\n        \"\"\"  # noqa: E501\n        from nearai.environment import Environment\n\n        env = Environment(\"/\", [], CONFIG, create_files=False)\n        # Read from stdin (piped input)\n        lines = sys.stdin.readlines()\n        env.save_from_history(lines, name)\n\n    def interactive(\n        self,\n        agents: str,\n        path: Optional[str] = \"\",\n        record_run: str = \"true\",\n        env_vars: Optional[Dict[str, Any]] = None,\n        load_env: str = \"\",\n        local: bool = False,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        print_system_log: bool = True,\n    ) -&gt; None:\n        \"\"\"Runs agent interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n        if not path:\n            if len(_agents) == 1:\n                path = _agents[0].path\n            else:\n                raise ValueError(\"Local path is required when running multiple agents\")\n        env = Environment(\n            path,\n            _agents,\n            CONFIG,\n            env_vars=env_vars,\n            tool_resources=tool_resources,\n            print_system_log=print_system_log,\n        )\n\n        env.run_interactive(record_run, load_env)\n\n    def task(\n        self,\n        agents: str,\n        task: str,\n        path: Optional[str] = \"\",\n        max_iterations: int = 10,\n        record_run: str = \"true\",\n        env_vars: Optional[Dict[str, Any]] = None,\n        load_env: str = \"\",\n        local: bool = False,\n    ) -&gt; None:\n        \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n        if not path:\n            if len(_agents) == 1:\n                path = _agents[0].path\n            else:\n                raise ValueError(\"Local path is required when running multiple agents\")\n        env = Environment(path, _agents, CONFIG, env_vars=env_vars)\n        env.run_task(task, record_run, load_env, max_iterations)\n\n    def run_remote(\n        self,\n        agents: str,\n        new_message: str = \"\",\n        environment_id: str = \"\",\n        provider: str = \"aws_lambda\",\n        params: object = None,\n    ) -&gt; None:\n        \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n        if not CONFIG.auth:\n            print(\"Please login with `nearai login`\")\n            return\n        if provider != \"aws_lambda\":\n            print(f\"Provider {provider} is not supported.\")\n            return\n        if not params:\n            params = {\"max_iterations\": 2}\n        wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n        try:\n            new_environment = wrapper.invoke_function(\n                \"agent-runner-docker\",\n                {\n                    \"agents\": agents,\n                    \"environment_id\": environment_id,\n                    \"auth\": CONFIG.auth.model_dump(),\n                    \"new_message\": new_message,\n                    \"params\": params,\n                },\n            )\n            print(f\"Agent run finished. New environment is {new_environment}\")\n        except Exception as e:\n            print(f\"Error running agent remotely: {e}\")\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.inspect","title":"inspect","text":"<pre><code>inspect(path: str) -&gt; None\n</code></pre> <p>Inspect environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def inspect(self, path: str) -&gt; None:\n    \"\"\"Inspect environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.inspect()\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.interactive","title":"interactive","text":"<pre><code>interactive(agents: str, path: Optional[str] = '', record_run: str = 'true', env_vars: Optional[Dict[str, Any]] = None, load_env: str = '', local: bool = False, tool_resources: Optional[Dict[str, Any]] = None, print_system_log: bool = True) -&gt; None\n</code></pre> <p>Runs agent interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def interactive(\n    self,\n    agents: str,\n    path: Optional[str] = \"\",\n    record_run: str = \"true\",\n    env_vars: Optional[Dict[str, Any]] = None,\n    load_env: str = \"\",\n    local: bool = False,\n    tool_resources: Optional[Dict[str, Any]] = None,\n    print_system_log: bool = True,\n) -&gt; None:\n    \"\"\"Runs agent interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n    if not path:\n        if len(_agents) == 1:\n            path = _agents[0].path\n        else:\n            raise ValueError(\"Local path is required when running multiple agents\")\n    env = Environment(\n        path,\n        _agents,\n        CONFIG,\n        env_vars=env_vars,\n        tool_resources=tool_resources,\n        print_system_log=print_system_log,\n    )\n\n    env.run_interactive(record_run, load_env)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.run_remote","title":"run_remote","text":"<pre><code>run_remote(agents: str, new_message: str = '', environment_id: str = '', provider: str = 'aws_lambda', params: object = None) -&gt; None\n</code></pre> <p>Invoke a Container based AWS lambda function to run agents on a given environment.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run_remote(\n    self,\n    agents: str,\n    new_message: str = \"\",\n    environment_id: str = \"\",\n    provider: str = \"aws_lambda\",\n    params: object = None,\n) -&gt; None:\n    \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n    if not CONFIG.auth:\n        print(\"Please login with `nearai login`\")\n        return\n    if provider != \"aws_lambda\":\n        print(f\"Provider {provider} is not supported.\")\n        return\n    if not params:\n        params = {\"max_iterations\": 2}\n    wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n    try:\n        new_environment = wrapper.invoke_function(\n            \"agent-runner-docker\",\n            {\n                \"agents\": agents,\n                \"environment_id\": environment_id,\n                \"auth\": CONFIG.auth.model_dump(),\n                \"new_message\": new_message,\n                \"params\": params,\n            },\n        )\n        print(f\"Agent run finished. New environment is {new_environment}\")\n    except Exception as e:\n        print(f\"Error running agent remotely: {e}\")\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.save_folder","title":"save_folder","text":"<pre><code>save_folder(path: str, name: Optional[str] = None) -&gt; None\n</code></pre> <p>Saves all subfolders with agent task runs (must contain non-empty chat.txt).</p> Source code in <code>nearai/cli.py</code> <pre><code>def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n    \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.save_folder(name)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.save_from_history","title":"save_from_history","text":"<pre><code>save_from_history(name: Optional[str] = None) -&gt; None\n</code></pre> <p>Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.</p> <p>This command: 1. Finds agent task runs (must contain non-empty chat.txt) 2. Writes start_command.log files 3. Saves to registry</p> <p>Only 'interactive' is supported. Assumes format: '   agent interactive  ' Run: $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00 Source code in <code>nearai/cli.py</code> <pre><code>def save_from_history(self, name: Optional[str] = None) -&gt; None:\n    \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai agent save_from_history --help.\n\n    This command:\n    1. Finds agent task runs (must contain non-empty chat.txt)\n    2. Writes start_command.log files\n    3. Saves to registry\n\n    Only 'interactive' is supported.\n    Assumes format:\n    ' &lt;line_number&gt;  &lt;program_name&gt; agent interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n    Run:\n    $ history | grep \"agent interactive\" | sed \"s:~:$HOME:g\" | nearai agent save_from_history environment_interactive_runs_from_lambda_00\n    \"\"\"  # noqa: E501\n    from nearai.environment import Environment\n\n    env = Environment(\"/\", [], CONFIG, create_files=False)\n    # Read from stdin (piped input)\n    lines = sys.stdin.readlines()\n    env.save_from_history(lines, name)\n</code></pre>"},{"location":"api/#nearai.cli.AgentCli.task","title":"task","text":"<pre><code>task(agents: str, task: str, path: Optional[str] = '', max_iterations: int = 10, record_run: str = 'true', env_vars: Optional[Dict[str, Any]] = None, load_env: str = '', local: bool = False) -&gt; None\n</code></pre> <p>Runs agent non interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def task(\n    self,\n    agents: str,\n    task: str,\n    path: Optional[str] = \"\",\n    max_iterations: int = 10,\n    record_run: str = \"true\",\n    env_vars: Optional[Dict[str, Any]] = None,\n    load_env: str = \"\",\n    local: bool = False,\n) -&gt; None:\n    \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n    if not path:\n        if len(_agents) == 1:\n            path = _agents[0].path\n        else:\n            raise ValueError(\"Local path is required when running multiple agents\")\n    env = Environment(path, _agents, CONFIG, env_vars=env_vars)\n    env.run_task(task, record_run, load_env, max_iterations)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli","title":"BenchmarkCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class BenchmarkCli:\n    def __init__(self):\n        \"\"\"Initialize Benchmark API.\"\"\"\n        self.client = BenchmarkApi()\n\n    def _get_or_create_benchmark(self, benchmark_name: str, solver_name: str, args: Dict[str, Any], force: bool) -&gt; int:\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n        namespace = CONFIG.auth.account_id\n\n        # Sort the args to have a consistent representation.\n        solver_args = json.dumps(OrderedDict(sorted(args.items())))\n\n        benchmark_id = self.client.get_benchmark_v1_benchmark_get_get(\n            namespace=namespace,\n            benchmark_name=benchmark_name,\n            solver_name=solver_name,\n            solver_args=solver_args,\n        )\n\n        if benchmark_id == -1 or force:\n            benchmark_id = self.client.create_benchmark_v1_benchmark_create_get(\n                benchmark_name=benchmark_name,\n                solver_name=solver_name,\n                solver_args=solver_args,\n            )\n\n        assert benchmark_id != -1\n        return benchmark_id\n\n    def run(\n        self,\n        dataset: str,\n        solver_strategy: str,\n        max_concurrent: int = -1,\n        force: bool = False,\n        subset: Optional[str] = None,\n        check_compatibility: bool = True,\n        record: bool = False,\n        **solver_args: Any,\n    ) -&gt; None:\n        \"\"\"Run benchmark on a dataset with a solver strategy.\n\n        It will cache the results in the database and subsequent runs will pull the results from the cache.\n        If force is set to True, it will run the benchmark again and update the cache.\n        \"\"\"\n        from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n        from nearai.dataset import load_dataset\n        from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n        args = dict(solver_args)\n        if subset is not None:\n            args[\"subset\"] = subset\n\n        benchmark_id = self._get_or_create_benchmark(\n            benchmark_name=dataset,\n            solver_name=solver_strategy,\n            args=args,\n            force=force,\n        )\n\n        solver_strategy_class: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n        assert (\n            solver_strategy_class\n        ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n\n        name = dataset\n        if solver_strategy_class.scoring_method == SolverScoringMethod.Custom:\n            dataset = str(get_dataset(dataset))\n        else:\n            dataset = load_dataset(dataset)\n\n        solver_strategy_obj: SolverStrategy = solver_strategy_class(dataset_ref=dataset, **solver_args)  # type: ignore\n        if check_compatibility:\n            assert name in solver_strategy_obj.compatible_datasets() or any(\n                map(lambda n: n in name, solver_strategy_obj.compatible_datasets())\n            ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n        be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n        cpu_count = os.cpu_count()\n        max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n        be.run(max_concurrent=max_concurrent, record=record)\n\n    def list(\n        self,\n        namespace: Optional[str] = None,\n        benchmark: Optional[str] = None,\n        solver: Optional[str] = None,\n        args: Optional[str] = None,\n        total: int = 32,\n        offset: int = 0,\n    ):\n        \"\"\"List all executed benchmarks.\"\"\"\n        result = self.client.list_benchmarks_v1_benchmark_list_get(\n            namespace=namespace,\n            benchmark_name=benchmark,\n            solver_name=solver,\n            solver_args=args,\n            total=total,\n            offset=offset,\n        )\n\n        header = [\"id\", \"namespace\", \"benchmark\", \"solver\", \"args\", \"score\", \"solved\", \"total\"]\n        table = []\n        for benchmark_output in result:\n            score = 100 * benchmark_output.solved / benchmark_output.total\n            table.append(\n                [\n                    fill(str(benchmark_output.id)),\n                    fill(benchmark_output.namespace),\n                    fill(benchmark_output.benchmark),\n                    fill(benchmark_output.solver),\n                    fill(benchmark_output.args),\n                    fill(f\"{score:.2f}%\"),\n                    fill(str(benchmark_output.solved)),\n                    fill(str(benchmark_output.total)),\n                ]\n            )\n\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize Benchmark API.</p> Source code in <code>nearai/cli.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize Benchmark API.\"\"\"\n    self.client = BenchmarkApi()\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.list","title":"list","text":"<pre><code>list(namespace: Optional[str] = None, benchmark: Optional[str] = None, solver: Optional[str] = None, args: Optional[str] = None, total: int = 32, offset: int = 0)\n</code></pre> <p>List all executed benchmarks.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    namespace: Optional[str] = None,\n    benchmark: Optional[str] = None,\n    solver: Optional[str] = None,\n    args: Optional[str] = None,\n    total: int = 32,\n    offset: int = 0,\n):\n    \"\"\"List all executed benchmarks.\"\"\"\n    result = self.client.list_benchmarks_v1_benchmark_list_get(\n        namespace=namespace,\n        benchmark_name=benchmark,\n        solver_name=solver,\n        solver_args=args,\n        total=total,\n        offset=offset,\n    )\n\n    header = [\"id\", \"namespace\", \"benchmark\", \"solver\", \"args\", \"score\", \"solved\", \"total\"]\n    table = []\n    for benchmark_output in result:\n        score = 100 * benchmark_output.solved / benchmark_output.total\n        table.append(\n            [\n                fill(str(benchmark_output.id)),\n                fill(benchmark_output.namespace),\n                fill(benchmark_output.benchmark),\n                fill(benchmark_output.solver),\n                fill(benchmark_output.args),\n                fill(f\"{score:.2f}%\"),\n                fill(str(benchmark_output.solved)),\n                fill(str(benchmark_output.total)),\n            ]\n        )\n\n    print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.run","title":"run","text":"<pre><code>run(dataset: str, solver_strategy: str, max_concurrent: int = -1, force: bool = False, subset: Optional[str] = None, check_compatibility: bool = True, record: bool = False, **solver_args: Any) -&gt; None\n</code></pre> <p>Run benchmark on a dataset with a solver strategy.</p> <p>It will cache the results in the database and subsequent runs will pull the results from the cache. If force is set to True, it will run the benchmark again and update the cache.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run(\n    self,\n    dataset: str,\n    solver_strategy: str,\n    max_concurrent: int = -1,\n    force: bool = False,\n    subset: Optional[str] = None,\n    check_compatibility: bool = True,\n    record: bool = False,\n    **solver_args: Any,\n) -&gt; None:\n    \"\"\"Run benchmark on a dataset with a solver strategy.\n\n    It will cache the results in the database and subsequent runs will pull the results from the cache.\n    If force is set to True, it will run the benchmark again and update the cache.\n    \"\"\"\n    from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n    from nearai.dataset import load_dataset\n    from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n    args = dict(solver_args)\n    if subset is not None:\n        args[\"subset\"] = subset\n\n    benchmark_id = self._get_or_create_benchmark(\n        benchmark_name=dataset,\n        solver_name=solver_strategy,\n        args=args,\n        force=force,\n    )\n\n    solver_strategy_class: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n    assert (\n        solver_strategy_class\n    ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n\n    name = dataset\n    if solver_strategy_class.scoring_method == SolverScoringMethod.Custom:\n        dataset = str(get_dataset(dataset))\n    else:\n        dataset = load_dataset(dataset)\n\n    solver_strategy_obj: SolverStrategy = solver_strategy_class(dataset_ref=dataset, **solver_args)  # type: ignore\n    if check_compatibility:\n        assert name in solver_strategy_obj.compatible_datasets() or any(\n            map(lambda n: n in name, solver_strategy_obj.compatible_datasets())\n        ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n    be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n    cpu_count = os.cpu_count()\n    max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n    be.run(max_concurrent=max_concurrent, record=record)\n</code></pre>"},{"location":"api/#nearai.cli.CLI","title":"CLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class CLI:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.registry = RegistryCli()\n        self.login = LoginCLI()\n        self.logout = LogoutCLI()\n        self.hub = HubCLI()\n\n        self.config = ConfigCli()\n        self.benchmark = BenchmarkCli()\n        self.evaluation = EvaluationCli()\n        self.agent = AgentCli()\n        self.finetune = FinetuneCli()\n        self.tensorboard = TensorboardCli()\n        self.vllm = VllmCli()\n\n    def location(self) -&gt; None:  # noqa: D102\n        \"\"\"Show location where nearai is installed.\"\"\"\n        from nearai import cli_path\n\n        print(cli_path())\n\n    def version(self):\n        \"\"\"Show nearai version.\"\"\"\n        print(importlib.metadata.version(\"nearai\"))\n</code></pre>"},{"location":"api/#nearai.cli.CLI.location","title":"location","text":"<pre><code>location() -&gt; None\n</code></pre> <p>Show location where nearai is installed.</p> Source code in <code>nearai/cli.py</code> <pre><code>def location(self) -&gt; None:  # noqa: D102\n    \"\"\"Show location where nearai is installed.\"\"\"\n    from nearai import cli_path\n\n    print(cli_path())\n</code></pre>"},{"location":"api/#nearai.cli.CLI.version","title":"version","text":"<pre><code>version()\n</code></pre> <p>Show nearai version.</p> Source code in <code>nearai/cli.py</code> <pre><code>def version(self):\n    \"\"\"Show nearai version.\"\"\"\n    print(importlib.metadata.version(\"nearai\"))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli","title":"ConfigCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class ConfigCli:\n    def set(self, key: str, value: str, local: bool = False) -&gt; None:\n        \"\"\"Add key-value pair to the config file.\"\"\"\n        update_config(key, value, local)\n\n    def get(self, key: str) -&gt; None:\n        \"\"\"Get value of a key in the config file.\"\"\"\n        print(CONFIG.get(key))\n\n    def show(self) -&gt; None:  # noqa: D102\n        for key, value in asdict(CONFIG).items():\n            print(f\"{key}: {value}\")\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.get","title":"get","text":"<pre><code>get(key: str) -&gt; None\n</code></pre> <p>Get value of a key in the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def get(self, key: str) -&gt; None:\n    \"\"\"Get value of a key in the config file.\"\"\"\n    print(CONFIG.get(key))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.set","title":"set","text":"<pre><code>set(key: str, value: str, local: bool = False) -&gt; None\n</code></pre> <p>Add key-value pair to the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def set(self, key: str, value: str, local: bool = False) -&gt; None:\n    \"\"\"Add key-value pair to the config file.\"\"\"\n    update_config(key, value, local)\n</code></pre>"},{"location":"api/#nearai.cli.EvaluationCli","title":"EvaluationCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class EvaluationCli:\n    def table(\n        self,\n        namespace: str = \"\",\n        tags: str = \"\",\n        all_key_columns: bool = False,\n        all_metrics: bool = False,\n        num_columns: int = 6,\n        metric_name_max_length: int = 30,\n    ) -&gt; None:\n        \"\"\"Prints table of evaluations.\"\"\"\n        rows, columns, important_columns = evaluation_table(namespace, tags)\n        print_evaluation_table(\n            rows, columns, important_columns, all_key_columns, all_metrics, num_columns, metric_name_max_length\n        )\n</code></pre>"},{"location":"api/#nearai.cli.EvaluationCli.table","title":"table","text":"<pre><code>table(namespace: str = '', tags: str = '', all_key_columns: bool = False, all_metrics: bool = False, num_columns: int = 6, metric_name_max_length: int = 30) -&gt; None\n</code></pre> <p>Prints table of evaluations.</p> Source code in <code>nearai/cli.py</code> <pre><code>def table(\n    self,\n    namespace: str = \"\",\n    tags: str = \"\",\n    all_key_columns: bool = False,\n    all_metrics: bool = False,\n    num_columns: int = 6,\n    metric_name_max_length: int = 30,\n) -&gt; None:\n    \"\"\"Prints table of evaluations.\"\"\"\n    rows, columns, important_columns = evaluation_table(namespace, tags)\n    print_evaluation_table(\n        rows, columns, important_columns, all_key_columns, all_metrics, num_columns, metric_name_max_length\n    )\n</code></pre>"},{"location":"api/#nearai.cli.HubCLI","title":"HubCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class HubCLI:\n    def chat(self, **kwargs):\n        \"\"\"Chat with model from NearAI hub.\n\n        Args:\n        ----\n            query (str): User's query to model\n            endpoint (str): NearAI HUB's url\n            model (str): Name of a model\n            provider (str): Name of a provider\n            info (bool): Display system info\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        hub = Hub(CONFIG)\n        hub.chat(kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.HubCLI.chat","title":"chat","text":"<pre><code>chat(**kwargs)\n</code></pre> <p>Chat with model from NearAI hub.</p> <pre><code>query (str): User's query to model\nendpoint (str): NearAI HUB's url\nmodel (str): Name of a model\nprovider (str): Name of a provider\ninfo (bool): Display system info\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def chat(self, **kwargs):\n    \"\"\"Chat with model from NearAI hub.\n\n    Args:\n    ----\n        query (str): User's query to model\n        endpoint (str): NearAI HUB's url\n        model (str): Name of a model\n        provider (str): Name of a provider\n        info (bool): Display system info\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    hub = Hub(CONFIG)\n    hub.chat(kwargs)\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI","title":"LoginCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class LoginCLI:\n    def __call__(self, **kwargs):\n        \"\"\"Login with NEAR Mainnet account.\n\n        Args:\n        ----\n            remote (bool): Remote login allows signing message with NEAR Account on a remote machine\n            auth_url (str): Url to the auth portal\n            accountId (str): AccountId in .near-credentials folder to signMessage\n            privateKey (str): Private Key to sign a message\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        from nearai.login import generate_and_save_signature, login_with_file_credentials, login_with_near_auth\n\n        remote = kwargs.get(\"remote\", False)\n        account_id = kwargs.get(\"accountId\", None)\n        private_key = kwargs.get(\"privateKey\", None)\n\n        if not remote and account_id and private_key:\n            generate_and_save_signature(account_id, private_key)\n        elif not remote and account_id:\n            login_with_file_credentials(account_id)\n        else:\n            auth_url = kwargs.get(\"auth_url\", \"https://auth.near.ai\")\n            login_with_near_auth(remote, auth_url)\n\n    def status(self):\n        \"\"\"Load NEAR account authorization data.\"\"\"\n        from nearai.login import print_login_status\n\n        print_login_status()\n\n    def save(self, **kwargs):\n        \"\"\"Save NEAR account authorization data.\n\n        Args:\n        ----\n            accountId (str): Near Account\n            signature (str): Signature\n            publicKey (str): Public Key used to sign\n            callbackUrl (str): Callback Url\n            nonce (str): nonce\n            kwargs (Dict[str, Any]): All cli keyword arguments\n\n        \"\"\"\n        from nearai.login import update_auth_config\n\n        account_id = kwargs.get(\"accountId\")\n        signature = kwargs.get(\"signature\")\n        public_key = kwargs.get(\"publicKey\")\n        callback_url = kwargs.get(\"callbackUrl\")\n        nonce = kwargs.get(\"nonce\")\n\n        if account_id and signature and public_key and callback_url and nonce:\n            update_auth_config(account_id, signature, public_key, callback_url, nonce)\n        else:\n            print(\"Missing data\")\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.__call__","title":"__call__","text":"<pre><code>__call__(**kwargs)\n</code></pre> <p>Login with NEAR Mainnet account.</p> <pre><code>remote (bool): Remote login allows signing message with NEAR Account on a remote machine\nauth_url (str): Url to the auth portal\naccountId (str): AccountId in .near-credentials folder to signMessage\nprivateKey (str): Private Key to sign a message\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def __call__(self, **kwargs):\n    \"\"\"Login with NEAR Mainnet account.\n\n    Args:\n    ----\n        remote (bool): Remote login allows signing message with NEAR Account on a remote machine\n        auth_url (str): Url to the auth portal\n        accountId (str): AccountId in .near-credentials folder to signMessage\n        privateKey (str): Private Key to sign a message\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    from nearai.login import generate_and_save_signature, login_with_file_credentials, login_with_near_auth\n\n    remote = kwargs.get(\"remote\", False)\n    account_id = kwargs.get(\"accountId\", None)\n    private_key = kwargs.get(\"privateKey\", None)\n\n    if not remote and account_id and private_key:\n        generate_and_save_signature(account_id, private_key)\n    elif not remote and account_id:\n        login_with_file_credentials(account_id)\n    else:\n        auth_url = kwargs.get(\"auth_url\", \"https://auth.near.ai\")\n        login_with_near_auth(remote, auth_url)\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.save","title":"save","text":"<pre><code>save(**kwargs)\n</code></pre> <p>Save NEAR account authorization data.</p> <pre><code>accountId (str): Near Account\nsignature (str): Signature\npublicKey (str): Public Key used to sign\ncallbackUrl (str): Callback Url\nnonce (str): nonce\nkwargs (Dict[str, Any]): All cli keyword arguments\n</code></pre> Source code in <code>nearai/cli.py</code> <pre><code>def save(self, **kwargs):\n    \"\"\"Save NEAR account authorization data.\n\n    Args:\n    ----\n        accountId (str): Near Account\n        signature (str): Signature\n        publicKey (str): Public Key used to sign\n        callbackUrl (str): Callback Url\n        nonce (str): nonce\n        kwargs (Dict[str, Any]): All cli keyword arguments\n\n    \"\"\"\n    from nearai.login import update_auth_config\n\n    account_id = kwargs.get(\"accountId\")\n    signature = kwargs.get(\"signature\")\n    public_key = kwargs.get(\"publicKey\")\n    callback_url = kwargs.get(\"callbackUrl\")\n    nonce = kwargs.get(\"nonce\")\n\n    if account_id and signature and public_key and callback_url and nonce:\n        update_auth_config(account_id, signature, public_key, callback_url, nonce)\n    else:\n        print(\"Missing data\")\n</code></pre>"},{"location":"api/#nearai.cli.LoginCLI.status","title":"status","text":"<pre><code>status()\n</code></pre> <p>Load NEAR account authorization data.</p> Source code in <code>nearai/cli.py</code> <pre><code>def status(self):\n    \"\"\"Load NEAR account authorization data.\"\"\"\n    from nearai.login import print_login_status\n\n    print_login_status()\n</code></pre>"},{"location":"api/#nearai.cli.LogoutCLI","title":"LogoutCLI","text":"Source code in <code>nearai/cli.py</code> <pre><code>class LogoutCLI:\n    def __call__(self, **kwargs):\n        \"\"\"Clear NEAR account auth data.\"\"\"\n        from nearai.config import load_config_file, save_config_file\n\n        config = load_config_file()\n        if not config.get(\"auth\") or not config[\"auth\"].get(\"account_id\"):\n            print(\"Auth data does not exist.\")\n        else:\n            config.pop(\"auth\", None)\n            save_config_file(config)\n            print(\"Auth data removed\")\n</code></pre>"},{"location":"api/#nearai.cli.LogoutCLI.__call__","title":"__call__","text":"<pre><code>__call__(**kwargs)\n</code></pre> <p>Clear NEAR account auth data.</p> Source code in <code>nearai/cli.py</code> <pre><code>def __call__(self, **kwargs):\n    \"\"\"Clear NEAR account auth data.\"\"\"\n    from nearai.config import load_config_file, save_config_file\n\n    config = load_config_file()\n    if not config.get(\"auth\") or not config[\"auth\"].get(\"account_id\"):\n        print(\"Auth data does not exist.\")\n    else:\n        config.pop(\"auth\", None)\n        save_config_file(config)\n        print(\"Auth data removed\")\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli","title":"RegistryCli","text":"Source code in <code>nearai/cli.py</code> <pre><code>class RegistryCli:\n    def info(self, entry: str) -&gt; None:\n        \"\"\"Show information about an item.\"\"\"\n        entry_location = parse_location(entry)\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            print(f\"Entry {entry} not found.\")\n            return\n\n        print(metadata.model_dump_json(indent=2))\n\n    def metadata_template(self, local_path: str = \".\", category: str = \"\", description: str = \"\"):\n        \"\"\"Create a metadata template.\"\"\"\n        path = Path(local_path)\n\n        metadata_path = path / \"metadata.json\"\n\n        # Get the name of the folder\n        folder_name = path.name\n\n        with open(metadata_path, \"w\") as f:\n            metadata: Dict[str, Any] = {\n                \"name\": folder_name,\n                \"version\": \"0.0.1\",\n                \"description\": description,\n                \"category\": category,\n                \"tags\": [],\n                \"details\": {},\n                \"show_entry\": True,\n            }\n\n            if category == \"agent\":\n                metadata[\"details\"][\"agent\"] = {}\n                metadata[\"details\"][\"agent\"][\"defaults\"] = {\n                    \"model\": DEFAULT_MODEL,\n                    \"model_provider\": DEFAULT_PROVIDER,\n                    \"model_temperature\": DEFAULT_MODEL_TEMPERATURE,\n                    \"model_max_tokens\": DEFAULT_MODEL_MAX_TOKENS,\n                }\n\n            json.dump(metadata, f, indent=2)\n\n    def list(\n        self,\n        namespace: str = \"\",\n        category: str = \"\",\n        tags: str = \"\",\n        total: int = 32,\n        offset: int = 0,\n        show_all: bool = False,\n        show_latest_version: bool = True,\n        star: str = \"\",\n    ) -&gt; None:\n        \"\"\"List available items.\"\"\"\n        # Make sure tags is a comma-separated list of tags\n        tags_l = parse_tags(tags)\n        tags = \",\".join(tags_l)\n\n        entries = registry.list(\n            namespace=namespace,\n            category=category,\n            tags=tags,\n            total=total + 1,\n            offset=offset,\n            show_all=show_all,\n            show_latest_version=show_latest_version,\n            starred_by=star,\n        )\n\n        more_rows = len(entries) &gt; total\n        entries = entries[:total]\n\n        header = [\"entry\", \"category\", \"description\", \"tags\"]\n\n        table = []\n        for entry in entries:\n            table.append(\n                [\n                    fill(f\"{entry.namespace}/{entry.name}/{entry.version}\"),\n                    fill(entry.category, 20),\n                    fill(entry.description, 50),\n                    fill(\", \".join(entry.tags), 20),\n                ]\n            )\n\n        if more_rows:\n            table.append([\"...\", \"...\", \"...\", \"...\"])\n\n        print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n\n    def update(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Update metadata of a registry item.\"\"\"\n        path = Path(local_path)\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n        check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.account_id\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=metadata.pop(\"name\"),\n                version=metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(metadata)\n        result = registry.update(entry_location, entry_metadata)\n        print(json.dumps(result, indent=2))\n\n    def upload(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Upload item to the registry.\"\"\"\n        registry.upload(Path(local_path), show_progress=True)\n\n    def download(self, entry_location: str, force: bool = False) -&gt; None:\n        \"\"\"Download item.\"\"\"\n        registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.download","title":"download","text":"<pre><code>download(entry_location: str, force: bool = False) -&gt; None\n</code></pre> <p>Download item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def download(self, entry_location: str, force: bool = False) -&gt; None:\n    \"\"\"Download item.\"\"\"\n    registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.info","title":"info","text":"<pre><code>info(entry: str) -&gt; None\n</code></pre> <p>Show information about an item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def info(self, entry: str) -&gt; None:\n    \"\"\"Show information about an item.\"\"\"\n    entry_location = parse_location(entry)\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        print(f\"Entry {entry} not found.\")\n        return\n\n    print(metadata.model_dump_json(indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.list","title":"list","text":"<pre><code>list(namespace: str = '', category: str = '', tags: str = '', total: int = 32, offset: int = 0, show_all: bool = False, show_latest_version: bool = True, star: str = '') -&gt; None\n</code></pre> <p>List available items.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    namespace: str = \"\",\n    category: str = \"\",\n    tags: str = \"\",\n    total: int = 32,\n    offset: int = 0,\n    show_all: bool = False,\n    show_latest_version: bool = True,\n    star: str = \"\",\n) -&gt; None:\n    \"\"\"List available items.\"\"\"\n    # Make sure tags is a comma-separated list of tags\n    tags_l = parse_tags(tags)\n    tags = \",\".join(tags_l)\n\n    entries = registry.list(\n        namespace=namespace,\n        category=category,\n        tags=tags,\n        total=total + 1,\n        offset=offset,\n        show_all=show_all,\n        show_latest_version=show_latest_version,\n        starred_by=star,\n    )\n\n    more_rows = len(entries) &gt; total\n    entries = entries[:total]\n\n    header = [\"entry\", \"category\", \"description\", \"tags\"]\n\n    table = []\n    for entry in entries:\n        table.append(\n            [\n                fill(f\"{entry.namespace}/{entry.name}/{entry.version}\"),\n                fill(entry.category, 20),\n                fill(entry.description, 50),\n                fill(\", \".join(entry.tags), 20),\n            ]\n        )\n\n    if more_rows:\n        table.append([\"...\", \"...\", \"...\", \"...\"])\n\n    print(tabulate(table, headers=header, tablefmt=\"simple_grid\"))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.metadata_template","title":"metadata_template","text":"<pre><code>metadata_template(local_path: str = '.', category: str = '', description: str = '')\n</code></pre> <p>Create a metadata template.</p> Source code in <code>nearai/cli.py</code> <pre><code>def metadata_template(self, local_path: str = \".\", category: str = \"\", description: str = \"\"):\n    \"\"\"Create a metadata template.\"\"\"\n    path = Path(local_path)\n\n    metadata_path = path / \"metadata.json\"\n\n    # Get the name of the folder\n    folder_name = path.name\n\n    with open(metadata_path, \"w\") as f:\n        metadata: Dict[str, Any] = {\n            \"name\": folder_name,\n            \"version\": \"0.0.1\",\n            \"description\": description,\n            \"category\": category,\n            \"tags\": [],\n            \"details\": {},\n            \"show_entry\": True,\n        }\n\n        if category == \"agent\":\n            metadata[\"details\"][\"agent\"] = {}\n            metadata[\"details\"][\"agent\"][\"defaults\"] = {\n                \"model\": DEFAULT_MODEL,\n                \"model_provider\": DEFAULT_PROVIDER,\n                \"model_temperature\": DEFAULT_MODEL_TEMPERATURE,\n                \"model_max_tokens\": DEFAULT_MODEL_MAX_TOKENS,\n            }\n\n        json.dump(metadata, f, indent=2)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.update","title":"update","text":"<pre><code>update(local_path: str = '.') -&gt; None\n</code></pre> <p>Update metadata of a registry item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def update(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Update metadata of a registry item.\"\"\"\n    path = Path(local_path)\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n    check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.account_id\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=metadata.pop(\"name\"),\n            version=metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(metadata)\n    result = registry.update(entry_location, entry_metadata)\n    print(json.dumps(result, indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.upload","title":"upload","text":"<pre><code>upload(local_path: str = '.') -&gt; None\n</code></pre> <p>Upload item to the registry.</p> Source code in <code>nearai/cli.py</code> <pre><code>def upload(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Upload item to the registry.\"\"\"\n    registry.upload(Path(local_path), show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.check_update","title":"check_update","text":"<pre><code>check_update()\n</code></pre> <p>Check if there is a new version of nearai CLI available.</p> Source code in <code>nearai/cli.py</code> <pre><code>def check_update():\n    \"\"\"Check if there is a new version of nearai CLI available.\"\"\"\n    try:\n        api = DefaultApi()\n        latest = api.version_v1_version_get()\n        current = importlib.metadata.version(\"nearai\")\n\n        if latest != current:\n            print(f\"New version of nearai CLI available: {latest}. Current version: {current}\")\n            print(\"Run `pip install --upgrade nearai` to update.\")\n\n    except Exception as _:\n        pass\n</code></pre>"},{"location":"api/#nearai.completion","title":"completion","text":""},{"location":"api/#nearai.completion.InferenceRouter","title":"InferenceRouter","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/completion.py</code> <pre><code>class InferenceRouter(object):\n    def __init__(self, config: Config) -&gt; None:  # noqa: D107\n        self._config = config\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n        self._endpoint: Any\n\n    def get_auth_str(self, auth: Optional[AuthData] = None) -&gt; str:\n        \"\"\"Get authentication string from provided auth or config object.\n\n        Args:\n        ----\n            auth (Optional[AuthData]): Authentication data. If None, uses config auth.\n\n        Returns:\n        -------\n            str: JSON string containing authentication data.\n\n        \"\"\"\n        _auth = auth\n        if auth is None:\n            _auth = self._config.auth\n\n        bearer_data = {\n            key: getattr(_auth, key)\n            for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n        }\n\n        return json.dumps(bearer_data)\n\n    def completions(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        stream: bool = False,\n        temperature: Optional[float] = None,\n        auth: Optional[AuthData] = None,\n        max_tokens: Optional[int] = None,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Takes a `model` and `messages` and returns completions.\n\n        `model` can be:\n        1. full path `provider::model_full_path`.\n        2. `model_short_name`. Default provider will be used.\n        \"\"\"\n        if self._config.nearai_hub is None:\n            raise ValueError(\"Missing NearAI Hub config\")\n        provider, _ = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n        auth_bearer_token = self.get_auth_str(auth)\n\n        if temperature is None:\n            temperature = DEFAULT_MODEL_TEMPERATURE\n\n        if max_tokens is None:\n            max_tokens = DEFAULT_MODEL_MAX_TOKENS\n\n        # NOTE(#246): this is to disable \"Provider List\" messages.\n        litellm.suppress_debug_info = True\n\n        self._endpoint = lambda model, messages, stream, temperature, max_tokens, **kwargs: litellm_completion(\n            model,\n            messages,\n            stream=stream,\n            custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n            input_cost_per_token=0,\n            output_cost_per_token=0,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            base_url=self._config.nearai_hub.base_url,\n            provider=provider,\n            api_key=auth_bearer_token,\n            **kwargs,\n        )\n\n        try:\n            result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n                model=model, messages=messages, stream=stream, temperature=temperature, max_tokens=max_tokens, **kwargs\n            )\n        except Exception as e:\n            raise ValueError(f\"Bad request: {e}\") from None\n\n        return result\n\n    def query_vector_store(\n        self, vector_store_id: str, query: str, auth: Optional[AuthData] = None\n    ) -&gt; List[SimilaritySearch]:\n        \"\"\"Query a vector store.\"\"\"\n        if self._config.nearai_hub is None:\n            raise ValueError(\"Missing NearAI Hub config\")\n\n        auth_bearer_token = self.get_auth_str(auth)\n\n        headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {auth_bearer_token}\"}\n\n        data = {\"query\": query}\n\n        endpoint = f\"{self._config.nearai_hub.base_url}/vector_stores/{vector_store_id}/search\"\n\n        try:\n            response = requests.post(endpoint, headers=headers, json=data)\n            response.raise_for_status()\n            return response.json()\n        except requests.RequestException as e:\n            raise ValueError(f\"Error querying vector store: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter.completions","title":"completions","text":"<pre><code>completions(model: str, messages: Iterable[ChatCompletionMessageParam], stream: bool = False, temperature: Optional[float] = None, auth: Optional[AuthData] = None, max_tokens: Optional[int] = None, **kwargs: Any) -&gt; Union[ModelResponse, CustomStreamWrapper]\n</code></pre> <p>Takes a <code>model</code> and <code>messages</code> and returns completions.</p> <p><code>model</code> can be: 1. full path <code>provider::model_full_path</code>. 2. <code>model_short_name</code>. Default provider will be used.</p> Source code in <code>nearai/completion.py</code> <pre><code>def completions(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    stream: bool = False,\n    temperature: Optional[float] = None,\n    auth: Optional[AuthData] = None,\n    max_tokens: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Takes a `model` and `messages` and returns completions.\n\n    `model` can be:\n    1. full path `provider::model_full_path`.\n    2. `model_short_name`. Default provider will be used.\n    \"\"\"\n    if self._config.nearai_hub is None:\n        raise ValueError(\"Missing NearAI Hub config\")\n    provider, _ = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n    auth_bearer_token = self.get_auth_str(auth)\n\n    if temperature is None:\n        temperature = DEFAULT_MODEL_TEMPERATURE\n\n    if max_tokens is None:\n        max_tokens = DEFAULT_MODEL_MAX_TOKENS\n\n    # NOTE(#246): this is to disable \"Provider List\" messages.\n    litellm.suppress_debug_info = True\n\n    self._endpoint = lambda model, messages, stream, temperature, max_tokens, **kwargs: litellm_completion(\n        model,\n        messages,\n        stream=stream,\n        custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n        input_cost_per_token=0,\n        output_cost_per_token=0,\n        temperature=temperature,\n        max_tokens=max_tokens,\n        base_url=self._config.nearai_hub.base_url,\n        provider=provider,\n        api_key=auth_bearer_token,\n        **kwargs,\n    )\n\n    try:\n        result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n            model=model, messages=messages, stream=stream, temperature=temperature, max_tokens=max_tokens, **kwargs\n        )\n    except Exception as e:\n        raise ValueError(f\"Bad request: {e}\") from None\n\n    return result\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter.get_auth_str","title":"get_auth_str","text":"<pre><code>get_auth_str(auth: Optional[AuthData] = None) -&gt; str\n</code></pre> <p>Get authentication string from provided auth or config object.</p> <pre><code>auth (Optional[AuthData]): Authentication data. If None, uses config auth.\n</code></pre> <pre><code>str: JSON string containing authentication data.\n</code></pre> Source code in <code>nearai/completion.py</code> <pre><code>def get_auth_str(self, auth: Optional[AuthData] = None) -&gt; str:\n    \"\"\"Get authentication string from provided auth or config object.\n\n    Args:\n    ----\n        auth (Optional[AuthData]): Authentication data. If None, uses config auth.\n\n    Returns:\n    -------\n        str: JSON string containing authentication data.\n\n    \"\"\"\n    _auth = auth\n    if auth is None:\n        _auth = self._config.auth\n\n    bearer_data = {\n        key: getattr(_auth, key)\n        for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n    }\n\n    return json.dumps(bearer_data)\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter.query_vector_store","title":"query_vector_store","text":"<pre><code>query_vector_store(vector_store_id: str, query: str, auth: Optional[AuthData] = None) -&gt; List[SimilaritySearch]\n</code></pre> <p>Query a vector store.</p> Source code in <code>nearai/completion.py</code> <pre><code>def query_vector_store(\n    self, vector_store_id: str, query: str, auth: Optional[AuthData] = None\n) -&gt; List[SimilaritySearch]:\n    \"\"\"Query a vector store.\"\"\"\n    if self._config.nearai_hub is None:\n        raise ValueError(\"Missing NearAI Hub config\")\n\n    auth_bearer_token = self.get_auth_str(auth)\n\n    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {auth_bearer_token}\"}\n\n    data = {\"query\": query}\n\n    endpoint = f\"{self._config.nearai_hub.base_url}/vector_stores/{vector_store_id}/search\"\n\n    try:\n        response = requests.post(endpoint, headers=headers, json=data)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        raise ValueError(f\"Error querying vector store: {e}\") from None\n</code></pre>"},{"location":"api/#nearai.config","title":"config","text":""},{"location":"api/#nearai.config.AuthData","title":"AuthData","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/config.py</code> <pre><code>class AuthData(BaseModel):\n    account_id: str\n    signature: str\n    public_key: str\n    callback_url: str\n    nonce: str\n    recipient: str\n    message: str\n\n    def generate_bearer_token(self):\n        \"\"\"Generates a JSON-encoded bearer token containing authentication data.\"\"\"\n        required_keys = {\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"}\n\n        for key in required_keys:\n            if getattr(self, key) is None:\n                raise ValueError(f\"Missing required auth data: {key}\")\n\n        bearer_data = {key: getattr(self, key) for key in required_keys}\n\n        return json.dumps(bearer_data)\n</code></pre>"},{"location":"api/#nearai.config.AuthData.generate_bearer_token","title":"generate_bearer_token","text":"<pre><code>generate_bearer_token()\n</code></pre> <p>Generates a JSON-encoded bearer token containing authentication data.</p> Source code in <code>nearai/config.py</code> <pre><code>def generate_bearer_token(self):\n    \"\"\"Generates a JSON-encoded bearer token containing authentication data.\"\"\"\n    required_keys = {\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"}\n\n    for key in required_keys:\n        if getattr(self, key) is None:\n            raise ValueError(f\"Missing required auth data: {key}\")\n\n    bearer_data = {key: getattr(self, key) for key in required_keys}\n\n    return json.dumps(bearer_data)\n</code></pre>"},{"location":"api/#nearai.config.Config","title":"Config","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/config.py</code> <pre><code>class Config(BaseModel):\n    origin: Optional[str] = None\n    api_url: Optional[str] = \"https://api.near.ai\"\n    inference_url: str = \"http://localhost:5000/v1/\"\n    inference_api_key: str = \"n/a\"\n    nearai_hub: Optional[NearAiHubConfig] = NearAiHubConfig()\n    confirm_commands: bool = True\n    auth: Optional[AuthData] = None\n\n    def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n        \"\"\"Update the config with the given dictionary.\"\"\"\n        dict_repr = self.model_dump()\n        keys = list(map(map_key, dict_repr.keys()))\n\n        for key in keys:\n            value = extra_config.get(key, None)\n\n            if value:\n                # This will skip empty values, even if they are set in the `extra_config`\n                dict_repr[key] = value\n\n        return Config.model_validate(dict_repr)\n\n    def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n        \"\"\"Get the value of a key in the config if it exists.\"\"\"\n        return getattr(self, key, default)\n</code></pre>"},{"location":"api/#nearai.config.Config.get","title":"get","text":"<pre><code>get(key: str, default: Optional[Any] = None) -&gt; Optional[Any]\n</code></pre> <p>Get the value of a key in the config if it exists.</p> Source code in <code>nearai/config.py</code> <pre><code>def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n    \"\"\"Get the value of a key in the config if it exists.\"\"\"\n    return getattr(self, key, default)\n</code></pre>"},{"location":"api/#nearai.config.Config.update_with","title":"update_with","text":"<pre><code>update_with(extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; Config\n</code></pre> <p>Update the config with the given dictionary.</p> Source code in <code>nearai/config.py</code> <pre><code>def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n    \"\"\"Update the config with the given dictionary.\"\"\"\n    dict_repr = self.model_dump()\n    keys = list(map(map_key, dict_repr.keys()))\n\n    for key in keys:\n        value = extra_config.get(key, None)\n\n        if value:\n            # This will skip empty values, even if they are set in the `extra_config`\n            dict_repr[key] = value\n\n    return Config.model_validate(dict_repr)\n</code></pre>"},{"location":"api/#nearai.config.NearAiHubConfig","title":"NearAiHubConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>NearAiHub Config.</p> <p>login_with_near (Optional[bool]): Indicates whether to attempt login using Near Auth.</p> <p>api_key (Optional[str]): The API key to use if Near Auth is not being utilized</p> <p>base_url (Optional[str]): NearAI Hub url</p> <p>default_provider (Optional[str]): Default provider name</p> <p>default_model (Optional[str]): Default model name</p> <p>custom_llm_provider (Optional[str]): provider to be used by litellm proxy</p> Source code in <code>nearai/config.py</code> <pre><code>class NearAiHubConfig(BaseModel):\n    \"\"\"NearAiHub Config.\n\n    login_with_near (Optional[bool]): Indicates whether to attempt login using Near Auth.\n\n    api_key (Optional[str]): The API key to use if Near Auth is not being utilized\n\n    base_url (Optional[str]): NearAI Hub url\n\n    default_provider (Optional[str]): Default provider name\n\n    default_model (Optional[str]): Default model name\n\n    custom_llm_provider (Optional[str]): provider to be used by litellm proxy\n    \"\"\"\n\n    base_url: str = \"https://api.near.ai/v1\"\n    default_provider: str = DEFAULT_PROVIDER\n    default_model: str = DEFAULT_PROVIDER_MODEL\n    custom_llm_provider: str = \"openai\"\n    login_with_near: Optional[bool] = True\n    api_key: Optional[str] = \"\"\n</code></pre>"},{"location":"api/#nearai.dataset","title":"dataset","text":""},{"location":"api/#nearai.dataset.get_dataset","title":"get_dataset","text":"<pre><code>get_dataset(name: str, verbose: bool = True) -&gt; Path\n</code></pre> <p>Download the dataset from the registry and download it locally if it hasn't been downloaded yet.</p> <p>:param name: The name of the entry to download the dataset. The format should be namespace/name/version. :return: The path to the downloaded dataset</p> Source code in <code>nearai/dataset.py</code> <pre><code>def get_dataset(name: str, verbose: bool = True) -&gt; Path:\n    \"\"\"Download the dataset from the registry and download it locally if it hasn't been downloaded yet.\n\n    :param name: The name of the entry to download the dataset. The format should be namespace/name/version.\n    :return: The path to the downloaded dataset\n    \"\"\"\n    return registry.download(name, verbose=verbose)\n</code></pre>"},{"location":"api/#nearai.dataset.load_dataset","title":"load_dataset","text":"<pre><code>load_dataset(alias_or_name: str, verbose: bool = True) -&gt; Union[Dataset, DatasetDict]\n</code></pre> <p>Load a dataset from the registry.</p> Source code in <code>nearai/dataset.py</code> <pre><code>def load_dataset(alias_or_name: str, verbose: bool = True) -&gt; Union[Dataset, DatasetDict]:\n    \"\"\"Load a dataset from the registry.\"\"\"\n    path = get_dataset(alias_or_name, verbose=verbose)\n    return load_from_disk(path.as_posix())\n</code></pre>"},{"location":"api/#nearai.environment","title":"environment","text":""},{"location":"api/#nearai.environment.Environment","title":"Environment","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/environment.py</code> <pre><code>class Environment(object):\n    def __init__(  # noqa: D107\n        self,\n        path: str,\n        agents: List[Agent],\n        config: Config,\n        create_files: bool = True,\n        env_vars: Optional[Dict[str, Any]] = None,\n        tool_resources: Optional[Dict[str, Any]] = None,\n        print_system_log: bool = False,\n    ) -&gt; None:\n        self._path = path\n        self._agents = agents\n        self._done = False\n        self._config = config\n        self._inference = InferenceRouter(config)\n        self._tools = ToolRegistry()\n        self.register_standard_tools()\n        self.env_vars: Dict[str, Any] = env_vars if env_vars else {}\n        self._last_used_model = \"\"\n        self.tool_resources: Dict[str, Any] = tool_resources if tool_resources else {}\n        self.print_system_log = print_system_log\n\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        if create_files:\n            os.makedirs(self._path, exist_ok=True)\n            open(os.path.join(self._path, CHAT_FILENAME), \"a\").close()\n        os.chdir(self._path)\n\n    @staticmethod\n    def _generate_run_id() -&gt; str:\n        return uuid.uuid4().hex\n\n    def get_tool_registry(self) -&gt; ToolRegistry:  # noqa: D102\n        \"\"\"Returns the tool registry, a dictionary of tools that can be called by the agent.\"\"\"\n        return self._tools\n\n    def register_standard_tools(self) -&gt; None:  # noqa: D102\n        reg = self.get_tool_registry()\n        reg.register_tool(self.exec_command)\n        reg.register_tool(self.read_file)\n        reg.register_tool(self.write_file)\n        reg.register_tool(self.request_user_input)\n        reg.register_tool(self.list_files)\n        reg.register_tool(self.verify_message)\n        reg.register_tool(self.query_vector_store)\n\n    def add_message(self, role: str, message: str, filename: str = CHAT_FILENAME, **kwargs: Any) -&gt; None:\n        \"\"\"Add a message to the chat file.\"\"\"\n        with open(os.path.join(self._path, filename), \"a\") as f:\n            f.write(json.dumps({\"role\": role, \"content\": message, **kwargs}) + DELIMITER)\n\n    def add_system_log(self, log: str, level: int = logging.INFO) -&gt; None:\n        \"\"\"Add system log with timestamp and log level.\"\"\"\n        logger = logging.getLogger(\"system_logger\")\n        if not logger.handlers:\n            # Configure the logger if it hasn't been set up yet\n            logger.setLevel(logging.DEBUG)\n            file_handler = logging.FileHandler(os.path.join(self._path, SYSTEM_LOG_FILENAME))\n            formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n            if self.print_system_log:\n                console_handler = logging.StreamHandler()\n                console_handler.setFormatter(formatter)\n                logger.addHandler(console_handler)\n\n        # Log the message\n        logger.log(level, log)\n\n    def add_agent_log(self, log: str, level: int = logging.INFO) -&gt; None:\n        \"\"\"Add agent log with timestamp and log level.\"\"\"\n        logger = logging.getLogger(\"agent_logger\")\n        if not logger.handlers:\n            # Configure the logger if it hasn't been set up yet\n            logger.setLevel(logging.DEBUG)\n            file_handler = logging.FileHandler(os.path.join(self._path, AGENT_LOG_FILENAME))\n            formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n            file_handler.setFormatter(formatter)\n            logger.addHandler(file_handler)\n\n        # Log the message\n        logger.log(level, log)\n\n    def _add_agent_start_system_log(self, agent_idx: int) -&gt; None:\n        \"\"\"Add agent start system log.\"\"\"\n        agent = self._agents[agent_idx]\n        message = f\"Starting an agent {agent.name}\"\n        if agent.model != \"\":\n            model = self.get_model_for_inference(agent.model)\n            self._last_used_model = model\n            message += f\" that will connect to {model}\"\n            if agent.model_temperature:\n                message += f\", temperature={agent.model_temperature}\"\n            if agent.model_max_tokens:\n                message += f\", max_tokens={agent.model_max_tokens}\"\n        self.add_system_log(message)\n\n    def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:\n        \"\"\"Returns the terminal commands from the terminal file.\"\"\"\n        return self.list_messages(filename)\n\n    def list_messages(self, filename: str = CHAT_FILENAME) -&gt; List[Any]:\n        \"\"\"Returns messages from a specified file.\"\"\"\n        path = os.path.join(self._path, filename)\n\n        if not os.path.exists(path):\n            return []\n\n        with open(path, \"r\") as f:\n            return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n\n    def verify_message(\n        self, account_id: str, public_key: str, signature: str, message: str, nonce: str, callback_url: str\n    ) -&gt; bool:\n        \"\"\"Verify user message signed with NEAR Account.\"\"\"\n        return near.verify_signed_message(\n            account_id, public_key, signature, message, nonce, self._agents[0].name, callback_url\n        )\n\n    def list_files(self, path: str) -&gt; List[str]:\n        \"\"\"Lists files in the environment.\n\n        path: The path to list files from.\n        \"\"\"\n        return os.listdir(os.path.join(self._path, path))\n\n    def get_path(self) -&gt; str:  # noqa: D102\n        \"\"\"Returns the path of the current directory.\"\"\"\n        return self._path\n\n    def read_file(self, filename: str) -&gt; str:\n        \"\"\"Read a file from the environment.\n\n        filename: The name of the file to read.\n        \"\"\"\n        if not os.path.exists(os.path.join(self._path, filename)):\n            return \"\"\n        try:\n            with open(os.path.join(self._path, filename), \"r\") as f:\n                return f.read()\n        except Exception as e:\n            return f\"failed to read file: {e}\"\n\n    def write_file(self, filename: str, content: str) -&gt; str:\n        \"\"\"Writes a file to the environment.\n\n        filename: The name of the file to write to\n        content: The content to write to the file.\n        \"\"\"\n        path = Path(self._path) / filename\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with open(path, \"w\") as f:\n            f.write(content)\n        return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n\n    def query_vector_store(self, vector_store_id: str, query: str):\n        \"\"\"Query a vector store.\n\n        vector_store_id: The id of the vector store to query.\n        query: The query to search for.\n        \"\"\"\n        return self._inference.query_vector_store(vector_store_id, query)\n\n    def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"Executes a command in the environment and logs the output.\n\n        The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n        command: The command to execute, like 'ls -l' or 'python3 tests.py'\n        \"\"\"  # noqa: E501\n        if self._config.get(\"confirm_commands\", True):\n            yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n            if yes_no != \"\" and yes_no.lower() != \"y\":\n                return {\n                    \"command\": command,\n                    \"returncode\": 999,\n                    \"stdout\": \"\",\n                    \"stderr\": \"declined by user\",\n                }\n\n        try:\n            process = subprocess.Popen(\n                shlex.split(command),\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                bufsize=0,\n                universal_newlines=True,\n                cwd=self._path,\n            )\n        except Exception as e:\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"Failed to execute: \" + str(e),\n            }\n\n        msg = \"\"\n\n        def kill_process_tree(p: Any) -&gt; None:\n            nonlocal msg\n            msg = \"Killing process due to timeout\"\n\n            process = psutil.Process(p.pid)\n            for proc in process.children(recursive=True):\n                proc.kill()\n            process.kill()\n\n        timer = threading.Timer(2, kill_process_tree, (process,))\n        timer.start()\n        process.wait()\n        timer.cancel()\n\n        result = {\n            \"command\": command,\n            \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n            \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n            \"returncode\": process.returncode,\n            \"msg\": msg,\n        }\n        with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n            f.write(json.dumps(result) + DELIMITER)\n        return result\n\n    def get_model_for_inference(self, model: str = \"\") -&gt; str:\n        \"\"\"Returns 'provider::model_full_path' or 'model_short_name' if provider is default or not given.\"\"\"\n        provider = self._agents[0].model_provider if self._agents else \"\"\n        if model == \"\":\n            model = self._agents[0].model if self._agents else \"\"\n        if model == \"\":\n            return DEFAULT_PROVIDER_MODEL\n\n        # TODO(#225): convert model_short_name -&gt; model_full_path before passing to AI Hub.\n        # Until it's not implemented assume the model given from metadata for not default provider\n        # is already model_full_path, or model_short_name as used by fireworks.\n        if provider == \"\" or provider == DEFAULT_PROVIDER:\n            return model\n        return provider + PROVIDER_MODEL_SEP + model\n\n    def _run_inference_completions(\n        self,\n        messages: Iterable[ChatCompletionMessageParam] | str,\n        model: Iterable[ChatCompletionMessageParam] | str,\n        stream: bool,\n        auth: Optional[AuthData],\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Run inference completions for given parameters.\"\"\"\n        if isinstance(messages, str):\n            self.add_system_log(\"Deprecated completions call. Pass `messages` as a first parameter.\", logging.WARNING)\n            messages_or_model = messages\n            model_or_messages = model\n            model = cast(str, messages_or_model)\n            messages = cast(Iterable[ChatCompletionMessageParam], model_or_messages)\n        else:\n            model = cast(str, model)\n            messages = cast(Iterable[ChatCompletionMessageParam], messages)\n        model = self.get_model_for_inference(model)\n        if model != self._last_used_model:\n            self._last_used_model = model\n            self.add_system_log(f\"Connecting to {model}\")\n        return self._inference.completions(\n            model,\n            messages,\n            auth=auth,\n            stream=stream,\n            temperature=self._agents[0].model_temperature if self._agents else None,\n            max_tokens=self._agents[0].model_max_tokens if self._agents else None,\n            **kwargs,\n        )\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completions(\n        self,\n        messages: Iterable[ChatCompletionMessageParam] | str,\n        model: Iterable[ChatCompletionMessageParam] | str = \"\",\n        stream: bool = False,\n        auth: Optional[AuthData] = None,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Returns all completions for given messages using the given model.\"\"\"\n        return self._run_inference_completions(messages, model, stream, auth, **kwargs)\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completions_and_run_tools(\n        self,\n        messages: Iterable[ChatCompletionMessageParam] | str,\n        model: Iterable[ChatCompletionMessageParam] | str = \"\",\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; ModelResponse:\n        \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n        raw_response = self._run_inference_completions(messages, model, stream=False, tools=tools, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message\n        if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n            for tool_call in response_message.tool_calls:\n                function_name = tool_call.function.name\n                assert function_name, \"Tool call must have a function name\"\n                function_args = json.loads(tool_call.function.arguments)\n                function_response = self._tools.call_tool(function_name, **function_args)\n\n                if function_response:\n                    function_response_json = json.dumps(function_response) if function_response else \"\"\n                    self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n        return response\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completion(\n        self,\n        messages: Iterable[ChatCompletionMessageParam] | str,\n        model: Iterable[ChatCompletionMessageParam] | str = \"\",\n        auth: Dict | Optional[AuthData] = None,\n    ) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n        if isinstance(auth, Dict):\n            auth = AuthData(**auth)\n        raw_response = self.completions(messages, model, auth=auth)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    # TODO(286): `messages` may be model and `model` may be messages temporarily to support deprecated API.\n    def completion_and_run_tools(\n        self,\n        messages: Iterable[ChatCompletionMessageParam] | str,\n        model: Iterable[ChatCompletionMessageParam] | str = \"\",\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n        completion_tools_response = self.completions_and_run_tools(messages, model, tools, **kwargs)\n        assert all(\n            map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n        ), \"Expected Choices\"\n        choices: List[Choices] = completion_tools_response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def call_agent(self, agent_path: int, task: str) -&gt; None:\n        \"\"\"Calls agent with given task.\"\"\"\n        self._agents[agent_path].run(self, task=task)\n\n    def get_agents(self) -&gt; List[Agent]:\n        \"\"\"Returns list of agents available in environment.\"\"\"\n        return self._agents\n\n    def is_done(self) -&gt; bool:  # noqa: D102\n        return self._done\n\n    def mark_done(self) -&gt; None:  # noqa: D102\n        self._done = True\n\n    def create_snapshot(self) -&gt; bytes:\n        \"\"\"Create an in memory snapshot.\"\"\"\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(self._path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n        return snapshot\n\n    def save_to_registry(\n        self,\n        path: str,\n        run_type: str,\n        run_id: str,\n        base_id: Optional[Union[str, int]] = None,\n        run_name: Optional[str] = None,\n    ) -&gt; Optional[bytes]:\n        \"\"\"Save Environment to Registry.\"\"\"\n        if self._config.auth is None:\n            print(\"Warning: Authentication is not set up. Run not saved to registry. To log in, run `nearai login`\")\n            return None\n\n        agent_name = self._agents[0].name if self._agents else \"unknown\"\n        generated_name = f\"environment_run_{agent_name}_{run_id}\"\n        name = run_name or generated_name\n\n        tempdir = Path(tempfile.mkdtemp())\n        environment_path = tempdir / \"environment.tar.gz\"\n\n        with open(environment_path, \"w+b\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n            tar_filename = f.name\n\n            timestamp = datetime.now(timezone.utc).isoformat()\n\n            entry_location = registry.upload(\n                tempdir,\n                EntryMetadata.from_dict(\n                    {\n                        \"name\": name,\n                        \"version\": \"0.0.1\",\n                        \"description\": f\"Agent {run_type} run {agent_name}\",\n                        \"category\": \"environment\",\n                        \"tags\": [\"environment\"],\n                        \"details\": {\n                            \"base_id\": base_id,\n                            \"timestamp\": timestamp,\n                            \"agents\": [agent.name for agent in self._agents],\n                            \"run_id\": run_id,\n                            \"run_type\": run_type,\n                            \"filename\": tar_filename,\n                        },\n                        \"show_entry\": True,\n                    }\n                ),\n                show_progress=True,\n            )\n\n            location_str = plain_location(entry_location)\n\n            print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n        rmtree(tempdir)\n        return snapshot\n\n    def load_snapshot(self, snapshot: bytes) -&gt; None:\n        \"\"\"Load Environment from Snapshot.\"\"\"\n        shutil.rmtree(self._path, ignore_errors=True)\n\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            f.write(snapshot)\n            f.flush()\n            f.seek(0)\n\n            with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n                tar.extractall(self._path)\n\n    def load_from_registry(self, load_env: str) -&gt; str:  # noqa: D102\n        print(f\"Loading environment from {load_env} to {self._path}\")\n\n        directory = registry.download(load_env)\n        assert directory is not None, \"Failed to download environment\"\n\n        files = os.listdir(directory)\n        tarfile_file = next(f for f in files if f.endswith(\".tar.gz\"))\n\n        with tarfile.open(directory / tarfile_file, \"r\") as tar:\n            tar.extractall(self._path)\n        return directory.name\n\n    def __str__(self) -&gt; str:  # noqa: D105\n        return f\"Environment({self._path})\"\n\n    def run_agent(self, task: Optional[str]) -&gt; None:  # noqa: D102\n        self._agents[0].run(self, task=task)\n\n    def request_user_input(self) -&gt; None:\n        \"\"\"Must be called to request input from the user.\"\"\"\n        self.set_next_actor(\"user\")\n\n    def clear_temp_agent_files(self) -&gt; None:  # noqa: D102\n        \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n        for agent in self._agents:\n            if agent.temp_dir and os.path.exists(agent.temp_dir):\n                shutil.rmtree(agent.temp_dir)\n\n    def set_next_actor(self, who: str) -&gt; None:  # noqa: D102\n        \"\"\"Set the next actor / action in the dialogue.\"\"\"\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        with open(next_action_fn, \"w\") as f:\n            f.write(who)\n\n    def get_next_actor(self) -&gt; str:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        if os.path.exists(next_action_fn):\n            with open(next_action_fn) as f:\n                return f.read().strip(\" \\n\")\n        else:\n            # By default the user starts the conversation.\n            return \"user\"\n\n    def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n        \"\"\"Run an interactive session within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        last_message_idx = 0\n\n        self._add_agent_start_system_log(agent_idx=0)\n\n        if self._agents[0].welcome_description:\n            if self._agents[0].welcome_title:\n                print(f\"{self._agents[0].welcome_title}: {self._agents[0].welcome_description}\")\n            else:\n                print(self._agents[0].welcome_description)\n\n        def print_messages(last_message_idx: int) -&gt; int:\n            messages = self.list_messages()\n            for item in messages[last_message_idx:]:\n                print(f\"[{item['role']}]: {item['content']}\", flush=True)\n            return len(messages)\n\n        last_message_idx = print_messages(last_message_idx)\n\n        iteration_count = 0\n        while True:\n            if self.get_next_actor() != \"user\":\n                messages = self.list_messages()\n                new_message = None if not messages else messages[-1][\"content\"]\n\n                iteration_count += 1\n                self.run_agent(new_message)\n\n                last_message_idx = print_messages(last_message_idx)\n                if self.is_done():\n                    break\n\n            else:\n                new_message = input(\"&gt; \")\n                if new_message == \"exit\":\n                    break\n                self.add_message(\"user\", new_message)\n\n                self.set_next_actor(\"agent\")\n\n        self.clear_temp_agent_files()\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n\n    def run_task(\n        self,\n        task: str,\n        record_run: str = \"\",\n        load_env: str = \"\",\n        max_iterations: int = 10,\n    ) -&gt; None:\n        \"\"\"Runs a task within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        iteration = 0\n\n        self._add_agent_start_system_log(agent_idx=0)\n\n        if task:\n            self.add_message(\"user\", task)\n\n        while iteration &lt; max_iterations and not self.is_done():\n            iteration += 1\n            self._agents[0].run(self, task=task)\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n\n    def inspect(self) -&gt; None:  # noqa: D102\n        filename = Path(os.path.abspath(__file__)).parent / \"streamlit_inspect.py\"\n        subprocess.call([\"streamlit\", \"run\", filename, \"--\", self._path])\n\n    def contains_non_empty_chat_txt(self, directory: str) -&gt; bool:  # noqa: D102\n        chat_txt_path = os.path.join(directory, \"chat.txt\")\n        return os.path.isfile(chat_txt_path) and os.path.getsize(chat_txt_path) &gt; 0\n\n    def save_folder(self, name: Optional[str] = None) -&gt; None:  # noqa: D102\n        path = self._path\n        temp_dir = None\n\n        def copy_relevant_folders(src: str, dest: str) -&gt; None:\n            for item in os.listdir(src):\n                s = os.path.join(src, item)\n                d = os.path.join(dest, item)\n                if os.path.isdir(s):\n                    if self.contains_non_empty_chat_txt(s):\n                        shutil.copytree(s, d)\n                    else:\n                        os.makedirs(d, exist_ok=True)\n                        copy_relevant_folders(s, d)\n                        if not os.listdir(d):\n                            os.rmdir(d)\n\n        if not self.contains_non_empty_chat_txt(path):\n            temp_dir = tempfile.mkdtemp()\n            copy_relevant_folders(path, temp_dir)\n            path = temp_dir\n\n        try:\n            if not os.listdir(path):\n                raise ValueError(f\"No files found in {path}\")\n\n            self.save_to_registry(\n                path, \"folders\" if temp_dir else \"folder\", self.generate_folder_hash_id(path), None, name\n            )\n        finally:\n            if temp_dir:\n                shutil.rmtree(temp_dir)\n\n    def save_from_history(self, lines: List[str], name: Optional[str] = None) -&gt; None:  # noqa: D102\n        # Parse lines and extract relevant information\n        pattern = r\"^\\s*(?:\\d+\\s+)?(\\S+)\\s+environment\\s+interactive\\s+(\\S+)\\s+(\\S+)(.*?)$\"\n        relevant_paths = {}\n        for line in lines:\n            match = re.match(pattern, line)\n            if match:\n                program_name, agents, path, other_args = match.groups()\n                path = path.strip(\"/\")\n                if self.contains_non_empty_chat_txt(path):\n                    command = f\"{program_name} environment interactive {agents} {path} {other_args}\"\n                    relevant_paths[path] = {\"command\": command.strip()}\n\n        if not relevant_paths:\n            raise ValueError(\"No relevant paths with non-empty chat.txt files found in history\")\n\n        for path, info in relevant_paths.items():\n            print(path)\n            # Write start_command.log\n            with open(os.path.join(path, \"start_command.log\"), \"w\") as f:\n                f.write(info[\"command\"])\n\n        # Create temporary directory and copy relevant folders\n        temp_dir = tempfile.mkdtemp()\n        try:\n            for path, _info in relevant_paths.items():\n                dest = os.path.join(temp_dir, path.replace(\"/\", \"_\").strip(\"_\"))\n                shutil.copytree(path, dest)\n            self.save_to_registry(temp_dir, \"folders\", self.generate_folder_hash_id(temp_dir), None, name)\n\n        finally:\n            shutil.rmtree(temp_dir)\n\n    def generate_folder_hash_id(self, path: str) -&gt; str:\n        \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n        hash_obj = hashlib.md5()\n\n        for root, _dirs, files in os.walk(path):\n            for file in sorted(files):\n                file_path = os.path.join(root, file)\n                with open(file_path, \"rb\") as f:\n                    while chunk := f.read(8192):\n                        hash_obj.update(chunk)\n\n        return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.add_agent_log","title":"add_agent_log","text":"<pre><code>add_agent_log(log: str, level: int = logging.INFO) -&gt; None\n</code></pre> <p>Add agent log with timestamp and log level.</p> Source code in <code>nearai/environment.py</code> <pre><code>def add_agent_log(self, log: str, level: int = logging.INFO) -&gt; None:\n    \"\"\"Add agent log with timestamp and log level.\"\"\"\n    logger = logging.getLogger(\"agent_logger\")\n    if not logger.handlers:\n        # Configure the logger if it hasn't been set up yet\n        logger.setLevel(logging.DEBUG)\n        file_handler = logging.FileHandler(os.path.join(self._path, AGENT_LOG_FILENAME))\n        formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n    # Log the message\n    logger.log(level, log)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.add_message","title":"add_message","text":"<pre><code>add_message(role: str, message: str, filename: str = CHAT_FILENAME, **kwargs: Any) -&gt; None\n</code></pre> <p>Add a message to the chat file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def add_message(self, role: str, message: str, filename: str = CHAT_FILENAME, **kwargs: Any) -&gt; None:\n    \"\"\"Add a message to the chat file.\"\"\"\n    with open(os.path.join(self._path, filename), \"a\") as f:\n        f.write(json.dumps({\"role\": role, \"content\": message, **kwargs}) + DELIMITER)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.add_system_log","title":"add_system_log","text":"<pre><code>add_system_log(log: str, level: int = logging.INFO) -&gt; None\n</code></pre> <p>Add system log with timestamp and log level.</p> Source code in <code>nearai/environment.py</code> <pre><code>def add_system_log(self, log: str, level: int = logging.INFO) -&gt; None:\n    \"\"\"Add system log with timestamp and log level.\"\"\"\n    logger = logging.getLogger(\"system_logger\")\n    if not logger.handlers:\n        # Configure the logger if it hasn't been set up yet\n        logger.setLevel(logging.DEBUG)\n        file_handler = logging.FileHandler(os.path.join(self._path, SYSTEM_LOG_FILENAME))\n        formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n        if self.print_system_log:\n            console_handler = logging.StreamHandler()\n            console_handler.setFormatter(formatter)\n            logger.addHandler(console_handler)\n\n    # Log the message\n    logger.log(level, log)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.call_agent","title":"call_agent","text":"<pre><code>call_agent(agent_path: int, task: str) -&gt; None\n</code></pre> <p>Calls agent with given task.</p> Source code in <code>nearai/environment.py</code> <pre><code>def call_agent(self, agent_path: int, task: str) -&gt; None:\n    \"\"\"Calls agent with given task.\"\"\"\n    self._agents[agent_path].run(self, task=task)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.clear_temp_agent_files","title":"clear_temp_agent_files","text":"<pre><code>clear_temp_agent_files() -&gt; None\n</code></pre> <p>Remove temp agent files created to be used in <code>runpy</code>.</p> Source code in <code>nearai/environment.py</code> <pre><code>def clear_temp_agent_files(self) -&gt; None:  # noqa: D102\n    \"\"\"Remove temp agent files created to be used in `runpy`.\"\"\"\n    for agent in self._agents:\n        if agent.temp_dir and os.path.exists(agent.temp_dir):\n            shutil.rmtree(agent.temp_dir)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion","title":"completion","text":"<pre><code>completion(messages: Iterable[ChatCompletionMessageParam] | str, model: Iterable[ChatCompletionMessageParam] | str = '', auth: Dict | Optional[AuthData] = None) -&gt; str\n</code></pre> <p>Returns a completion for the given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion(\n    self,\n    messages: Iterable[ChatCompletionMessageParam] | str,\n    model: Iterable[ChatCompletionMessageParam] | str = \"\",\n    auth: Dict | Optional[AuthData] = None,\n) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n    if isinstance(auth, Dict):\n        auth = AuthData(**auth)\n    raw_response = self.completions(messages, model, auth=auth)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion_and_run_tools","title":"completion_and_run_tools","text":"<pre><code>completion_and_run_tools(messages: Iterable[ChatCompletionMessageParam] | str, model: Iterable[ChatCompletionMessageParam] | str = '', tools: Optional[List] = None, **kwargs: Any) -&gt; str\n</code></pre> <p>Returns a completion for the given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion_and_run_tools(\n    self,\n    messages: Iterable[ChatCompletionMessageParam] | str,\n    model: Iterable[ChatCompletionMessageParam] | str = \"\",\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n    completion_tools_response = self.completions_and_run_tools(messages, model, tools, **kwargs)\n    assert all(\n        map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n    ), \"Expected Choices\"\n    choices: List[Choices] = completion_tools_response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions","title":"completions","text":"<pre><code>completions(messages: Iterable[ChatCompletionMessageParam] | str, model: Iterable[ChatCompletionMessageParam] | str = '', stream: bool = False, auth: Optional[AuthData] = None, **kwargs: Any) -&gt; Union[ModelResponse, CustomStreamWrapper]\n</code></pre> <p>Returns all completions for given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions(\n    self,\n    messages: Iterable[ChatCompletionMessageParam] | str,\n    model: Iterable[ChatCompletionMessageParam] | str = \"\",\n    stream: bool = False,\n    auth: Optional[AuthData] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Returns all completions for given messages using the given model.\"\"\"\n    return self._run_inference_completions(messages, model, stream, auth, **kwargs)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions_and_run_tools","title":"completions_and_run_tools","text":"<pre><code>completions_and_run_tools(messages: Iterable[ChatCompletionMessageParam] | str, model: Iterable[ChatCompletionMessageParam] | str = '', tools: Optional[List] = None, **kwargs: Any) -&gt; ModelResponse\n</code></pre> <p>Returns all completions for given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions_and_run_tools(\n    self,\n    messages: Iterable[ChatCompletionMessageParam] | str,\n    model: Iterable[ChatCompletionMessageParam] | str = \"\",\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; ModelResponse:\n    \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n    raw_response = self._run_inference_completions(messages, model, stream=False, tools=tools, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message\n    if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n        for tool_call in response_message.tool_calls:\n            function_name = tool_call.function.name\n            assert function_name, \"Tool call must have a function name\"\n            function_args = json.loads(tool_call.function.arguments)\n            function_response = self._tools.call_tool(function_name, **function_args)\n\n            if function_response:\n                function_response_json = json.dumps(function_response) if function_response else \"\"\n                self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n    return response\n</code></pre>"},{"location":"api/#nearai.environment.Environment.create_snapshot","title":"create_snapshot","text":"<pre><code>create_snapshot() -&gt; bytes\n</code></pre> <p>Create an in memory snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def create_snapshot(self) -&gt; bytes:\n    \"\"\"Create an in memory snapshot.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(self._path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.environment.Environment.exec_command","title":"exec_command","text":"<pre><code>exec_command(command: str) -&gt; Dict[str, Union[str, int]]\n</code></pre> <p>Executes a command in the environment and logs the output.</p> <p>The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input. command: The command to execute, like 'ls -l' or 'python3 tests.py'</p> Source code in <code>nearai/environment.py</code> <pre><code>def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Executes a command in the environment and logs the output.\n\n    The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n    command: The command to execute, like 'ls -l' or 'python3 tests.py'\n    \"\"\"  # noqa: E501\n    if self._config.get(\"confirm_commands\", True):\n        yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n        if yes_no != \"\" and yes_no.lower() != \"y\":\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"declined by user\",\n            }\n\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            bufsize=0,\n            universal_newlines=True,\n            cwd=self._path,\n        )\n    except Exception as e:\n        return {\n            \"command\": command,\n            \"returncode\": 999,\n            \"stdout\": \"\",\n            \"stderr\": \"Failed to execute: \" + str(e),\n        }\n\n    msg = \"\"\n\n    def kill_process_tree(p: Any) -&gt; None:\n        nonlocal msg\n        msg = \"Killing process due to timeout\"\n\n        process = psutil.Process(p.pid)\n        for proc in process.children(recursive=True):\n            proc.kill()\n        process.kill()\n\n    timer = threading.Timer(2, kill_process_tree, (process,))\n    timer.start()\n    process.wait()\n    timer.cancel()\n\n    result = {\n        \"command\": command,\n        \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n        \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n        \"returncode\": process.returncode,\n        \"msg\": msg,\n    }\n    with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n        f.write(json.dumps(result) + DELIMITER)\n    return result\n</code></pre>"},{"location":"api/#nearai.environment.Environment.generate_folder_hash_id","title":"generate_folder_hash_id","text":"<pre><code>generate_folder_hash_id(path: str) -&gt; str\n</code></pre> <p>Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.</p> Source code in <code>nearai/environment.py</code> <pre><code>def generate_folder_hash_id(self, path: str) -&gt; str:\n    \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n    hash_obj = hashlib.md5()\n\n    for root, _dirs, files in os.walk(path):\n        for file in sorted(files):\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                while chunk := f.read(8192):\n                    hash_obj.update(chunk)\n\n    return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_agents","title":"get_agents","text":"<pre><code>get_agents() -&gt; List[Agent]\n</code></pre> <p>Returns list of agents available in environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_agents(self) -&gt; List[Agent]:\n    \"\"\"Returns list of agents available in environment.\"\"\"\n    return self._agents\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_model_for_inference","title":"get_model_for_inference","text":"<pre><code>get_model_for_inference(model: str = '') -&gt; str\n</code></pre> <p>Returns 'provider::model_full_path' or 'model_short_name' if provider is default or not given.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_model_for_inference(self, model: str = \"\") -&gt; str:\n    \"\"\"Returns 'provider::model_full_path' or 'model_short_name' if provider is default or not given.\"\"\"\n    provider = self._agents[0].model_provider if self._agents else \"\"\n    if model == \"\":\n        model = self._agents[0].model if self._agents else \"\"\n    if model == \"\":\n        return DEFAULT_PROVIDER_MODEL\n\n    # TODO(#225): convert model_short_name -&gt; model_full_path before passing to AI Hub.\n    # Until it's not implemented assume the model given from metadata for not default provider\n    # is already model_full_path, or model_short_name as used by fireworks.\n    if provider == \"\" or provider == DEFAULT_PROVIDER:\n        return model\n    return provider + PROVIDER_MODEL_SEP + model\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_path","title":"get_path","text":"<pre><code>get_path() -&gt; str\n</code></pre> <p>Returns the path of the current directory.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_path(self) -&gt; str:  # noqa: D102\n    \"\"\"Returns the path of the current directory.\"\"\"\n    return self._path\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_tool_registry","title":"get_tool_registry","text":"<pre><code>get_tool_registry() -&gt; ToolRegistry\n</code></pre> <p>Returns the tool registry, a dictionary of tools that can be called by the agent.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_tool_registry(self) -&gt; ToolRegistry:  # noqa: D102\n    \"\"\"Returns the tool registry, a dictionary of tools that can be called by the agent.\"\"\"\n    return self._tools\n</code></pre>"},{"location":"api/#nearai.environment.Environment.list_files","title":"list_files","text":"<pre><code>list_files(path: str) -&gt; List[str]\n</code></pre> <p>Lists files in the environment.</p> <p>path: The path to list files from.</p> Source code in <code>nearai/environment.py</code> <pre><code>def list_files(self, path: str) -&gt; List[str]:\n    \"\"\"Lists files in the environment.\n\n    path: The path to list files from.\n    \"\"\"\n    return os.listdir(os.path.join(self._path, path))\n</code></pre>"},{"location":"api/#nearai.environment.Environment.list_messages","title":"list_messages","text":"<pre><code>list_messages(filename: str = CHAT_FILENAME) -&gt; List[Any]\n</code></pre> <p>Returns messages from a specified file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def list_messages(self, filename: str = CHAT_FILENAME) -&gt; List[Any]:\n    \"\"\"Returns messages from a specified file.\"\"\"\n    path = os.path.join(self._path, filename)\n\n    if not os.path.exists(path):\n        return []\n\n    with open(path, \"r\") as f:\n        return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n</code></pre>"},{"location":"api/#nearai.environment.Environment.list_terminal_commands","title":"list_terminal_commands","text":"<pre><code>list_terminal_commands(filename: str = TERMINAL_FILENAME) -&gt; List[Any]\n</code></pre> <p>Returns the terminal commands from the terminal file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:\n    \"\"\"Returns the terminal commands from the terminal file.\"\"\"\n    return self.list_messages(filename)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.load_snapshot","title":"load_snapshot","text":"<pre><code>load_snapshot(snapshot: bytes) -&gt; None\n</code></pre> <p>Load Environment from Snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def load_snapshot(self, snapshot: bytes) -&gt; None:\n    \"\"\"Load Environment from Snapshot.\"\"\"\n    shutil.rmtree(self._path, ignore_errors=True)\n\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        f.write(snapshot)\n        f.flush()\n        f.seek(0)\n\n        with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n            tar.extractall(self._path)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.query_vector_store","title":"query_vector_store","text":"<pre><code>query_vector_store(vector_store_id: str, query: str)\n</code></pre> <p>Query a vector store.</p> <p>vector_store_id: The id of the vector store to query. query: The query to search for.</p> Source code in <code>nearai/environment.py</code> <pre><code>def query_vector_store(self, vector_store_id: str, query: str):\n    \"\"\"Query a vector store.\n\n    vector_store_id: The id of the vector store to query.\n    query: The query to search for.\n    \"\"\"\n    return self._inference.query_vector_store(vector_store_id, query)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.read_file","title":"read_file","text":"<pre><code>read_file(filename: str) -&gt; str\n</code></pre> <p>Read a file from the environment.</p> <p>filename: The name of the file to read.</p> Source code in <code>nearai/environment.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n    \"\"\"Read a file from the environment.\n\n    filename: The name of the file to read.\n    \"\"\"\n    if not os.path.exists(os.path.join(self._path, filename)):\n        return \"\"\n    try:\n        with open(os.path.join(self._path, filename), \"r\") as f:\n            return f.read()\n    except Exception as e:\n        return f\"failed to read file: {e}\"\n</code></pre>"},{"location":"api/#nearai.environment.Environment.request_user_input","title":"request_user_input","text":"<pre><code>request_user_input() -&gt; None\n</code></pre> <p>Must be called to request input from the user.</p> Source code in <code>nearai/environment.py</code> <pre><code>def request_user_input(self) -&gt; None:\n    \"\"\"Must be called to request input from the user.\"\"\"\n    self.set_next_actor(\"user\")\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_interactive","title":"run_interactive","text":"<pre><code>run_interactive(record_run: str = '', load_env: str = '') -&gt; None\n</code></pre> <p>Run an interactive session within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n    \"\"\"Run an interactive session within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    last_message_idx = 0\n\n    self._add_agent_start_system_log(agent_idx=0)\n\n    if self._agents[0].welcome_description:\n        if self._agents[0].welcome_title:\n            print(f\"{self._agents[0].welcome_title}: {self._agents[0].welcome_description}\")\n        else:\n            print(self._agents[0].welcome_description)\n\n    def print_messages(last_message_idx: int) -&gt; int:\n        messages = self.list_messages()\n        for item in messages[last_message_idx:]:\n            print(f\"[{item['role']}]: {item['content']}\", flush=True)\n        return len(messages)\n\n    last_message_idx = print_messages(last_message_idx)\n\n    iteration_count = 0\n    while True:\n        if self.get_next_actor() != \"user\":\n            messages = self.list_messages()\n            new_message = None if not messages else messages[-1][\"content\"]\n\n            iteration_count += 1\n            self.run_agent(new_message)\n\n            last_message_idx = print_messages(last_message_idx)\n            if self.is_done():\n                break\n\n        else:\n            new_message = input(\"&gt; \")\n            if new_message == \"exit\":\n                break\n            self.add_message(\"user\", new_message)\n\n            self.set_next_actor(\"agent\")\n\n    self.clear_temp_agent_files()\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_task","title":"run_task","text":"<pre><code>run_task(task: str, record_run: str = '', load_env: str = '', max_iterations: int = 10) -&gt; None\n</code></pre> <p>Runs a task within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_task(\n    self,\n    task: str,\n    record_run: str = \"\",\n    load_env: str = \"\",\n    max_iterations: int = 10,\n) -&gt; None:\n    \"\"\"Runs a task within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    iteration = 0\n\n    self._add_agent_start_system_log(agent_idx=0)\n\n    if task:\n        self.add_message(\"user\", task)\n\n    while iteration &lt; max_iterations and not self.is_done():\n        iteration += 1\n        self._agents[0].run(self, task=task)\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.save_to_registry","title":"save_to_registry","text":"<pre><code>save_to_registry(path: str, run_type: str, run_id: str, base_id: Optional[Union[str, int]] = None, run_name: Optional[str] = None) -&gt; Optional[bytes]\n</code></pre> <p>Save Environment to Registry.</p> Source code in <code>nearai/environment.py</code> <pre><code>def save_to_registry(\n    self,\n    path: str,\n    run_type: str,\n    run_id: str,\n    base_id: Optional[Union[str, int]] = None,\n    run_name: Optional[str] = None,\n) -&gt; Optional[bytes]:\n    \"\"\"Save Environment to Registry.\"\"\"\n    if self._config.auth is None:\n        print(\"Warning: Authentication is not set up. Run not saved to registry. To log in, run `nearai login`\")\n        return None\n\n    agent_name = self._agents[0].name if self._agents else \"unknown\"\n    generated_name = f\"environment_run_{agent_name}_{run_id}\"\n    name = run_name or generated_name\n\n    tempdir = Path(tempfile.mkdtemp())\n    environment_path = tempdir / \"environment.tar.gz\"\n\n    with open(environment_path, \"w+b\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n        tar_filename = f.name\n\n        timestamp = datetime.now(timezone.utc).isoformat()\n\n        entry_location = registry.upload(\n            tempdir,\n            EntryMetadata.from_dict(\n                {\n                    \"name\": name,\n                    \"version\": \"0.0.1\",\n                    \"description\": f\"Agent {run_type} run {agent_name}\",\n                    \"category\": \"environment\",\n                    \"tags\": [\"environment\"],\n                    \"details\": {\n                        \"base_id\": base_id,\n                        \"timestamp\": timestamp,\n                        \"agents\": [agent.name for agent in self._agents],\n                        \"run_id\": run_id,\n                        \"run_type\": run_type,\n                        \"filename\": tar_filename,\n                    },\n                    \"show_entry\": True,\n                }\n            ),\n            show_progress=True,\n        )\n\n        location_str = plain_location(entry_location)\n\n        print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n    rmtree(tempdir)\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.environment.Environment.set_next_actor","title":"set_next_actor","text":"<pre><code>set_next_actor(who: str) -&gt; None\n</code></pre> <p>Set the next actor / action in the dialogue.</p> Source code in <code>nearai/environment.py</code> <pre><code>def set_next_actor(self, who: str) -&gt; None:  # noqa: D102\n    \"\"\"Set the next actor / action in the dialogue.\"\"\"\n    next_action_fn = os.path.join(self._path, \".next_action\")\n\n    with open(next_action_fn, \"w\") as f:\n        f.write(who)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.verify_message","title":"verify_message","text":"<pre><code>verify_message(account_id: str, public_key: str, signature: str, message: str, nonce: str, callback_url: str) -&gt; bool\n</code></pre> <p>Verify user message signed with NEAR Account.</p> Source code in <code>nearai/environment.py</code> <pre><code>def verify_message(\n    self, account_id: str, public_key: str, signature: str, message: str, nonce: str, callback_url: str\n) -&gt; bool:\n    \"\"\"Verify user message signed with NEAR Account.\"\"\"\n    return near.verify_signed_message(\n        account_id, public_key, signature, message, nonce, self._agents[0].name, callback_url\n    )\n</code></pre>"},{"location":"api/#nearai.environment.Environment.write_file","title":"write_file","text":"<pre><code>write_file(filename: str, content: str) -&gt; str\n</code></pre> <p>Writes a file to the environment.</p> <p>filename: The name of the file to write to content: The content to write to the file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def write_file(self, filename: str, content: str) -&gt; str:\n    \"\"\"Writes a file to the environment.\n\n    filename: The name of the file to write to\n    content: The content to write to the file.\n    \"\"\"\n    path = Path(self._path) / filename\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with open(path, \"w\") as f:\n        f.write(content)\n    return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n</code></pre>"},{"location":"api/#nearai.evaluation","title":"evaluation","text":""},{"location":"api/#nearai.evaluation.evaluation_table","title":"evaluation_table","text":"<pre><code>evaluation_table(namespace: str = '', tags: str = '') -&gt; Tuple[Dict[tuple[tuple[str, Any], ...], Dict[str, str]], List[str], List[str]]\n</code></pre> <p>Returns rows, columns, and important columns.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def evaluation_table(\n    namespace: str = \"\", tags: str = \"\"\n) -&gt; Tuple[Dict[tuple[tuple[str, Any], ...], Dict[str, str]], List[str], List[str]]:\n    \"\"\"Returns rows, columns, and important columns.\"\"\"\n    # Make sure tags is a comma-separated list of tags\n    tags_l = parse_tags(tags)\n    tags = \",\".join(tags_l)\n\n    entries = registry.list(\n        namespace=namespace,\n        category=\"evaluation\",\n        tags=tags,\n        total=10000,\n        offset=0,\n        show_all=False,\n        show_latest_version=True,\n    )\n    rows: Dict[tuple[tuple[str, Any], ...], Dict[str, str]] = {}\n    metric_names: Set[str] = set()\n    important_metric_names: Set[str] = set()\n    for entry in entries:\n        evaluation_name = f\"{entry.namespace}/{entry.name}/{entry.version}\"\n        evaluation_path = registry.download(evaluation_name, verbose=False)\n        metrics_path = evaluation_path / \"metrics.json\"\n        with open(metrics_path, \"r\") as f:\n            metrics = json.load(f)\n            key = {\n                \"model\": metrics[EVALUATED_ENTRY_METADATA].get(\"model\", \"\"),\n                \"agent\": metrics[EVALUATED_ENTRY_METADATA].get(\"agent\", \"\"),\n                \"namespace\": metrics[EVALUATED_ENTRY_METADATA].get(\"namespace\", \"\"),\n                \"version\": metrics[EVALUATED_ENTRY_METADATA].get(\"version\", \"\"),\n                \"provider\": metrics[EVALUATED_ENTRY_METADATA].get(\"provider\", \"\"),\n            }\n\n            # Convert the key dictionary to a tuple to use as a key in rows\n            key_tuple = tuple(key.items())\n\n            # Initialize the inner dictionary if this key doesn't exist\n            if key_tuple not in rows:\n                rows[key_tuple] = {}\n\n            # Add all other metrics that are not EVALUATED_ENTRY_METADATA\n            for metric_name, metric_value in metrics.items():\n                if metric_name == EVALUATED_ENTRY_METADATA:\n                    continue\n                if _is_important_metric(metric_name, metrics):\n                    important_metric_names.add(metric_name)\n                rows[key_tuple][metric_name] = str(metric_value)\n                metric_names.add(metric_name)\n\n    sorted_metric_names = sorted(metric_names)\n    columns = [\"model\", \"agent\", \"namespace\", \"version\", \"provider\"] + sorted_metric_names\n    important_columns = [\"model\", \"agent\"] + sorted(important_metric_names)\n    return rows, columns, important_columns\n</code></pre>"},{"location":"api/#nearai.evaluation.print_evaluation_table","title":"print_evaluation_table","text":"<pre><code>print_evaluation_table(rows: Dict[tuple[tuple[str, Any], ...], Dict[str, str]], columns: List[str], important_columns: List[str], all_key_columns: bool, all_metrics: bool, num_columns: int, metric_name_max_length: int) -&gt; None\n</code></pre> <p>Prints table of evaluations.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def print_evaluation_table(\n    rows: Dict[tuple[tuple[str, Any], ...], Dict[str, str]],\n    columns: List[str],\n    important_columns: List[str],\n    all_key_columns: bool,\n    all_metrics: bool,\n    num_columns: int,\n    metric_name_max_length: int,\n) -&gt; None:\n    \"\"\"Prints table of evaluations.\"\"\"\n    metric_names = columns[5:] if all_metrics else important_columns[2:]\n    _print_metrics_tables(rows, metric_names, num_columns, all_key_columns, metric_name_max_length)\n</code></pre>"},{"location":"api/#nearai.evaluation.record_evaluation_metrics","title":"record_evaluation_metrics","text":"<pre><code>record_evaluation_metrics(solver_strategy: SolverStrategy, metrics: Dict[str, Any], prepend_evaluation_name: bool = True) -&gt; None\n</code></pre> <p>Uploads evaluation metrics into registry.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def record_evaluation_metrics(\n    solver_strategy: SolverStrategy, metrics: Dict[str, Any], prepend_evaluation_name: bool = True\n) -&gt; None:\n    \"\"\"Uploads evaluation metrics into registry.\"\"\"\n    evaluation_name = solver_strategy.evaluation_name()\n    model = \"\"\n    agent = \"\"\n    version = \"\"\n\n    if model_metadata := solver_strategy.model_metadata():\n        model = model_metadata.get(\"name\", \"\")\n        version = model_metadata.get(\"version\", \"\")\n\n    if agent_metadata := solver_strategy.agent_metadata():\n        agent = agent_metadata.get(\"name\", \"\")\n        version = agent_metadata.get(\"version\", \"\")\n\n    upload_evaluation(\n        evaluation_name,\n        metrics if not prepend_evaluation_name else _prepend_name_to_metrics(evaluation_name, metrics),\n        model,\n        agent,\n        solver_strategy.evaluated_entry_namespace(),\n        version,\n        solver_strategy.model_provider(),\n    )\n</code></pre>"},{"location":"api/#nearai.evaluation.record_single_score_evaluation","title":"record_single_score_evaluation","text":"<pre><code>record_single_score_evaluation(solver_strategy: SolverStrategy, score: float) -&gt; None\n</code></pre> <p>Uploads single score evaluation into registry.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def record_single_score_evaluation(solver_strategy: SolverStrategy, score: float) -&gt; None:\n    \"\"\"Uploads single score evaluation into registry.\"\"\"\n    evaluation_name = solver_strategy.evaluation_name()\n    record_evaluation_metrics(solver_strategy, {evaluation_name: score}, False)\n</code></pre>"},{"location":"api/#nearai.evaluation.upload_evaluation","title":"upload_evaluation","text":"<pre><code>upload_evaluation(evaluation_name: str, metrics: Dict[str, Any], model: str = '', agent: str = '', namespace: str = '', version: str = '', provider: str = '') -&gt; None\n</code></pre> <p>Uploads evaluation into registry.</p> <p><code>evaluation_name</code>: a unique name for (benchmark, solver) tuple, e.g. \"mbpp\" or \"live_bench\" or \"mmlu-5-shot\". <code>metrics</code>: metrics from evaluation. <code>model</code>: model that was used. <code>agent</code>: agent that was evaluated, in any. <code>namespace</code>: namespace of evaluated agent or evaluated model. <code>version</code>: version of evaluated agent or evaluated model. <code>provider</code>: provider of model used; pass <code>local</code> if running locally.</p> Source code in <code>nearai/evaluation.py</code> <pre><code>def upload_evaluation(\n    evaluation_name: str,\n    metrics: Dict[str, Any],\n    model: str = \"\",\n    agent: str = \"\",\n    namespace: str = \"\",\n    version: str = \"\",\n    provider: str = \"\",\n) -&gt; None:\n    \"\"\"Uploads evaluation into registry.\n\n    `evaluation_name`: a unique name for (benchmark, solver) tuple, e.g. \"mbpp\" or \"live_bench\" or \"mmlu-5-shot\".\n    `metrics`: metrics from evaluation.\n    `model`: model that was used.\n    `agent`: agent that was evaluated, in any.\n    `namespace`: namespace of evaluated agent or evaluated model.\n    `version`: version of evaluated agent or evaluated model.\n    `provider`: provider of model used; pass `local` if running locally.\n    \"\"\"\n    key = f\"evaluation_{evaluation_name}\"\n    metrics[EVALUATED_ENTRY_METADATA] = {}\n    if agent != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"agent\"] = agent\n        key += f\"_agent_{agent}\"\n    if model != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"model\"] = model\n        key += f\"_model_{model}\"\n    if namespace != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"namespace\"] = namespace\n        key += f\"_namespace_{namespace}\"\n    if version != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"version\"] = version\n        key += f\"_version_{version}\"\n    if provider != \"\":\n        metrics[EVALUATED_ENTRY_METADATA][\"provider\"] = provider\n        key += f\"_provider_{provider}\"\n\n    entry_path = get_registry_folder() / key\n    # Create folder entry_path if not present\n    entry_path.mkdir(parents=True, exist_ok=True)\n    # Write file metrics.json inside\n    metrics_file = entry_path / \"metrics.json\"\n    with metrics_file.open(\"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    metadata_path = entry_path / \"metadata.json\"\n    # TODO(#273): Currently that will not update existing evaluation.\n    with open(metadata_path, \"w\") as f:\n        json.dump(\n            {\n                \"name\": key,\n                \"version\": \"0.0.1\",\n                \"description\": \"\",\n                \"category\": \"evaluation\",\n                \"tags\": [],\n                \"details\": {},\n                \"show_entry\": True,\n            },\n            f,\n            indent=2,\n        )\n\n    registry.upload(Path(entry_path), show_progress=True)\n</code></pre>"},{"location":"api/#nearai.finetune","title":"finetune","text":""},{"location":"api/#nearai.finetune.FinetuneCli","title":"FinetuneCli","text":"Source code in <code>nearai/finetune/__init__.py</code> <pre><code>class FinetuneCli:\n    def start(\n        self,\n        model: str,\n        tokenizer: str,\n        dataset: str,\n        num_procs: int,\n        format: str,\n        upload_checkpoint: bool = True,\n        num_nodes: int = 1,\n        job_id: Optional[str] = None,\n        checkpoint: Optional[str] = None,\n        **dataset_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Start a finetuning job on the current node.\n\n        Args:\n        ----\n            model: Name of a model in the registry. Base model to finetune.\n            tokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\n            dataset: Name of a dataset in the registry.\n            num_procs: Number of GPUs to use for training\n            format: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\n            upload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\n            num_nodes: Number of nodes to use for training. Default is 1.\n            job_id: Unique identifier for the job. Default is None.\n            checkpoint: Name of the model checkpoint to start from. Default is None.\n            dataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n\n        \"\"\"  # noqa: E501\n        from nearai.dataset import get_dataset\n\n        assert num_nodes &gt;= 1\n\n        # Prepare job id folder\n        if job_id is None:\n            job_id = \"job\"\n        job_id = f\"{job_id}-{timestamp()}-{randint(10**8, 10**9 - 1)}\"\n        job_folder = DATA_FOLDER / \"finetune\" / job_id\n        job_folder.mkdir(parents=True, exist_ok=True)\n\n        # Either use the provided config file template or load one predefined one\n        if Path(format).exists():\n            config_template_path = Path(format)\n        else:\n            configs = ETC_FOLDER / \"finetune\"\n            config_template_path = configs / f\"{format}.yml\"\n\n        if not config_template_path.exists():\n            raise FileNotFoundError(f\"Config file not found: {config_template_path}\")\n\n        CONFIG_TEMPLATE = config_template_path.read_text()  # noqa: N806\n\n        # Download model\n        model_path = get_model(model)\n\n        # Download tokenizer\n        tokenizer_path = registry.download(tokenizer) / \"tokenizer.model\"\n        assert tokenizer_path.exists(), f\"tokenizer.model not found in {tokenizer_path}\"\n\n        # Download checkpoint if any\n        checkpoint_path = get_model(checkpoint) if checkpoint else \"null\"\n        resume_checkpoint = checkpoint_path != \"null\"\n\n        # Download dataset\n        dataset_path = get_dataset(dataset)\n\n        # Set up output directories\n        checkpoint_output_dir = job_folder / \"checkpoint_output\"\n        logging_output_dir = job_folder / \"logs\"\n        logging_output_dir.mkdir(parents=True, exist_ok=True)\n\n        # Prepare config file\n        dataset_args_dict = deepcopy(dataset_kwargs)\n\n        dataset_args_dict[\"_component_\"] = dataset_args_dict.pop(\"method\")\n        dataset_args_dict[\"source\"] = str(dataset_path.absolute())\n        dataset_args = \"\\n\".join(f\"  {key}: {value}\" for key, value in dataset_args_dict.items())\n\n        config = job_folder / \"config.yaml\"\n        with open(config, \"w\") as f:\n            f.write(\n                CONFIG_TEMPLATE.format(\n                    TOKENIZER=str(tokenizer_path),\n                    MODEL=str(model_path),\n                    RECIPE_CHECKPOINT=checkpoint_path,\n                    RESUME_FROM_CHECKPOINT=resume_checkpoint,\n                    CHECKPOINT_OUTPUT_DIR=str(checkpoint_output_dir),\n                    DATASET_ARGS=dataset_args,\n                    LOGGING_OUTPUT_DIR=str(logging_output_dir),\n                )\n            )\n\n        # Spawn background thread to read logs and push to database\n        threading.Thread(target=find_new_logs_background, args=(logging_output_dir, job_id)).start()\n\n        print(\"Starting job at\", job_folder)\n        if num_nodes == 1:\n            run(\n                [\n                    \"tune\",\n                    \"run\",\n                    \"--nproc_per_node\",\n                    str(num_procs),\n                    \"lora_finetune_distributed\",\n                    \"--config\",\n                    str(config),\n                ]\n            )\n        else:\n            # Fetch rank and master addr from environment variables\n            raise NotImplementedError()\n\n        global BACKGROUND_PROCESS\n        BACKGROUND_PROCESS = False\n\n        if upload_checkpoint:\n            registry.upload(\n                job_folder,\n                EntryMetadata.from_dict(\n                    {\n                        \"name\": f\"finetune-{job_id}\",\n                        \"version\": \"0.0.1\",\n                        \"description\": f\"Finetuned checkpoint from base mode {model} using dataset {dataset}\",\n                        \"category\": \"finetune\",\n                        \"tags\": [\"finetune\", f\"base-model-{model}\", f\"base-dataset-{dataset}\"],\n                        \"details\": dict(\n                            model=model,\n                            tokenizer=tokenizer,\n                            dataset=dataset,\n                            num_procs=num_procs,\n                            format=format,\n                            num_nodes=num_nodes,\n                            checkpoint=checkpoint,\n                            **dataset_kwargs,\n                        ),\n                        \"show_entry\": True,\n                    }\n                ),\n                show_progress=True,\n            )\n\n    def inspect(self, job_id: str) -&gt; None:  # noqa: D102\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/#nearai.finetune.FinetuneCli.start","title":"start","text":"<pre><code>start(model: str, tokenizer: str, dataset: str, num_procs: int, format: str, upload_checkpoint: bool = True, num_nodes: int = 1, job_id: Optional[str] = None, checkpoint: Optional[str] = None, **dataset_kwargs: Any) -&gt; None\n</code></pre> <p>Start a finetuning job on the current node.</p> <pre><code>model: Name of a model in the registry. Base model to finetune.\ntokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\ndataset: Name of a dataset in the registry.\nnum_procs: Number of GPUs to use for training\nformat: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\nupload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\nnum_nodes: Number of nodes to use for training. Default is 1.\njob_id: Unique identifier for the job. Default is None.\ncheckpoint: Name of the model checkpoint to start from. Default is None.\ndataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n</code></pre> Source code in <code>nearai/finetune/__init__.py</code> <pre><code>def start(\n    self,\n    model: str,\n    tokenizer: str,\n    dataset: str,\n    num_procs: int,\n    format: str,\n    upload_checkpoint: bool = True,\n    num_nodes: int = 1,\n    job_id: Optional[str] = None,\n    checkpoint: Optional[str] = None,\n    **dataset_kwargs: Any,\n) -&gt; None:\n    \"\"\"Start a finetuning job on the current node.\n\n    Args:\n    ----\n        model: Name of a model in the registry. Base model to finetune.\n        tokenizer: Name of a tokenizer in the registry. Using tokenizer.model format.\n        dataset: Name of a dataset in the registry.\n        num_procs: Number of GPUs to use for training\n        format: Name of the configuration file to use. For example llama3-70b, llama3-8b. Valid options are in etc/finetune.\n        upload_checkpoint: Whether to upload the checkpoint to the registry. Default is True.\n        num_nodes: Number of nodes to use for training. Default is 1.\n        job_id: Unique identifier for the job. Default is None.\n        checkpoint: Name of the model checkpoint to start from. Default is None.\n        dataset_kwargs: Additional keyword arguments to pass to the dataset constructor.\n\n    \"\"\"  # noqa: E501\n    from nearai.dataset import get_dataset\n\n    assert num_nodes &gt;= 1\n\n    # Prepare job id folder\n    if job_id is None:\n        job_id = \"job\"\n    job_id = f\"{job_id}-{timestamp()}-{randint(10**8, 10**9 - 1)}\"\n    job_folder = DATA_FOLDER / \"finetune\" / job_id\n    job_folder.mkdir(parents=True, exist_ok=True)\n\n    # Either use the provided config file template or load one predefined one\n    if Path(format).exists():\n        config_template_path = Path(format)\n    else:\n        configs = ETC_FOLDER / \"finetune\"\n        config_template_path = configs / f\"{format}.yml\"\n\n    if not config_template_path.exists():\n        raise FileNotFoundError(f\"Config file not found: {config_template_path}\")\n\n    CONFIG_TEMPLATE = config_template_path.read_text()  # noqa: N806\n\n    # Download model\n    model_path = get_model(model)\n\n    # Download tokenizer\n    tokenizer_path = registry.download(tokenizer) / \"tokenizer.model\"\n    assert tokenizer_path.exists(), f\"tokenizer.model not found in {tokenizer_path}\"\n\n    # Download checkpoint if any\n    checkpoint_path = get_model(checkpoint) if checkpoint else \"null\"\n    resume_checkpoint = checkpoint_path != \"null\"\n\n    # Download dataset\n    dataset_path = get_dataset(dataset)\n\n    # Set up output directories\n    checkpoint_output_dir = job_folder / \"checkpoint_output\"\n    logging_output_dir = job_folder / \"logs\"\n    logging_output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Prepare config file\n    dataset_args_dict = deepcopy(dataset_kwargs)\n\n    dataset_args_dict[\"_component_\"] = dataset_args_dict.pop(\"method\")\n    dataset_args_dict[\"source\"] = str(dataset_path.absolute())\n    dataset_args = \"\\n\".join(f\"  {key}: {value}\" for key, value in dataset_args_dict.items())\n\n    config = job_folder / \"config.yaml\"\n    with open(config, \"w\") as f:\n        f.write(\n            CONFIG_TEMPLATE.format(\n                TOKENIZER=str(tokenizer_path),\n                MODEL=str(model_path),\n                RECIPE_CHECKPOINT=checkpoint_path,\n                RESUME_FROM_CHECKPOINT=resume_checkpoint,\n                CHECKPOINT_OUTPUT_DIR=str(checkpoint_output_dir),\n                DATASET_ARGS=dataset_args,\n                LOGGING_OUTPUT_DIR=str(logging_output_dir),\n            )\n        )\n\n    # Spawn background thread to read logs and push to database\n    threading.Thread(target=find_new_logs_background, args=(logging_output_dir, job_id)).start()\n\n    print(\"Starting job at\", job_folder)\n    if num_nodes == 1:\n        run(\n            [\n                \"tune\",\n                \"run\",\n                \"--nproc_per_node\",\n                str(num_procs),\n                \"lora_finetune_distributed\",\n                \"--config\",\n                str(config),\n            ]\n        )\n    else:\n        # Fetch rank and master addr from environment variables\n        raise NotImplementedError()\n\n    global BACKGROUND_PROCESS\n    BACKGROUND_PROCESS = False\n\n    if upload_checkpoint:\n        registry.upload(\n            job_folder,\n            EntryMetadata.from_dict(\n                {\n                    \"name\": f\"finetune-{job_id}\",\n                    \"version\": \"0.0.1\",\n                    \"description\": f\"Finetuned checkpoint from base mode {model} using dataset {dataset}\",\n                    \"category\": \"finetune\",\n                    \"tags\": [\"finetune\", f\"base-model-{model}\", f\"base-dataset-{dataset}\"],\n                    \"details\": dict(\n                        model=model,\n                        tokenizer=tokenizer,\n                        dataset=dataset,\n                        num_procs=num_procs,\n                        format=format,\n                        num_nodes=num_nodes,\n                        checkpoint=checkpoint,\n                        **dataset_kwargs,\n                    ),\n                    \"show_entry\": True,\n                }\n            ),\n            show_progress=True,\n        )\n</code></pre>"},{"location":"api/#nearai.finetune.parse_line","title":"parse_line","text":"<pre><code>parse_line(line: str) -&gt; Tuple[int, dict[str, float]]\n</code></pre> <p>Example of line to be parsed.</p> <p>Step 33 | loss:1.5400923490524292 lr:9.9e-05 tokens_per_second_per_gpu:101.22285588141214</p> Source code in <code>nearai/finetune/__init__.py</code> <pre><code>def parse_line(line: str) -&gt; Tuple[int, dict[str, float]]:\n    \"\"\"Example of line to be parsed.\n\n    Step 33 | loss:1.5400923490524292 lr:9.9e-05 tokens_per_second_per_gpu:101.22285588141214\n    \"\"\"\n    step_raw, metrics_raw = map(str.strip, line.strip(\" \\n\").split(\"|\"))\n    step = int(step_raw.split(\" \")[-1])\n    metrics = {metric[0]: float(metric[1]) for metric in map(lambda metric: metric.split(\":\"), metrics_raw.split(\" \"))}\n    return step, metrics\n</code></pre>"},{"location":"api/#nearai.finetune.text_completion","title":"text_completion","text":""},{"location":"api/#nearai.finetune.text_completion.TextCompletionDataset","title":"TextCompletionDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Freeform dataset for any unstructured text corpus. Quickly load any dataset from Hugging Face or local disk and tokenize it for your model.</p> <pre><code>tokenizer (BaseTokenizer): Tokenizer used to encode data. Tokenize must implement an ``encode`` and ``decode`` method.\nsource (str): path string of dataset, anything supported by Hugging Face's ``load_dataset``\n    (https://huggingface.co/docs/datasets/en/package_reference/loading_methods#datasets.load_dataset.path)\ncolumn (str): name of column in the sample that contains the text data. This is typically required\n    for Hugging Face datasets or tabular data. For local datasets with a single column, use the default \"text\",\n    which is what is assigned by Hugging Face datasets when loaded into memory. Default is \"text\".\nmax_seq_len (Optional[int]): Maximum number of tokens in the returned input and label token id lists.\n    Default is None, disabling truncation. We recommend setting this to the highest you can fit in memory\n    and is supported by the model. For example, llama2-7B supports up to 4096 for sequence length.\n**load_dataset_kwargs (Dict[str, Any]): additional keyword arguments to pass to ``load_dataset``.\n</code></pre> Source code in <code>nearai/finetune/text_completion.py</code> <pre><code>class TextCompletionDataset(Dataset):\n    \"\"\"Freeform dataset for any unstructured text corpus. Quickly load any dataset from Hugging Face or local disk and tokenize it for your model.\n\n    Args:\n    ----\n        tokenizer (BaseTokenizer): Tokenizer used to encode data. Tokenize must implement an ``encode`` and ``decode`` method.\n        source (str): path string of dataset, anything supported by Hugging Face's ``load_dataset``\n            (https://huggingface.co/docs/datasets/en/package_reference/loading_methods#datasets.load_dataset.path)\n        column (str): name of column in the sample that contains the text data. This is typically required\n            for Hugging Face datasets or tabular data. For local datasets with a single column, use the default \"text\",\n            which is what is assigned by Hugging Face datasets when loaded into memory. Default is \"text\".\n        max_seq_len (Optional[int]): Maximum number of tokens in the returned input and label token id lists.\n            Default is None, disabling truncation. We recommend setting this to the highest you can fit in memory\n            and is supported by the model. For example, llama2-7B supports up to 4096 for sequence length.\n        **load_dataset_kwargs (Dict[str, Any]): additional keyword arguments to pass to ``load_dataset``.\n\n    \"\"\"  # noqa: E501\n\n    def __init__(  # noqa: D107\n        self,\n        tokenizer: BaseTokenizer,\n        source: str,\n        column: str = \"text\",\n        split: Optional[str] = None,\n        max_seq_len: Optional[int] = None,\n        **load_dataset_kwargs: Dict[str, Any],\n    ) -&gt; None:\n        self._tokenizer = tokenizer\n        self._data = load_from_disk(source, **load_dataset_kwargs)\n        if split is not None:\n            self._data = self._data[split]\n        self.max_seq_len = max_seq_len\n        self._column = column\n\n    def __len__(self) -&gt; int:  # noqa: D105\n        return len(self._data)\n\n    def __getitem__(self, index: int) -&gt; Dict[str, List[int]]:  # noqa: D105\n        sample = self._data[index]\n        return self._prepare_sample(sample)\n\n    def _prepare_sample(self, sample: Mapping[str, Any]) -&gt; Dict[str, List[int]]:\n        prompt = sample[self._column]\n        tokens = self._tokenizer.encode(text=prompt, add_bos=True, add_eos=True)\n\n        # Truncate if needed, but don't coerce EOS id\n        if self.max_seq_len is not None:\n            tokens = truncate(tokens, self.max_seq_len - 1)\n\n        # No need to offset labels by 1 - happens in the recipe\n        labels = tokens.copy()\n\n        return {\"tokens\": tokens, \"labels\": labels}\n</code></pre>"},{"location":"api/#nearai.finetune.text_completion.truncate","title":"truncate","text":"<pre><code>truncate(tokens: List[Any], max_seq_len: int, eos_id: Optional[Any] = None) -&gt; List[Any]\n</code></pre> <p>Truncate a list of tokens to a maximum length. If eos_id is provided, the last token will be replaced with eos_id.</p> <pre><code>tokens (List[Any]): list of tokens to truncate\nmax_seq_len (int): maximum length of the list\neos_id (Optional[Any]): token to replace the last token with. If None, the\n    last token will not be replaced. Default is None.\n</code></pre> <pre><code>List[Any]: truncated list of tokens\n</code></pre> Source code in <code>nearai/finetune/text_completion.py</code> <pre><code>def truncate(\n    tokens: List[Any],\n    max_seq_len: int,\n    eos_id: Optional[Any] = None,\n) -&gt; List[Any]:\n    \"\"\"Truncate a list of tokens to a maximum length. If eos_id is provided, the last token will be replaced with eos_id.\n\n    Args:\n    ----\n        tokens (List[Any]): list of tokens to truncate\n        max_seq_len (int): maximum length of the list\n        eos_id (Optional[Any]): token to replace the last token with. If None, the\n            last token will not be replaced. Default is None.\n\n    Returns:\n    -------\n        List[Any]: truncated list of tokens\n\n    \"\"\"  # noqa: E501\n    tokens_truncated = tokens[:max_seq_len]\n    if eos_id is not None and tokens_truncated[-1] != eos_id:\n        tokens_truncated[-1] = eos_id\n    return tokens_truncated\n</code></pre>"},{"location":"api/#nearai.hub","title":"hub","text":""},{"location":"api/#nearai.hub.Hub","title":"Hub","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/hub.py</code> <pre><code>class Hub(object):\n    def __init__(self, config: Config) -&gt; None:\n        \"\"\"Initializes the Hub class with the given configuration.\"\"\"\n        self.info = None\n        self.provider = None\n        self.model = None\n        self.endpoint = None\n        self.query = None\n        self._config = config\n\n    def parse_hub_chat_params(self, kwargs):\n        \"\"\"Parses and sets instance attributes from the given keyword arguments, using default values if needed.\"\"\"\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        self.query = kwargs.get(\"query\")\n        self.endpoint = kwargs.get(\"endpoint\", f\"{self._config.nearai_hub.base_url}/chat/completions\")\n        self.model = kwargs.get(\"model\", self._config.nearai_hub.default_model)\n        self.provider = kwargs.get(\"provider\", self._config.nearai_hub.default_provider)\n        self.info = kwargs.get(\"info\", False)\n\n    def chat(self, kwargs):\n        \"\"\"Processes a chat request by sending parameters to the NearAI Hub and printing the response.\"\"\"\n        try:\n            self.parse_hub_chat_params(kwargs)\n\n            if not self.query:\n                return print(\"Error: 'query' is required for the `hub chat` command.\")\n\n            if self._config.nearai_hub is None:\n                self._config.nearai_hub = NearAiHubConfig()\n\n            data = {\n                \"max_tokens\": 256,\n                \"temperature\": 1,\n                \"frequency_penalty\": 0,\n                \"n\": 1,\n                \"messages\": [{\"role\": \"user\", \"content\": str(self.query)}],\n                \"model\": self.model,\n            }\n\n            auth = self._config.auth\n\n            if self._config.nearai_hub.login_with_near:\n                bearer_token = auth.generate_bearer_token()\n                headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {bearer_token}\"}\n\n                data[\"provider\"] = self.provider\n            elif self._config.nearai_hub.api_key:\n                headers = {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": \"Bearer {}\".format(self._config.nearai_hub.api_key),\n                }\n            else:\n                return print(\"Illegal NearAI Hub Config\")\n\n            if self.info:\n                print(f\"Requesting hub using NEAR Account {auth.account_id}\")\n\n            response = requests.post(self.endpoint, headers=headers, data=json.dumps(data))\n\n            completion = response.json()\n\n            print(completion[\"choices\"][0][\"message\"][\"content\"])\n\n        except Exception as e:\n            print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"api/#nearai.hub.Hub.__init__","title":"__init__","text":"<pre><code>__init__(config: Config) -&gt; None\n</code></pre> <p>Initializes the Hub class with the given configuration.</p> Source code in <code>nearai/hub.py</code> <pre><code>def __init__(self, config: Config) -&gt; None:\n    \"\"\"Initializes the Hub class with the given configuration.\"\"\"\n    self.info = None\n    self.provider = None\n    self.model = None\n    self.endpoint = None\n    self.query = None\n    self._config = config\n</code></pre>"},{"location":"api/#nearai.hub.Hub.chat","title":"chat","text":"<pre><code>chat(kwargs)\n</code></pre> <p>Processes a chat request by sending parameters to the NearAI Hub and printing the response.</p> Source code in <code>nearai/hub.py</code> <pre><code>def chat(self, kwargs):\n    \"\"\"Processes a chat request by sending parameters to the NearAI Hub and printing the response.\"\"\"\n    try:\n        self.parse_hub_chat_params(kwargs)\n\n        if not self.query:\n            return print(\"Error: 'query' is required for the `hub chat` command.\")\n\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        data = {\n            \"max_tokens\": 256,\n            \"temperature\": 1,\n            \"frequency_penalty\": 0,\n            \"n\": 1,\n            \"messages\": [{\"role\": \"user\", \"content\": str(self.query)}],\n            \"model\": self.model,\n        }\n\n        auth = self._config.auth\n\n        if self._config.nearai_hub.login_with_near:\n            bearer_token = auth.generate_bearer_token()\n            headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {bearer_token}\"}\n\n            data[\"provider\"] = self.provider\n        elif self._config.nearai_hub.api_key:\n            headers = {\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": \"Bearer {}\".format(self._config.nearai_hub.api_key),\n            }\n        else:\n            return print(\"Illegal NearAI Hub Config\")\n\n        if self.info:\n            print(f\"Requesting hub using NEAR Account {auth.account_id}\")\n\n        response = requests.post(self.endpoint, headers=headers, data=json.dumps(data))\n\n        completion = response.json()\n\n        print(completion[\"choices\"][0][\"message\"][\"content\"])\n\n    except Exception as e:\n        print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"api/#nearai.hub.Hub.parse_hub_chat_params","title":"parse_hub_chat_params","text":"<pre><code>parse_hub_chat_params(kwargs)\n</code></pre> <p>Parses and sets instance attributes from the given keyword arguments, using default values if needed.</p> Source code in <code>nearai/hub.py</code> <pre><code>def parse_hub_chat_params(self, kwargs):\n    \"\"\"Parses and sets instance attributes from the given keyword arguments, using default values if needed.\"\"\"\n    if self._config.nearai_hub is None:\n        self._config.nearai_hub = NearAiHubConfig()\n\n    self.query = kwargs.get(\"query\")\n    self.endpoint = kwargs.get(\"endpoint\", f\"{self._config.nearai_hub.base_url}/chat/completions\")\n    self.model = kwargs.get(\"model\", self._config.nearai_hub.default_model)\n    self.provider = kwargs.get(\"provider\", self._config.nearai_hub.default_provider)\n    self.info = kwargs.get(\"info\", False)\n</code></pre>"},{"location":"api/#nearai.lib","title":"lib","text":""},{"location":"api/#nearai.lib.parse_location","title":"parse_location","text":"<pre><code>parse_location(entry_location: str) -&gt; EntryLocation\n</code></pre> <p>Create a EntryLocation from a string in the format namespace/name/version.</p> Source code in <code>nearai/lib.py</code> <pre><code>def parse_location(entry_location: str) -&gt; EntryLocation:\n    \"\"\"Create a EntryLocation from a string in the format namespace/name/version.\"\"\"\n    match = entry_location_pattern.match(entry_location)\n\n    if match is None:\n        raise ValueError(f\"Invalid entry format: {entry_location}. Should have the format &lt;namespace&gt;/&lt;name&gt;/&lt;version&gt;\")\n\n    return EntryLocation(\n        namespace=match.group(\"namespace\"),\n        name=match.group(\"name\"),\n        version=match.group(\"version\"),\n    )\n</code></pre>"},{"location":"api/#nearai.login","title":"login","text":""},{"location":"api/#nearai.login.AuthHandler","title":"AuthHandler","text":"<p>               Bases: <code>SimpleHTTPRequestHandler</code></p> Source code in <code>nearai/login.py</code> <pre><code>class AuthHandler(http.server.SimpleHTTPRequestHandler):\n    def log_message(self, format, *args):\n        \"\"\"Webserver logging method.\"\"\"\n        pass  # Override to suppress logging\n\n    def do_GET(self):  # noqa: N802\n        \"\"\"Webserver GET method.\"\"\"\n        global NONCE, PORT\n\n        script_path = Path(__file__).resolve()\n        assets_folder = script_path.parent / \"assets\"\n\n        if self.path.startswith(\"/capture\"):\n            with open(os.path.join(assets_folder, \"auth_capture.html\"), \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(content.encode(\"utf-8\"))\n\n        if self.path.startswith(\"/auth\"):\n            parsed_url = urlparse.urlparse(self.path)\n            fragment = parsed_url.query\n            params = urlparse.parse_qs(fragment)\n\n            required_params = [\"accountId\", \"signature\", \"publicKey\"]\n\n            if all(param in params for param in required_params):\n                update_auth_config(\n                    params[\"accountId\"][0],\n                    params[\"signature\"][0],\n                    params[\"publicKey\"][0],\n                    callback_url=generate_callback_url(PORT),\n                    nonce=NONCE,\n                )\n            else:\n                print(\"Required parameters not found\")\n\n            with open(os.path.join(assets_folder, \"auth_complete.html\"), \"r\", encoding=\"utf-8\") as file:\n                content = file.read()\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(content.encode(\"utf-8\"))\n\n            # Give the server some time to read the response before shutting it down\n            def shutdown_server():\n                global httpd\n                time.sleep(2)  # Wait 2 seconds before shutting down\n                if httpd:\n                    httpd.shutdown()\n\n            threading.Thread(target=shutdown_server).start()\n</code></pre>"},{"location":"api/#nearai.login.AuthHandler.do_GET","title":"do_GET","text":"<pre><code>do_GET()\n</code></pre> <p>Webserver GET method.</p> Source code in <code>nearai/login.py</code> <pre><code>def do_GET(self):  # noqa: N802\n    \"\"\"Webserver GET method.\"\"\"\n    global NONCE, PORT\n\n    script_path = Path(__file__).resolve()\n    assets_folder = script_path.parent / \"assets\"\n\n    if self.path.startswith(\"/capture\"):\n        with open(os.path.join(assets_folder, \"auth_capture.html\"), \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(content.encode(\"utf-8\"))\n\n    if self.path.startswith(\"/auth\"):\n        parsed_url = urlparse.urlparse(self.path)\n        fragment = parsed_url.query\n        params = urlparse.parse_qs(fragment)\n\n        required_params = [\"accountId\", \"signature\", \"publicKey\"]\n\n        if all(param in params for param in required_params):\n            update_auth_config(\n                params[\"accountId\"][0],\n                params[\"signature\"][0],\n                params[\"publicKey\"][0],\n                callback_url=generate_callback_url(PORT),\n                nonce=NONCE,\n            )\n        else:\n            print(\"Required parameters not found\")\n\n        with open(os.path.join(assets_folder, \"auth_complete.html\"), \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(content.encode(\"utf-8\"))\n\n        # Give the server some time to read the response before shutting it down\n        def shutdown_server():\n            global httpd\n            time.sleep(2)  # Wait 2 seconds before shutting down\n            if httpd:\n                httpd.shutdown()\n\n        threading.Thread(target=shutdown_server).start()\n</code></pre>"},{"location":"api/#nearai.login.AuthHandler.log_message","title":"log_message","text":"<pre><code>log_message(format, *args)\n</code></pre> <p>Webserver logging method.</p> Source code in <code>nearai/login.py</code> <pre><code>def log_message(self, format, *args):\n    \"\"\"Webserver logging method.\"\"\"\n    pass  # Override to suppress logging\n</code></pre>"},{"location":"api/#nearai.login.find_open_port","title":"find_open_port","text":"<pre><code>find_open_port() -&gt; int\n</code></pre> <p>Finds and returns an open port number by binding to a free port on the local machine.</p> Source code in <code>nearai/login.py</code> <pre><code>def find_open_port() -&gt; int:\n    \"\"\"Finds and returns an open port number by binding to a free port on the local machine.\"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((\"\", 0))\n        return s.getsockname()[1]\n</code></pre>"},{"location":"api/#nearai.login.generate_and_save_signature","title":"generate_and_save_signature","text":"<pre><code>generate_and_save_signature(account_id, private_key)\n</code></pre> <p>Generates a signature for the given account ID and private key, then updates the auth configuration.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_and_save_signature(account_id, private_key):\n    \"\"\"Generates a signature for the given account ID and private key, then updates the auth configuration.\"\"\"\n    nonce = generate_nonce()\n    payload = near.Payload(MESSAGE, nonce, RECIPIENT, None)\n\n    signature, public_key = near.create_signature(private_key, payload)\n\n    if update_auth_config(account_id, signature, public_key, None, nonce):\n        print_login_status()\n</code></pre>"},{"location":"api/#nearai.login.generate_callback_url","title":"generate_callback_url","text":"<pre><code>generate_callback_url(port)\n</code></pre> <p>Generates a callback URL using the specified port number.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_callback_url(port):\n    \"\"\"Generates a callback URL using the specified port number.\"\"\"\n    return f\"http://localhost:{port}/capture\"\n</code></pre>"},{"location":"api/#nearai.login.generate_nonce","title":"generate_nonce","text":"<pre><code>generate_nonce()\n</code></pre> <p>Generates a nonce based on the current time in milliseconds.</p> Source code in <code>nearai/login.py</code> <pre><code>def generate_nonce():\n    \"\"\"Generates a nonce based on the current time in milliseconds.\"\"\"\n    return str(int(time.time() * 1000))\n</code></pre>"},{"location":"api/#nearai.login.login_with_file_credentials","title":"login_with_file_credentials","text":"<pre><code>login_with_file_credentials(account_id)\n</code></pre> <p>Logs in using credentials from a file for the specified account ID, generating and saving a signature.</p> Source code in <code>nearai/login.py</code> <pre><code>def login_with_file_credentials(account_id):\n    \"\"\"Logs in using credentials from a file for the specified account ID, generating and saving a signature.\"\"\"\n    file_path = os.path.expanduser(os.path.join(\"~/.near-credentials/\", \"mainnet\", f\"{account_id}.json\"))\n\n    if os.path.exists(file_path):\n        with open(file_path, \"r\") as file:\n            content = file.read()\n            account_data = json.loads(content)\n            private_key = account_data.get(\"private_key\", None)\n            if not private_key:\n                return print(f\"Private key is missing for {account_id} on mainnet\")\n            generate_and_save_signature(account_id, account_data[\"private_key\"])\n\n    else:\n        return print(f\"Account data is missing for {account_id}\")\n</code></pre>"},{"location":"api/#nearai.login.login_with_near_auth","title":"login_with_near_auth","text":"<pre><code>login_with_near_auth(remote, auth_url)\n</code></pre> <p>Initiates the login process using NEAR authentication, either starting a local server to handle the callback or providing a URL for remote authentication.</p> Source code in <code>nearai/login.py</code> <pre><code>def login_with_near_auth(remote, auth_url):\n    \"\"\"Initiates the login process using NEAR authentication, either starting a local server to handle the callback or providing a URL for remote authentication.\"\"\"  # noqa: E501\n    global NONCE, PORT\n    NONCE = generate_nonce()\n\n    params = {\n        \"message\": MESSAGE,\n        \"nonce\": NONCE,\n        \"recipient\": RECIPIENT,\n    }\n\n    if not remote:\n        PORT = find_open_port()\n\n        global httpd\n        with socketserver.TCPServer((\"\", PORT), AuthHandler) as httpd:\n            params[\"callbackUrl\"] = f\"http://localhost:{PORT}/capture\"\n\n            encoded_params = urlparse.urlencode(params)\n\n            print_url_message(f\"{auth_url}?{encoded_params}\")\n\n            httpd.serve_forever()\n\n    else:\n        encoded_params = urlparse.urlencode(params)\n\n        print_url_message(f\"{auth_url}?{encoded_params}\")\n        print(\"After visiting the URL, follow the instructions to save your auth signature\")\n</code></pre>"},{"location":"api/#nearai.login.print_login_status","title":"print_login_status","text":"<pre><code>print_login_status()\n</code></pre> <p>Prints the current authentication status if available in the config file.</p> Source code in <code>nearai/login.py</code> <pre><code>def print_login_status():\n    \"\"\"Prints the current authentication status if available in the config file.\"\"\"\n    config = load_config_file()\n    if config.get(\"auth\") and config[\"auth\"].get(\"account_id\"):\n        print(f'Auth data for: {config[\"auth\"][\"account_id\"]}')\n        print(f'signature: {config[\"auth\"][\"signature\"]}')\n        print(f'public_key: {config[\"auth\"][\"public_key\"]}')\n        print(f'nonce: {config[\"auth\"][\"nonce\"]}')\n        print(f'message: {config[\"auth\"][\"message\"]}')\n        print(f'recipient: {config[\"auth\"][\"recipient\"]}')\n    else:\n        print(\"Near auth details not found\")\n</code></pre>"},{"location":"api/#nearai.login.print_url_message","title":"print_url_message","text":"<pre><code>print_url_message(url)\n</code></pre> <p>Prints a message instructing the user to visit the given URL to complete the login process.</p> Source code in <code>nearai/login.py</code> <pre><code>def print_url_message(url):\n    \"\"\"Prints a message instructing the user to visit the given URL to complete the login process.\"\"\"\n    print(f\"Please visit the following URL to complete the login process: {url}\")\n</code></pre>"},{"location":"api/#nearai.login.update_auth_config","title":"update_auth_config","text":"<pre><code>update_auth_config(account_id, signature, public_key, callback_url, nonce)\n</code></pre> <p>Update authentication configuration if the provided signature is valid.</p> Source code in <code>nearai/login.py</code> <pre><code>def update_auth_config(account_id, signature, public_key, callback_url, nonce):\n    \"\"\"Update authentication configuration if the provided signature is valid.\"\"\"\n    if near.verify_signed_message(\n        account_id,\n        public_key,\n        signature,\n        MESSAGE,\n        nonce,\n        RECIPIENT,\n        callback_url,\n    ):\n        config = load_config_file()\n\n        auth = AuthData.model_validate(\n            {\n                \"account_id\": account_id,\n                \"signature\": signature,\n                \"public_key\": public_key,\n                \"callback_url\": callback_url,\n                \"nonce\": nonce,\n                \"recipient\": RECIPIENT,\n                \"message\": MESSAGE,\n            }\n        )\n\n        config[\"auth\"] = auth.model_dump()\n        save_config_file(config)\n\n        print(f\"Auth data has been successfully saved! You are now logged in with account ID: {account_id}\")\n        return True\n    else:\n        print(\"Signature verification failed. Abort\")\n        return False\n</code></pre>"},{"location":"api/#nearai.model","title":"model","text":""},{"location":"api/#nearai.model.get_model","title":"get_model","text":"<pre><code>get_model(name: str) -&gt; Path\n</code></pre> <p>Download the model from the registry and download it locally if it hasn't been downloaded yet.</p> <p>:param name: The name of the entry to download the model. The format should be namespace/name/version. :return: The path to the downloaded model</p> Source code in <code>nearai/model.py</code> <pre><code>def get_model(name: str) -&gt; Path:\n    \"\"\"Download the model from the registry and download it locally if it hasn't been downloaded yet.\n\n    :param name: The name of the entry to download the model. The format should be namespace/name/version.\n    :return: The path to the downloaded model\n    \"\"\"\n    return registry.download(name)\n</code></pre>"},{"location":"api/#nearai.naming","title":"naming","text":""},{"location":"api/#nearai.naming.get_canonical_name","title":"get_canonical_name","text":"<pre><code>get_canonical_name(name: str) -&gt; str\n</code></pre> <p>Returns a name that can be used for matching entities.</p> <p>Applies such transformations: 1. All letters lowercase. 2. Convert '.' between digits to 'p'. 3. Convert 'v' -&gt; '' 4. Remove all non-alphanumeric characters except between digits.     Use '_' between digits. 5. Convert 'metallama' -&gt; 'llama'. <p>e.g. \"llama-3.1-70b-instruct\" -&gt; \"llama3p1_70binstruct\"</p> Source code in <code>nearai/naming.py</code> <pre><code>def get_canonical_name(name: str) -&gt; str:\n    \"\"\"Returns a name that can be used for matching entities.\n\n    Applies such transformations:\n    1. All letters lowercase.\n    2. Convert '.' between digits to 'p'.\n    3. Convert '&lt;not letter&gt;v&lt;digit&gt;' -&gt; '&lt;not letter&gt;&lt;digit&gt;'\n    4. Remove all non-alphanumeric characters except between digits.\n        Use '_' between digits.\n    5. Convert 'metallama' -&gt; 'llama'.\n\n    e.g. \"llama-3.1-70b-instruct\" -&gt; \"llama3p1_70binstruct\"\n    \"\"\"\n    # Convert to lowercase\n    name = name.lower()\n    # Convert '.' between digits to 'p'\n    name = re.sub(r\"(\\d)\\.(\\d)\", r\"\\1p\\2\", name)\n    # Convert '&lt;digit&gt;v&lt;digit&gt;' -&gt; '&lt;digit&gt;_&lt;digit&gt;'\n    name = re.sub(r\"(\\d)v(\\d)\", r\"\\1_\\2\", name)\n    # Convert '&lt;not letter&gt;v&lt;digit&gt;' -&gt; '&lt;not letter&gt;&lt;digit&gt;'\n    name = re.sub(r\"(^|[^a-z])v(\\d)\", r\"\\1\\2\", name)\n    # Replace non-alphanumeric characters between digits with '_'\n    name = re.sub(r\"(\\d)[^a-z0-9]+(\\d)\", r\"\\1_\\2\", name)\n    # Remove remaining non-alphanumeric characters, except '_'\n    name = re.sub(r\"[^a-z0-9_]\", \"\", name)\n    # Remove any remaining underscores that are not between digits\n    name = re.sub(r\"(?&lt;!\\d)_|_(?!\\d)\", \"\", name)\n    # Convert 'metallama' to 'llama'\n    name = name.replace(\"metallama\", \"llama\")\n    return name\n</code></pre>"},{"location":"api/#nearai.registry","title":"registry","text":""},{"location":"api/#nearai.registry.Registry","title":"Registry","text":"Source code in <code>nearai/registry.py</code> <pre><code>class Registry:\n    def __init__(self):\n        \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n        self.download_folder = DATA_FOLDER / \"registry\"\n        self.api = RegistryApi()\n\n        if not self.download_folder.exists():\n            self.download_folder.mkdir(parents=True, exist_ok=True)\n\n    def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n        \"\"\"Update metadata of a entry in the registry.\"\"\"\n        result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n            BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n        )\n        return result\n\n    def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n        \"\"\"Get metadata of a entry in the registry.\"\"\"\n        try:\n            return self.api.download_metadata_v1_registry_download_metadata_post(\n                BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n            )\n        except NotFoundException:\n            return None\n\n    def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n        \"\"\"Upload a file to the registry.\"\"\"\n        with open(local_path, \"rb\") as file:\n            data = file.read()\n\n            try:\n                self.api.upload_file_v1_registry_upload_file_post(\n                    path=str(path),\n                    file=data,\n                    namespace=entry_location.namespace,\n                    name=entry_location.name,\n                    version=entry_location.version,\n                )\n                return True\n            except BadRequestException as e:\n                if isinstance(e.body, str) and \"already exists\" in e.body:\n                    return False\n\n                raise e\n\n    def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n        \"\"\"Download a file from the registry.\"\"\"\n        result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n            BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n                dict(\n                    entry_location=entry_location,\n                    path=str(path),\n                )\n            )\n        )\n\n        local_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(local_path, \"wb\") as f:\n            copyfileobj(result, f)\n\n    def download(\n        self,\n        entry_location: Union[str, EntryLocation],\n        force: bool = False,\n        show_progress: bool = False,\n        verbose: bool = True,\n    ) -&gt; Path:\n        \"\"\"Download entry from the registry locally.\"\"\"\n        if isinstance(entry_location, str):\n            entry_location = parse_location(entry_location)\n\n        download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n        if download_path.exists():\n            if not force:\n                if verbose:\n                    print(\n                        f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\"\n                    )\n                return download_path\n\n        files = registry.list_files(entry_location)\n\n        download_path.mkdir(parents=True, exist_ok=True)\n\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            raise ValueError(f\"Entry {entry_location} not found.\")\n\n        metadata_path = download_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n        for file in (pbar := tqdm(files, disable=not show_progress)):\n            pbar.set_description(file)\n            registry.download_file(entry_location, file, download_path / file)\n\n        return download_path\n\n    def upload(\n        self,\n        local_path: Path,\n        metadata: Optional[EntryMetadata] = None,\n        show_progress: bool = False,\n    ) -&gt; EntryLocation:\n        \"\"\"Upload entry to the registry.\n\n        If metadata is provided it will overwrite the metadata in the directory,\n        otherwise it will use the metadata.json found on the root of the directory.\n        \"\"\"\n        path = Path(local_path).absolute()\n\n        if not path.exists():\n            # try path in local registry if original path not exists\n            path = get_registry_folder() / local_path\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n\n        if metadata is not None:\n            with open(metadata_path, \"w\") as f:\n                f.write(metadata.model_dump_json(indent=2))\n\n        check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            plain_metadata: Dict[str, Any] = json.load(f)\n\n        namespace = get_namespace(local_path)\n        name = plain_metadata.pop(\"name\")\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=name,\n                version=plain_metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n        source = entry_metadata.details.get(\"_source\", None)\n\n        if source is not None:\n            print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n            exit(1)\n\n        if self.info(entry_location) is None:\n            # New entry location. Check for similar names in registry.\n            entries = self.list_all_visible()\n            canonical_namespace = get_canonical_name(namespace)\n            canonical_name = get_canonical_name(name)\n\n            for entry in entries:\n                if entry.name == name and entry.namespace == namespace:\n                    break\n                if (\n                    get_canonical_name(entry.name) == canonical_name\n                    and get_canonical_name(entry.namespace) == canonical_namespace\n                ):\n                    print(f\"A registry item with a similar name already exists: {entry.namespace}/{entry.name}\")\n                    exit(1)\n\n        registry.update(entry_location, entry_metadata)\n\n        all_files = []\n        total_size = 0\n\n        # Traverse all files in the directory `path`\n        for file in path.rglob(\"*\"):\n            if not file.is_file():\n                continue\n\n            relative = file.relative_to(path)\n\n            # Don't upload metadata file.\n            if file == metadata_path:\n                continue\n\n            # Don't upload backup files.\n            if file.name.endswith(\"~\"):\n                continue\n\n            # Don't upload configuration files.\n            if relative.parts[0] == \".nearai\":\n                continue\n\n            size = file.stat().st_size\n            total_size += size\n\n            all_files.append((file, relative, size))\n\n        pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n        for file, relative, size in all_files:\n            registry.upload_file(entry_location, file, relative)\n            pbar.update(size)\n\n        return entry_location\n\n    def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n        \"\"\"List files in from an entry in the registry.\n\n        Return the relative paths to all files with respect to the root of the entry.\n        \"\"\"\n        result = self.api.list_files_v1_registry_list_files_post(\n            BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n        )\n        return [file.filename for file in result]\n\n    def list(\n        self,\n        namespace: str,\n        category: str,\n        tags: str,\n        total: int,\n        offset: int,\n        show_all: bool,\n        show_latest_version: bool,\n        starred_by: str = \"\",\n    ) -&gt; List[EntryInformation]:\n        \"\"\"List and filter entries in the registry.\"\"\"\n        return self.api.list_entries_v1_registry_list_entries_post(\n            namespace=namespace,\n            category=category,\n            tags=tags,\n            total=total,\n            offset=offset,\n            show_hidden=show_all,\n            show_latest_version=show_latest_version,\n            starred_by=starred_by,\n        )\n\n    def list_all_visible(self) -&gt; List[EntryInformation]:\n        \"\"\"List all visible entries.\"\"\"\n        total = 10000\n        entries = self.list(\"\", \"\", \"\", total, 0, False, True)\n        assert len(entries) &lt; total\n        return entries\n</code></pre>"},{"location":"api/#nearai.registry.Registry.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Create Registry object to interact with the registry programmatically.</p> Source code in <code>nearai/registry.py</code> <pre><code>def __init__(self):\n    \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n    self.download_folder = DATA_FOLDER / \"registry\"\n    self.api = RegistryApi()\n\n    if not self.download_folder.exists():\n        self.download_folder.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download","title":"download","text":"<pre><code>download(entry_location: Union[str, EntryLocation], force: bool = False, show_progress: bool = False, verbose: bool = True) -&gt; Path\n</code></pre> <p>Download entry from the registry locally.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download(\n    self,\n    entry_location: Union[str, EntryLocation],\n    force: bool = False,\n    show_progress: bool = False,\n    verbose: bool = True,\n) -&gt; Path:\n    \"\"\"Download entry from the registry locally.\"\"\"\n    if isinstance(entry_location, str):\n        entry_location = parse_location(entry_location)\n\n    download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n    if download_path.exists():\n        if not force:\n            if verbose:\n                print(\n                    f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\"\n                )\n            return download_path\n\n    files = registry.list_files(entry_location)\n\n    download_path.mkdir(parents=True, exist_ok=True)\n\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        raise ValueError(f\"Entry {entry_location} not found.\")\n\n    metadata_path = download_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        f.write(metadata.model_dump_json(indent=2))\n\n    for file in (pbar := tqdm(files, disable=not show_progress)):\n        pbar.set_description(file)\n        registry.download_file(entry_location, file, download_path / file)\n\n    return download_path\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download_file","title":"download_file","text":"<pre><code>download_file(entry_location: EntryLocation, path: Path, local_path: Path)\n</code></pre> <p>Download a file from the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n    \"\"\"Download a file from the registry.\"\"\"\n    result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n        BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n            dict(\n                entry_location=entry_location,\n                path=str(path),\n            )\n        )\n    )\n\n    local_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(local_path, \"wb\") as f:\n        copyfileobj(result, f)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.info","title":"info","text":"<pre><code>info(entry_location: EntryLocation) -&gt; Optional[EntryMetadata]\n</code></pre> <p>Get metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n    \"\"\"Get metadata of a entry in the registry.\"\"\"\n    try:\n        return self.api.download_metadata_v1_registry_download_metadata_post(\n            BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n        )\n    except NotFoundException:\n        return None\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list","title":"list","text":"<pre><code>list(namespace: str, category: str, tags: str, total: int, offset: int, show_all: bool, show_latest_version: bool, starred_by: str = '') -&gt; List[EntryInformation]\n</code></pre> <p>List and filter entries in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list(\n    self,\n    namespace: str,\n    category: str,\n    tags: str,\n    total: int,\n    offset: int,\n    show_all: bool,\n    show_latest_version: bool,\n    starred_by: str = \"\",\n) -&gt; List[EntryInformation]:\n    \"\"\"List and filter entries in the registry.\"\"\"\n    return self.api.list_entries_v1_registry_list_entries_post(\n        namespace=namespace,\n        category=category,\n        tags=tags,\n        total=total,\n        offset=offset,\n        show_hidden=show_all,\n        show_latest_version=show_latest_version,\n        starred_by=starred_by,\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_all_visible","title":"list_all_visible","text":"<pre><code>list_all_visible() -&gt; List[EntryInformation]\n</code></pre> <p>List all visible entries.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_all_visible(self) -&gt; List[EntryInformation]:\n    \"\"\"List all visible entries.\"\"\"\n    total = 10000\n    entries = self.list(\"\", \"\", \"\", total, 0, False, True)\n    assert len(entries) &lt; total\n    return entries\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_files","title":"list_files","text":"<pre><code>list_files(entry_location: EntryLocation) -&gt; List[str]\n</code></pre> <p>List files in from an entry in the registry.</p> <p>Return the relative paths to all files with respect to the root of the entry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n    \"\"\"List files in from an entry in the registry.\n\n    Return the relative paths to all files with respect to the root of the entry.\n    \"\"\"\n    result = self.api.list_files_v1_registry_list_files_post(\n        BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n    )\n    return [file.filename for file in result]\n</code></pre>"},{"location":"api/#nearai.registry.Registry.update","title":"update","text":"<pre><code>update(entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]\n</code></pre> <p>Update metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n    \"\"\"Update metadata of a entry in the registry.\"\"\"\n    result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n        BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload","title":"upload","text":"<pre><code>upload(local_path: Path, metadata: Optional[EntryMetadata] = None, show_progress: bool = False) -&gt; EntryLocation\n</code></pre> <p>Upload entry to the registry.</p> <p>If metadata is provided it will overwrite the metadata in the directory, otherwise it will use the metadata.json found on the root of the directory.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload(\n    self,\n    local_path: Path,\n    metadata: Optional[EntryMetadata] = None,\n    show_progress: bool = False,\n) -&gt; EntryLocation:\n    \"\"\"Upload entry to the registry.\n\n    If metadata is provided it will overwrite the metadata in the directory,\n    otherwise it will use the metadata.json found on the root of the directory.\n    \"\"\"\n    path = Path(local_path).absolute()\n\n    if not path.exists():\n        # try path in local registry if original path not exists\n        path = get_registry_folder() / local_path\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n\n    if metadata is not None:\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n    check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        plain_metadata: Dict[str, Any] = json.load(f)\n\n    namespace = get_namespace(local_path)\n    name = plain_metadata.pop(\"name\")\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=name,\n            version=plain_metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n    source = entry_metadata.details.get(\"_source\", None)\n\n    if source is not None:\n        print(f\"Only default source is allowed, found: {source}. Remove details._source from metadata.\")\n        exit(1)\n\n    if self.info(entry_location) is None:\n        # New entry location. Check for similar names in registry.\n        entries = self.list_all_visible()\n        canonical_namespace = get_canonical_name(namespace)\n        canonical_name = get_canonical_name(name)\n\n        for entry in entries:\n            if entry.name == name and entry.namespace == namespace:\n                break\n            if (\n                get_canonical_name(entry.name) == canonical_name\n                and get_canonical_name(entry.namespace) == canonical_namespace\n            ):\n                print(f\"A registry item with a similar name already exists: {entry.namespace}/{entry.name}\")\n                exit(1)\n\n    registry.update(entry_location, entry_metadata)\n\n    all_files = []\n    total_size = 0\n\n    # Traverse all files in the directory `path`\n    for file in path.rglob(\"*\"):\n        if not file.is_file():\n            continue\n\n        relative = file.relative_to(path)\n\n        # Don't upload metadata file.\n        if file == metadata_path:\n            continue\n\n        # Don't upload backup files.\n        if file.name.endswith(\"~\"):\n            continue\n\n        # Don't upload configuration files.\n        if relative.parts[0] == \".nearai\":\n            continue\n\n        size = file.stat().st_size\n        total_size += size\n\n        all_files.append((file, relative, size))\n\n    pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n    for file, relative, size in all_files:\n        registry.upload_file(entry_location, file, relative)\n        pbar.update(size)\n\n    return entry_location\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload_file","title":"upload_file","text":"<pre><code>upload_file(entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool\n</code></pre> <p>Upload a file to the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n    \"\"\"Upload a file to the registry.\"\"\"\n    with open(local_path, \"rb\") as file:\n        data = file.read()\n\n        try:\n            self.api.upload_file_v1_registry_upload_file_post(\n                path=str(path),\n                file=data,\n                namespace=entry_location.namespace,\n                name=entry_location.name,\n                version=entry_location.version,\n            )\n            return True\n        except BadRequestException as e:\n            if isinstance(e.body, str) and \"already exists\" in e.body:\n                return False\n\n            raise e\n</code></pre>"},{"location":"api/#nearai.registry.get_namespace","title":"get_namespace","text":"<pre><code>get_namespace(local_path: Path) -&gt; str\n</code></pre> <p>Returns namespace of an item or user namespace.</p> Source code in <code>nearai/registry.py</code> <pre><code>def get_namespace(local_path: Path) -&gt; str:\n    \"\"\"Returns namespace of an item or user namespace.\"\"\"\n    registry_folder = get_registry_folder()\n\n    try:\n        # Check if the path matches the expected structure\n        relative_path = local_path.relative_to(registry_folder)\n        parts = relative_path.parts\n\n        # If the path has 3 parts (namespace, item_name, version),\n        # return the first part as the namespace\n        if len(parts) == 3:\n            return str(parts[0])\n    except ValueError:\n        # relative_to() raises ValueError if local_path is not relative to registry_folder\n        pass\n\n    # If we couldn't extract a namespace from the path, return the default\n    if CONFIG.auth is None:\n        raise ValueError(\"AuthData is None\")\n    return CONFIG.auth.account_id\n</code></pre>"},{"location":"api/#nearai.registry.get_registry_folder","title":"get_registry_folder","text":"<pre><code>get_registry_folder() -&gt; Path\n</code></pre> <p>Path to local registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def get_registry_folder() -&gt; Path:\n    \"\"\"Path to local registry.\"\"\"\n    return DATA_FOLDER / REGISTRY_FOLDER\n</code></pre>"},{"location":"api/#nearai.solvers","title":"solvers","text":""},{"location":"api/#nearai.solvers.DDOTSV0Solver","title":"DDOTSV0Solver","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        self.agents = [load_agent(agent) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"ddots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        # TODO: we may want to return the model used by an agent here.\n        return None\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return self.agents[0].metadata\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        return self.agents[0].namespace\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        # TODO: we may want to return the provider used by an agent here.\n        return DEFAULT_PROVIDER\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        config = deepcopy(CONFIG)\n        config.confirm_commands = False\n\n        env = DDOTSEnvironment(self.agents, problem_id, description, config)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run_task(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.GSM8KSolverStrategy","title":"GSM8KSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the GSM8K dataset.</p> Source code in <code>nearai/solvers/gsm8k_solver.py</code> <pre><code>class GSM8KSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the GSM8K dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"gsm8k\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"gsm8k\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        parsed_datum: GSM8KDatum = GSM8KDatum(**datum)\n\n        problem_shots_indices = list(range(0, self.SHOTS))\n        problem_shots = list(\n            map(\n                lambda i: GSM8KDatum(**self.dataset_ref[\"train\"][i]).model_dump(),\n                problem_shots_indices,\n            )\n        )\n        res: ModelResponse = cast(\n            ModelResponse,\n            self.completion_fn(\n                model=self.model,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": dedent(\n                            \"\"\"\n                    You are a helpful assistant. You're goal is to answer word based math questions.\n                    \"\"\"\n                            + \"\\n\\n\"\n                            + \"Here are some examples of math questions and their answers:\"\n                            + \"\\n\\n\".join(\n                                [f\"Question: {shot['question']}\\nAnswer: {shot['answer']}\" for shot in problem_shots]\n                            )\n                            + \"\\n\\n\"\n                            + \"Now, answer the next question provided in the user prompt. \"\n                            + \"Think step by step about how to solve the problem. \"\n                            + \"Then, provide the answer.\"\n                        ),\n                    },\n                    {\"role\": \"user\", \"content\": parsed_datum.question},\n                ],\n            ),\n        )\n        res_output = str(cast(List[Choices], res.choices)[0].message.content).strip()\n        res_refined: ModelResponse = cast(\n            ModelResponse,\n            self.completion_fn(\n                model=self.model,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": dedent(\n                            f\"\"\"\n                    You are a helpful assistant. You're goal is to answer math questions.\n\n                    You have just answered a math question with the following response:\n\n                    --- BEGIN RESPONSE ---\n                    {res_output}\n                    --- END RESPONSE ---\n\n                    Please refine your answer.\n\n                    Only output the final number *without units* as your answer. Nothing else.\n                    \"\"\"\n                        ),\n                    },\n                ],\n            ),\n        )\n\n        ## cleanup the output\n        res_refined_output = str(cast(List[Choices], res_refined.choices)[0].message.content).strip()\n        res_refined_output = res_refined_output.replace(\"$\", \"\").replace(\",\", \"\")\n        if \" \" in res_refined_output:\n            res_refined_output = res_refined_output.split(\" \")[0]\n        try:\n            res_refined_output = str(int(res_refined_output))\n        except Exception:\n            pass\n        try:\n            res_refined_output = str(int(float(res_refined_output)))\n        except Exception:\n            pass\n\n        refined_answer = parsed_datum.answer.replace(\"$\", \"\").replace(\",\", \"\")\n        print(res_refined_output, refined_answer)\n        return res_refined_output == refined_answer\n</code></pre>"},{"location":"api/#nearai.solvers.HellaswagSolverStrategy","title":"HellaswagSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"hellaswag\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.LiveBenchSolverStrategy","title":"LiveBenchSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the live bench dataset.</p> Source code in <code>nearai/solvers/livebench_solver.py</code> <pre><code>class LiveBenchSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the live bench dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: str, model: str, step: str = \"all\"\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        assert \"/\" not in model\n        self.model = model\n        self.step = step\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"live_bench\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"near.ai/live_bench/1.0.0\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def get_custom_tasks(self) -&gt; List[dict]:  # noqa: D102\n        return [{\"summary\": \"all\"}]\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:  # noqa: D102\n        return SolverScoringMethod.Custom\n\n    def solve(self, _datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        if self.step == \"gen_model_answer\":\n            self.gen_model_answer()\n            return True, {}\n        if self.step == \"gen_ground_truth_judgement\":\n            return self.gen_ground_truth_judgement(), {}\n        if self.step == \"show_livebench_results\":\n            return self.show_livebench_results()\n        if self.step == \"all\":\n            self.gen_model_answer()\n            if not self.gen_ground_truth_judgement():\n                return False, {}\n            return self.show_livebench_results()\n        return False, {}\n\n    def gen_model_answer(self) -&gt; None:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_model_answer -----------\")\n        print(\"\")\n        list_of_question_files = glob.glob(f\"{self.dataset_ref}/**/question.jsonl\", recursive=True)\n        for question_file in list_of_question_files:\n            questions = load_questions_jsonl(question_file)\n            bench_name = os.path.dirname(question_file).split(str(self.dataset_ref))[-1]\n            answer_file = f\"~/.nearai/live_bench_answers/{bench_name}/model_answer/{self.model}.jsonl\"\n            print(f\"Questions from {question_file}\")\n            print(f\"Output to {answer_file}\")\n            self.run_eval(questions, answer_file)\n\n    def run_eval(self, questions, answer_file) -&gt; None:  # noqa: D102\n        answer_file = os.path.expanduser(answer_file)\n\n        # Load existing answers\n        existing_answers = set()\n        if os.path.exists(answer_file):\n            print(\n                f\"Answer file {answer_file} exists. Will skip already answered questions. Delete this file if that is not intended.\"  # noqa: E501\n            )\n            with open(answer_file, \"r\") as fin:\n                for line in fin:\n                    answer = json.loads(line)\n                    existing_answers.add(answer[\"question_id\"])\n\n        for question in tqdm(questions):\n            if question[\"question_id\"] in existing_answers:\n                continue\n            choices = self.answer_question(question)\n\n            ans_json = {\n                \"question_id\": question[\"question_id\"],\n                \"answer_id\": shortuuid.uuid(),\n                \"model_id\": self.model,\n                \"choices\": choices,\n                \"tstamp\": time.time(),\n            }\n\n            os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n            with open(answer_file, \"a\") as fout:\n                fout.write(json.dumps(ans_json) + \"\\n\")\n\n    def answer_question(self, question) -&gt; List[dict]:  # noqa: D102\n        conv = []\n        # Append system prompt here if needed.\n        turns = []\n        for qs in question[\"turns\"]:\n            conv.append({\"role\": \"user\", \"content\": qs})\n\n            completion_response = cast(\n                ModelResponse,\n                self.completion_fn(\n                    self.model,\n                    messages=[convert_message(msg) for msg in conv],\n                    temperature=0.0,\n                ),\n            )\n            output = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n            conv.append({\"role\": \"assistant\", \"content\": output})\n            turns.append(output)\n\n        return [{\"index\": 0, \"turns\": turns}]\n\n    def gen_ground_truth_judgement(self) -&gt; bool:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_ground_truth_judgement -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/gen_ground_truth_judgement.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.model, self.dataset_ref], check=True)\n            return True\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False\n\n    def show_livebench_results(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step show_livebench_results -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/show_livebench_results.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.model], check=True)\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False, {}\n\n        return self.create_result_dict()\n\n    def read_csv_to_dict(self, file_path) -&gt; dict:  # noqa: D102\n        file_path = os.path.expanduser(file_path)\n        with open(file_path, \"r\") as f:\n            reader = csv.DictReader(f)\n            matching_rows = [row for row in reader if row[\"model\"] == self.model]\n            return matching_rows[-1] if matching_rows else {}  # Get the last matching row\n\n    def create_result_dict(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        tasks_data = self.read_csv_to_dict(\"~/.nearai/LiveBench/livebench/all_tasks.csv\")\n        groups_data = self.read_csv_to_dict(\"~/.nearai/LiveBench/livebench/all_groups.csv\")\n\n        if not tasks_data or not groups_data:\n            return False, {}  # Return None if the model is not found in either file\n\n        result: dict = {\"tasks\": {}, \"groups\": {}}\n\n        for key, value in tasks_data.items():\n            if key != \"model\":\n                result[\"tasks\"][key] = float(value)\n\n        for key, value in groups_data.items():\n            if key != \"model\":\n                result[\"groups\"][key] = float(value)\n\n        return True, result\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:  # noqa: D102\n        results: Dict[str, Dict[str, Any]] = tasks_results[-1][1]\n        metrics: Dict[str, Any] = {\"average\": results[\"groups\"][\"average\"]}\n\n        for group, score in results[\"groups\"].items():\n            if group == \"average\":\n                continue\n            metrics[f\"group/{group}\"] = score\n\n        for task, score in results[\"tasks\"].items():\n            metrics[f\"task/{task}\"] = score\n\n        return metrics\n</code></pre>"},{"location":"api/#nearai.solvers.MBPPSolverAgent","title":"MBPPSolverAgent","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_agent_solver.py</code> <pre><code>class MBPPSolverAgent(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], agent: str, num_iterations: int = 16, verbose: bool = False\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.agent = load_agent(agent)\n        self.verbose = verbose\n        self.num_iterations = num_iterations\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mbpp\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        # TODO: we may want to return the model used by an agent here.\n        return None\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return self.agent.metadata\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        return self.agent.namespace\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        # TODO: we may want to return the provider used by an agent here.\n        return DEFAULT_PROVIDER\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n        function_name = get_function_name(datum[\"code\"])\n\n        path = os.path.join(\n            \"/tmp\",\n            \"mbpp\",\n            str(datum[\"task_id\"]),\n            str(int(time.time() * 1000)),\n            str(random.randint(0, 1000)),\n        )\n        CONFIG.confirm_commands = False\n        env = Environment(path, [self.agent], CONFIG)\n\n        new_line = \"\\n\"\n        task = f\"\"\"{datum[\"text\"]}\nWrite a single file with python function named `{function_name}` that solves the above problem and satisfied the following tests:\n```python\\n{new_line.join(datum[\"test_list\"])}\\n```\"\"\"  # noqa: E501\n        if self.verbose:\n            print(task)\n            print(path)\n        env.run_task(task, max_iterations=self.num_iterations)\n\n        code = \"\"\n        for filename in env.list_files(\".\"):\n            if filename.endswith(\".py\"):\n                code += env.read_file(filename) + \"\\n\"\n\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code, {}, {})\n            return True\n        except Exception as e:\n            if self.verbose:\n                print(e)\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.MBPPSolverStrategy","title":"MBPPSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    SHOTS = 3\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mbpp\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.SHOTS))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.MMLUSolverStrategy","title":"MMLUSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mmlu\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.2,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy","title":"SolverStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class for solver strategies.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>class SolverStrategy(ABC, metaclass=SolverStrategyMeta):\n    \"\"\"Abstract class for solver strategies.\"\"\"\n\n    def __init__(self) -&gt; None:\n        pass\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the solver strategy.\"\"\"\n        return type(self).__name__\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:\n        return SolverScoringMethod.TrueOrFalseList\n\n    @abstractmethod\n    def evaluation_name(self) -&gt; str:\n        \"\"\"Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.\"\"\"\n        ...\n\n    @abstractmethod\n    def compatible_datasets(self) -&gt; List[str]:\n        \"\"\"Returns the list of datasets that the solver strategy is compatible with.\"\"\"\n        ...\n\n    @abstractmethod\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Returns model metadata that is evaluated or used by an agent.\"\"\"\n        ...\n\n    @abstractmethod\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Returns agent metadata that is evaluated.\"\"\"\n        ...\n\n    @abstractmethod\n    def evaluated_entry_namespace(self) -&gt; str:\n        \"\"\"Returns namespace of a model or agent to be evaluated.\"\"\"\n        ...\n\n    @abstractmethod\n    def model_provider(self) -&gt; str:\n        \"\"\"Returns model provider.\"\"\"\n        ...\n\n    @abstractmethod\n    def solve(self, datum: dict) -&gt; Union[bool, Tuple[bool, Any]]:\n        \"\"\"Solves the task for the given datum.\"\"\"\n        ...\n\n    def get_custom_tasks(self) -&gt; List[dict]:\n        \"\"\"Custom tasks for custom benchmark.\"\"\"\n        if self.scoring_method == SolverScoringMethod.Custom:\n            raise NotImplementedError(\"get_custom_tasks must be implemented for Custom scoring method\")\n        else:\n            raise AttributeError(\"get_custom_tasks is only applicable for Custom scoring method\")\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Given results for all datums, returns evaluation metrics.\n\n        Not used by TrueOrFalseList scoring method.\n        Do not prepend with evaluation_name. If hierarchical, use slashes /.\n        Expected metrics is a dict of scores, e.g.: {\"average\": &lt;val&gt;, \"group/coding\": &lt;val&gt;}.\n        \"\"\"\n        raise NotImplementedError(\"get_evaluation_metrics not implemented\")\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Returns the name of the solver strategy.</p>"},{"location":"api/#nearai.solvers.SolverStrategy.agent_metadata","title":"agent_metadata  <code>abstractmethod</code>","text":"<pre><code>agent_metadata() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Returns agent metadata that is evaluated.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef agent_metadata(self) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Returns agent metadata that is evaluated.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.compatible_datasets","title":"compatible_datasets  <code>abstractmethod</code>","text":"<pre><code>compatible_datasets() -&gt; List[str]\n</code></pre> <p>Returns the list of datasets that the solver strategy is compatible with.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef compatible_datasets(self) -&gt; List[str]:\n    \"\"\"Returns the list of datasets that the solver strategy is compatible with.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.evaluated_entry_namespace","title":"evaluated_entry_namespace  <code>abstractmethod</code>","text":"<pre><code>evaluated_entry_namespace() -&gt; str\n</code></pre> <p>Returns namespace of a model or agent to be evaluated.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef evaluated_entry_namespace(self) -&gt; str:\n    \"\"\"Returns namespace of a model or agent to be evaluated.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.evaluation_name","title":"evaluation_name  <code>abstractmethod</code>","text":"<pre><code>evaluation_name() -&gt; str\n</code></pre> <p>Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef evaluation_name(self) -&gt; str:\n    \"\"\"Returns a unique name for (benchmark, solver) tuple, e.g. 'mbpp' or 'live_bench' or 'mmlu-5-shot'.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.get_custom_tasks","title":"get_custom_tasks","text":"<pre><code>get_custom_tasks() -&gt; List[dict]\n</code></pre> <p>Custom tasks for custom benchmark.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def get_custom_tasks(self) -&gt; List[dict]:\n    \"\"\"Custom tasks for custom benchmark.\"\"\"\n    if self.scoring_method == SolverScoringMethod.Custom:\n        raise NotImplementedError(\"get_custom_tasks must be implemented for Custom scoring method\")\n    else:\n        raise AttributeError(\"get_custom_tasks is only applicable for Custom scoring method\")\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.get_evaluation_metrics","title":"get_evaluation_metrics","text":"<pre><code>get_evaluation_metrics(tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]\n</code></pre> <p>Given results for all datums, returns evaluation metrics.</p> <p>Not used by TrueOrFalseList scoring method. Do not prepend with evaluation_name. If hierarchical, use slashes /. Expected metrics is a dict of scores, e.g.: {\"average\": , \"group/coding\": }. Source code in <code>nearai/solvers/__init__.py</code> <pre><code>def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:\n    \"\"\"Given results for all datums, returns evaluation metrics.\n\n    Not used by TrueOrFalseList scoring method.\n    Do not prepend with evaluation_name. If hierarchical, use slashes /.\n    Expected metrics is a dict of scores, e.g.: {\"average\": &lt;val&gt;, \"group/coding\": &lt;val&gt;}.\n    \"\"\"\n    raise NotImplementedError(\"get_evaluation_metrics not implemented\")\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.model_metadata","title":"model_metadata  <code>abstractmethod</code>","text":"<pre><code>model_metadata() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Returns model metadata that is evaluated or used by an agent.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef model_metadata(self) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Returns model metadata that is evaluated or used by an agent.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.model_provider","title":"model_provider  <code>abstractmethod</code>","text":"<pre><code>model_provider() -&gt; str\n</code></pre> <p>Returns model provider.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef model_provider(self) -&gt; str:\n    \"\"\"Returns model provider.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategy.solve","title":"solve  <code>abstractmethod</code>","text":"<pre><code>solve(datum: dict) -&gt; Union[bool, Tuple[bool, Any]]\n</code></pre> <p>Solves the task for the given datum.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>@abstractmethod\ndef solve(self, datum: dict) -&gt; Union[bool, Tuple[bool, Any]]:\n    \"\"\"Solves the task for the given datum.\"\"\"\n    ...\n</code></pre>"},{"location":"api/#nearai.solvers.SolverStrategyMeta","title":"SolverStrategyMeta","text":"<p>               Bases: <code>ABCMeta</code></p> <p>Metaclass that automatically registers subclasses in the SolverStrategyRegistry.</p> Source code in <code>nearai/solvers/__init__.py</code> <pre><code>class SolverStrategyMeta(ABCMeta):\n    \"\"\"Metaclass that automatically registers subclasses in the SolverStrategyRegistry.\"\"\"\n\n    def __new__(cls, name: str, bases: tuple, namespace: dict) -&gt; Any:\n        new_class = super().__new__(cls, name, bases, namespace)\n        if bases != (ABC,):  # Avoid registering the abstract base class itself\n            SolverStrategyRegistry[new_class.__name__] = new_class  # type: ignore\n        return new_class\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver","title":"ddot_v0_solver","text":""},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment","title":"DDOTSEnvironment","text":"<p>               Bases: <code>Environment</code></p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSEnvironment(Environment):\n    def __init__(self, agents: List[Agent], problem_id: str, description: str, config: Config):  # noqa: D107\n        self.tdir = TemporaryDirectory()\n        super().__init__(self.tdir.name, agents, config)\n\n        self.problem_id = problem_id\n        self.solved = False\n\n        files = {\n            \".id\": problem_id,\n            \"PROBLEM.txt\": description,\n            \"solution.py\": \"\",\n            \"test.in\": \"\",\n            \"test.sh\": \"#!/bin/bash\\npython3 solution.py &lt; test.in\",\n        }\n        for fname, content in files.items():\n            with open(self.tdir.name + \"/\" + fname, \"w\") as f:\n                f.write(content)\n\n    async def async_submit(self, code: str) -&gt; Tuple[bool, str]:  # noqa: D102\n        submission_id = await submit_problem(self.problem_id, code, Extensions.PYTHON)\n\n        try:\n            await is_output_ready(submission_id)\n        except Exception:\n            print(\"WARNING: Submission took too long to execute on DDOTS\")\n            self.mark_done()\n            return False, \"Submission took too long to execute on the platform\"\n\n        ok = await submission_accepted(submission_id)\n\n        if ok:\n            self.solved = True\n            self.mark_done()\n            return True, \"\"\n\n        output = await get_output(submission_id)\n\n        return False, output\n\n    def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n        \"\"\"Returns True if the submission was accepted, False otherwise.\n\n        The second element of the tuple is the output of the checker if the submission was rejected.\n        \"\"\"\n        return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment.submit_python","title":"submit_python","text":"<pre><code>submit_python(code: str) -&gt; Tuple[bool, str]\n</code></pre> <p>Returns True if the submission was accepted, False otherwise.</p> <p>The second element of the tuple is the output of the checker if the submission was rejected.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n    \"\"\"Returns True if the submission was accepted, False otherwise.\n\n    The second element of the tuple is the output of the checker if the submission was rejected.\n    \"\"\"\n    return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSV0Solver","title":"DDOTSV0Solver","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        self.agents = [load_agent(agent) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"ddots\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        # TODO: we may want to return the model used by an agent here.\n        return None\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return self.agents[0].metadata\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        return self.agents[0].namespace\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        # TODO: we may want to return the provider used by an agent here.\n        return DEFAULT_PROVIDER\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        config = deepcopy(CONFIG)\n        config.confirm_commands = False\n\n        env = DDOTSEnvironment(self.agents, problem_id, description, config)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run_task(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.gsm8k_solver","title":"gsm8k_solver","text":""},{"location":"api/#nearai.solvers.gsm8k_solver.GSM8KSolverStrategy","title":"GSM8KSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the GSM8K dataset.</p> Source code in <code>nearai/solvers/gsm8k_solver.py</code> <pre><code>class GSM8KSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the GSM8K dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"gsm8k\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"gsm8k\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        parsed_datum: GSM8KDatum = GSM8KDatum(**datum)\n\n        problem_shots_indices = list(range(0, self.SHOTS))\n        problem_shots = list(\n            map(\n                lambda i: GSM8KDatum(**self.dataset_ref[\"train\"][i]).model_dump(),\n                problem_shots_indices,\n            )\n        )\n        res: ModelResponse = cast(\n            ModelResponse,\n            self.completion_fn(\n                model=self.model,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": dedent(\n                            \"\"\"\n                    You are a helpful assistant. You're goal is to answer word based math questions.\n                    \"\"\"\n                            + \"\\n\\n\"\n                            + \"Here are some examples of math questions and their answers:\"\n                            + \"\\n\\n\".join(\n                                [f\"Question: {shot['question']}\\nAnswer: {shot['answer']}\" for shot in problem_shots]\n                            )\n                            + \"\\n\\n\"\n                            + \"Now, answer the next question provided in the user prompt. \"\n                            + \"Think step by step about how to solve the problem. \"\n                            + \"Then, provide the answer.\"\n                        ),\n                    },\n                    {\"role\": \"user\", \"content\": parsed_datum.question},\n                ],\n            ),\n        )\n        res_output = str(cast(List[Choices], res.choices)[0].message.content).strip()\n        res_refined: ModelResponse = cast(\n            ModelResponse,\n            self.completion_fn(\n                model=self.model,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": dedent(\n                            f\"\"\"\n                    You are a helpful assistant. You're goal is to answer math questions.\n\n                    You have just answered a math question with the following response:\n\n                    --- BEGIN RESPONSE ---\n                    {res_output}\n                    --- END RESPONSE ---\n\n                    Please refine your answer.\n\n                    Only output the final number *without units* as your answer. Nothing else.\n                    \"\"\"\n                        ),\n                    },\n                ],\n            ),\n        )\n\n        ## cleanup the output\n        res_refined_output = str(cast(List[Choices], res_refined.choices)[0].message.content).strip()\n        res_refined_output = res_refined_output.replace(\"$\", \"\").replace(\",\", \"\")\n        if \" \" in res_refined_output:\n            res_refined_output = res_refined_output.split(\" \")[0]\n        try:\n            res_refined_output = str(int(res_refined_output))\n        except Exception:\n            pass\n        try:\n            res_refined_output = str(int(float(res_refined_output)))\n        except Exception:\n            pass\n\n        refined_answer = parsed_datum.answer.replace(\"$\", \"\").replace(\",\", \"\")\n        print(res_refined_output, refined_answer)\n        return res_refined_output == refined_answer\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver","title":"hellaswag_solver","text":""},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagSolverStrategy","title":"HellaswagSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"hellaswag\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.livebench_solver","title":"livebench_solver","text":""},{"location":"api/#nearai.solvers.livebench_solver.LiveBenchSolverStrategy","title":"LiveBenchSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the live bench dataset.</p> Source code in <code>nearai/solvers/livebench_solver.py</code> <pre><code>class LiveBenchSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the live bench dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: str, model: str, step: str = \"all\"\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        assert \"/\" not in model\n        self.model = model\n        self.step = step\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"live_bench\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"near.ai/live_bench/1.0.0\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def get_custom_tasks(self) -&gt; List[dict]:  # noqa: D102\n        return [{\"summary\": \"all\"}]\n\n    @SolverStrategyClassProperty\n    def scoring_method(self) -&gt; SolverScoringMethod:  # noqa: D102\n        return SolverScoringMethod.Custom\n\n    def solve(self, _datum: dict) -&gt; Tuple[bool, dict]:  # noqa: D102\n        if self.step == \"gen_model_answer\":\n            self.gen_model_answer()\n            return True, {}\n        if self.step == \"gen_ground_truth_judgement\":\n            return self.gen_ground_truth_judgement(), {}\n        if self.step == \"show_livebench_results\":\n            return self.show_livebench_results()\n        if self.step == \"all\":\n            self.gen_model_answer()\n            if not self.gen_ground_truth_judgement():\n                return False, {}\n            return self.show_livebench_results()\n        return False, {}\n\n    def gen_model_answer(self) -&gt; None:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_model_answer -----------\")\n        print(\"\")\n        list_of_question_files = glob.glob(f\"{self.dataset_ref}/**/question.jsonl\", recursive=True)\n        for question_file in list_of_question_files:\n            questions = load_questions_jsonl(question_file)\n            bench_name = os.path.dirname(question_file).split(str(self.dataset_ref))[-1]\n            answer_file = f\"~/.nearai/live_bench_answers/{bench_name}/model_answer/{self.model}.jsonl\"\n            print(f\"Questions from {question_file}\")\n            print(f\"Output to {answer_file}\")\n            self.run_eval(questions, answer_file)\n\n    def run_eval(self, questions, answer_file) -&gt; None:  # noqa: D102\n        answer_file = os.path.expanduser(answer_file)\n\n        # Load existing answers\n        existing_answers = set()\n        if os.path.exists(answer_file):\n            print(\n                f\"Answer file {answer_file} exists. Will skip already answered questions. Delete this file if that is not intended.\"  # noqa: E501\n            )\n            with open(answer_file, \"r\") as fin:\n                for line in fin:\n                    answer = json.loads(line)\n                    existing_answers.add(answer[\"question_id\"])\n\n        for question in tqdm(questions):\n            if question[\"question_id\"] in existing_answers:\n                continue\n            choices = self.answer_question(question)\n\n            ans_json = {\n                \"question_id\": question[\"question_id\"],\n                \"answer_id\": shortuuid.uuid(),\n                \"model_id\": self.model,\n                \"choices\": choices,\n                \"tstamp\": time.time(),\n            }\n\n            os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n            with open(answer_file, \"a\") as fout:\n                fout.write(json.dumps(ans_json) + \"\\n\")\n\n    def answer_question(self, question) -&gt; List[dict]:  # noqa: D102\n        conv = []\n        # Append system prompt here if needed.\n        turns = []\n        for qs in question[\"turns\"]:\n            conv.append({\"role\": \"user\", \"content\": qs})\n\n            completion_response = cast(\n                ModelResponse,\n                self.completion_fn(\n                    self.model,\n                    messages=[convert_message(msg) for msg in conv],\n                    temperature=0.0,\n                ),\n            )\n            output = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n            conv.append({\"role\": \"assistant\", \"content\": output})\n            turns.append(output)\n\n        return [{\"index\": 0, \"turns\": turns}]\n\n    def gen_ground_truth_judgement(self) -&gt; bool:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step gen_ground_truth_judgement -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/gen_ground_truth_judgement.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.model, self.dataset_ref], check=True)\n            return True\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False\n\n    def show_livebench_results(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        print(\"\")\n        print(\"----------- Step show_livebench_results -----------\")\n        print(\"\")\n        script_path = \"nearai/projects/live_bench/show_livebench_results.sh\"\n\n        try:\n            # Run the script without capturing output\n            subprocess.run([\"/bin/bash\", script_path, self.model], check=True)\n\n        except subprocess.CalledProcessError as e:\n            print(f\"An error occurred while running the script: {e}\")\n            return False, {}\n\n        return self.create_result_dict()\n\n    def read_csv_to_dict(self, file_path) -&gt; dict:  # noqa: D102\n        file_path = os.path.expanduser(file_path)\n        with open(file_path, \"r\") as f:\n            reader = csv.DictReader(f)\n            matching_rows = [row for row in reader if row[\"model\"] == self.model]\n            return matching_rows[-1] if matching_rows else {}  # Get the last matching row\n\n    def create_result_dict(self) -&gt; Tuple[bool, dict]:  # noqa: D102\n        tasks_data = self.read_csv_to_dict(\"~/.nearai/LiveBench/livebench/all_tasks.csv\")\n        groups_data = self.read_csv_to_dict(\"~/.nearai/LiveBench/livebench/all_groups.csv\")\n\n        if not tasks_data or not groups_data:\n            return False, {}  # Return None if the model is not found in either file\n\n        result: dict = {\"tasks\": {}, \"groups\": {}}\n\n        for key, value in tasks_data.items():\n            if key != \"model\":\n                result[\"tasks\"][key] = float(value)\n\n        for key, value in groups_data.items():\n            if key != \"model\":\n                result[\"groups\"][key] = float(value)\n\n        return True, result\n\n    def get_evaluation_metrics(self, tasks_results: List[Tuple[bool, Any]]) -&gt; Dict[str, Any]:  # noqa: D102\n        results: Dict[str, Dict[str, Any]] = tasks_results[-1][1]\n        metrics: Dict[str, Any] = {\"average\": results[\"groups\"][\"average\"]}\n\n        for group, score in results[\"groups\"].items():\n            if group == \"average\":\n                continue\n            metrics[f\"group/{group}\"] = score\n\n        for task, score in results[\"tasks\"].items():\n            metrics[f\"task/{task}\"] = score\n\n        return metrics\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_agent_solver","title":"mbpp_agent_solver","text":""},{"location":"api/#nearai.solvers.mbpp_agent_solver.MBPPSolverAgent","title":"MBPPSolverAgent","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_agent_solver.py</code> <pre><code>class MBPPSolverAgent(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], agent: str, num_iterations: int = 16, verbose: bool = False\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.agent = load_agent(agent)\n        self.verbose = verbose\n        self.num_iterations = num_iterations\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mbpp\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        # TODO: we may want to return the model used by an agent here.\n        return None\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return self.agent.metadata\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        return self.agent.namespace\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        # TODO: we may want to return the provider used by an agent here.\n        return DEFAULT_PROVIDER\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n        function_name = get_function_name(datum[\"code\"])\n\n        path = os.path.join(\n            \"/tmp\",\n            \"mbpp\",\n            str(datum[\"task_id\"]),\n            str(int(time.time() * 1000)),\n            str(random.randint(0, 1000)),\n        )\n        CONFIG.confirm_commands = False\n        env = Environment(path, [self.agent], CONFIG)\n\n        new_line = \"\\n\"\n        task = f\"\"\"{datum[\"text\"]}\nWrite a single file with python function named `{function_name}` that solves the above problem and satisfied the following tests:\n```python\\n{new_line.join(datum[\"test_list\"])}\\n```\"\"\"  # noqa: E501\n        if self.verbose:\n            print(task)\n            print(path)\n        env.run_task(task, max_iterations=self.num_iterations)\n\n        code = \"\"\n        for filename in env.list_files(\".\"):\n            if filename.endswith(\".py\"):\n                code += env.read_file(filename) + \"\\n\"\n\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code, {}, {})\n            return True\n        except Exception as e:\n            if self.verbose:\n                print(e)\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver","title":"mbpp_solver","text":""},{"location":"api/#nearai.solvers.mbpp_solver.MBPPSolverStrategy","title":"MBPPSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    SHOTS = 3\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mbpp\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.SHOTS))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver","title":"mmlu_solver","text":""},{"location":"api/#nearai.solvers.mmlu_solver.MMLUSolverStrategy","title":"MMLUSolverStrategy","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def evaluation_name(self) -&gt; str:  # noqa: D102\n        return \"mmlu\"\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def model_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return {\"name\": self.model}\n\n    def agent_metadata(self) -&gt; Optional[Dict[str, Any]]:  # noqa: D102\n        return None\n\n    def evaluated_entry_namespace(self) -&gt; str:  # noqa: D102\n        # Only provider models are supported.\n        return \"\"\n\n    def model_provider(self) -&gt; str:  # noqa: D102\n        provider, _ = get_provider_model(DEFAULT_PROVIDER, self.model)\n        return provider\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.2,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.tool_registry","title":"tool_registry","text":""},{"location":"api/#nearai.tool_registry.ToolRegistry","title":"ToolRegistry","text":"<p>A registry for tools that can be called by the agent.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>class ToolRegistry:\n    \"\"\"A registry for tools that can be called by the agent.\"\"\"\n\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.tools: Dict[str, Callable] = {}\n\n    def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n        \"\"\"Register a tool.\"\"\"\n        self.tools[tool.__name__] = tool\n\n    def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n        \"\"\"Get a tool by name.\"\"\"\n        return self.tools.get(name)\n\n    def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n        \"\"\"Get all tools.\"\"\"\n        return self.tools\n\n    def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n        \"\"\"Call a tool by name.\"\"\"\n        tool = self.get_tool(name)\n        if tool is None:\n            raise ValueError(f\"Tool '{name}' not found.\")\n        return tool(**kwargs)\n\n    def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n        \"\"\"Get the definition of a tool by name.\"\"\"\n        tool = self.get_tool(name)\n        if tool is None:\n            return None\n\n        assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n        docstring = tool.__doc__.strip().split(\"\\n\")\n\n        # The first line of the docstring is the function description\n        function_description = docstring[0].strip()\n\n        # The rest of the lines contain parameter descriptions\n        param_descriptions = docstring[1:]\n\n        # Extract parameter names and types\n        signature = inspect.signature(tool)\n        type_hints = get_type_hints(tool)\n\n        parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n        # Iterate through function parameters\n        for param in signature.parameters.values():\n            param_name = param.name\n            param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n            param_description = \"\"\n\n            # Find the parameter description in the docstring\n            for line in param_descriptions:\n                if line.strip().startswith(param_name):\n                    param_description = line.strip().split(\":\", 1)[1].strip()\n                    break\n\n            # Convert type hint to JSON Schema type\n            if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n                json_type = \"string\"\n            else:\n                json_type = param_type.__name__.lower()\n\n            json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n                json_type, json_type\n            )\n\n            # Add parameter to the definition\n            parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n            # Params without default values are required params\n            if param.default == inspect.Parameter.empty:\n                parameters[\"required\"].append(param_name)\n\n        return {\n            \"type\": \"function\",\n            \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n        }\n\n    def get_all_tool_definitions(self) -&gt; list[Dict]:  # noqa: D102\n        definitions = []\n        for tool_name, _tool in self.tools.items():\n            definition = self.get_tool_definition(tool_name)\n            if definition is not None:\n                definitions.append(definition)\n        return definitions\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry.call_tool","title":"call_tool","text":"<pre><code>call_tool(name: str, **kwargs: Any) -&gt; Any\n</code></pre> <p>Call a tool by name.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n    \"\"\"Call a tool by name.\"\"\"\n    tool = self.get_tool(name)\n    if tool is None:\n        raise ValueError(f\"Tool '{name}' not found.\")\n    return tool(**kwargs)\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry.get_all_tools","title":"get_all_tools","text":"<pre><code>get_all_tools() -&gt; Dict[str, Callable]\n</code></pre> <p>Get all tools.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n    \"\"\"Get all tools.\"\"\"\n    return self.tools\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry.get_tool","title":"get_tool","text":"<pre><code>get_tool(name: str) -&gt; Optional[Callable]\n</code></pre> <p>Get a tool by name.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n    \"\"\"Get a tool by name.\"\"\"\n    return self.tools.get(name)\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry.get_tool_definition","title":"get_tool_definition","text":"<pre><code>get_tool_definition(name: str) -&gt; Optional[Dict]\n</code></pre> <p>Get the definition of a tool by name.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n    \"\"\"Get the definition of a tool by name.\"\"\"\n    tool = self.get_tool(name)\n    if tool is None:\n        return None\n\n    assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n    docstring = tool.__doc__.strip().split(\"\\n\")\n\n    # The first line of the docstring is the function description\n    function_description = docstring[0].strip()\n\n    # The rest of the lines contain parameter descriptions\n    param_descriptions = docstring[1:]\n\n    # Extract parameter names and types\n    signature = inspect.signature(tool)\n    type_hints = get_type_hints(tool)\n\n    parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n    # Iterate through function parameters\n    for param in signature.parameters.values():\n        param_name = param.name\n        param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n        param_description = \"\"\n\n        # Find the parameter description in the docstring\n        for line in param_descriptions:\n            if line.strip().startswith(param_name):\n                param_description = line.strip().split(\":\", 1)[1].strip()\n                break\n\n        # Convert type hint to JSON Schema type\n        if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n            json_type = \"string\"\n        else:\n            json_type = param_type.__name__.lower()\n\n        json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n            json_type, json_type\n        )\n\n        # Add parameter to the definition\n        parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n        # Params without default values are required params\n        if param.default == inspect.Parameter.empty:\n            parameters[\"required\"].append(param_name)\n\n    return {\n        \"type\": \"function\",\n        \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n    }\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry.register_tool","title":"register_tool","text":"<pre><code>register_tool(tool: Callable) -&gt; None\n</code></pre> <p>Register a tool.</p> Source code in <code>nearai/tool_registry.py</code> <pre><code>def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n    \"\"\"Register a tool.\"\"\"\n    self.tools[tool.__name__] = tool\n</code></pre>"},{"location":"benchmarking/","title":"Building and running a benchmark","text":"<p>In the context of software engineering, the purpose of a benchmark is to associate some performance metric (accuracy, latency, memory usage, etc.) with a specific piece of code or a system. This metric is then usually used to compare different implementations of the same functionality in the hopes to improve the metric over time. This is especially important in the context of machine learning systems when measuring functional capabilities on specific tasks.</p> <p>To accomplish measuring machine learning systems capabilities, in the context of the <code>nearai</code> project, we provide a benchmark tool to compare different agents and solvers on sets of reference evaluations. This tool enables you to do measurement and compare your systems on various sets of reference evaluations, ex: <code>mpbb</code>. The core metric for benchmarks like these is \"percent true\" or \"accuracy\".</p>"},{"location":"benchmarking/#how-is-a-benchmark-implemented","title":"How is a benchmark implemented?","text":"<p>In the <code>nearai</code> project, a benchmark is the combination of a dataset and a solver.</p>"},{"location":"benchmarking/#adding-a-benchmark-dataset","title":"Adding a benchmark dataset","text":"<p><code>nearai</code> leverages huggingface datasets as the primitive when operating with datasets + benchmarks (see <code>load_dataset</code>). This means that to add a new benchmark, you need to create a new dataset and register it with the <code>nearai</code> registry (we will go over this in Implementing the \"3 digit addition\" benchmark).</p>"},{"location":"benchmarking/#adding-a-solver","title":"Adding a solver","text":"<p>To implement a solver, you will need to implement the SolverStrategy interface under the <code>nearai.solvers</code> module. The most important method the solver should implement is the <code>solve</code> method. This method should take a datum, run your implementation specific agentic strategy / strategies, and return a result.</p>"},{"location":"benchmarking/#implementing-the-3-digit-addition-benchmark","title":"Implementing the \"3 digit addition\" benchmark","text":"<p>In this section we will be implementing a benchmark we'll call \"3 digit addition\". The goal of the benchmark is to test an agents ability to add two 1-3 digit numbers together. The dataset will consist of 1000 examples of 3 digit addition problems and their solutions. The solver will adjudicate the agents answers and return an single accuracy score. While this benchmark is simple and can be solved with a simple program, it serves as a good example of how to implement a benchmark in <code>nearai</code>.</p>"},{"location":"benchmarking/#step-1-creating-the-dataset","title":"Step 1: Creating the dataset","text":"<p>To create this dataset, we will first synthetically generate the data. We will then register the dataset with the <code>nearai</code> registry.</p> <pre><code>import random\nfrom itertools import product\n\nimport datasets\n\nSAMPLE_SIZE = 1000\nSEED = 42\nPATH = \"3_digit_addition\"\n\nrandom.seed(SEED)\ndatasets.Dataset.from_generator(\n    lambda: iter(\n        {\n            \"input\": f\"{a} + {b}\",\n            \"output\": str(a + b)\n        }\n        for a, b in random.sample(list(product(range(1000), range(1000))), SAMPLE_SIZE)\n    ),\n    features=datasets.Features(\n        {\n            \"input\": datasets.Value(\"string\"),\n            \"output\": datasets.Value(\"string\")\n        }\n    )\n).save_to_disk(PATH)\n</code></pre> <p>Now to upload the dataset to the registry we'll run the command:</p> <pre><code>nearai registry upload ./3_digit_addition\n</code></pre>"},{"location":"benchmarking/#step-2-creating-the-solver","title":"Step 2: Creating the solver","text":"<p>To create the solver, we will implement the <code>SolverStrategy</code> interface. The solver will take in a datum, parse the input, execute any setup for the agent, run the agent, and return the correctness of the agents result.</p> Remember <p>To ensure this solver is registered with <code>nearai</code>:</p> <ol> <li>Write this implementation in the <code>nearai.solvers</code> module.</li> <li>Import it in the <code>__init__.py</code> file in the <code>nearai.solvers</code> module.</li> </ol> <pre><code># ... other imports ...\nfrom pydantic import BaseModel\nfrom huggingface import Dataset\nfrom nearai.solvers import SolverStrategy\n\nfrom typing import Dict, List\n\nclass ThreeDigitAdditionDatum(BaseModel):\n    input: str\n    output: str\n\nclass ThreeDigitAdditionAgentSolver(SolverStrategy):\n    \"\"\"Solver for the 3 digit addition benchmark.\"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agent: str):\n        self.dataset = dataset_ref\n        self.agent = agent\n        self.verbose = verbose\n\n    def compatible_datasets(self) -&gt; List[str]:\n        return [\"3_digit_addition\"]\n\n    def solve(self, datum: Dict[str, str]) -&gt; bool:\n        datum = ThreeDigitAdditionDatum(**datum)\n        label = datum.input.replace(\" + \", \"+\")\n        path = os.path.join(\n            \"/tmp\",\n            \"3_digit_addition\",\n            str(label),\n            str(int(time.time() * 1000)),\n            str(random.randint(0, 1000)),\n        )\n        CONFIG.confirm_commands = False\n        env = Environment(path, [self.agent], CONFIG)\n\n        goal = f\"\"\"Please add the following numbers together: {datum.input}\\n\\nOutput the result in a file called 'result.txt'.\"\"\"\n        env.run_task(goal)\n\n        with open(os.path.join(path, \"result.txt\"), \"r\") as f:\n            result = f.read().strip()\n        return result == datum.output\n</code></pre>"},{"location":"benchmarking/#step-3-running-the-benchmark","title":"Step 3: Running the benchmark","text":"<p>To run the benchmark, we will use the <code>nearai</code> CLI. We will specify the dataset and solver we want to use.</p> <pre><code>nearai benchmark run 3_digit_addition ThreeDigitAdditionAgentSolver --agent &lt;my_agent&gt;\n</code></pre>"},{"location":"contributing/","title":"Contribute to <code>nearai</code>","text":"<p>Everyone is welcome to contribute, and we value everybody's contribution. Code contributions are not the only way to help the community. Answering questions, helping others, and improving documentation are also immensely valuable.</p> <p>It also helps us if you spread the word! Reference the library in blog posts about the awesome projects it made possible, or even simply \u2b50\ufe0f the repository to say thank you.</p> <p>This guide was heavily inspired by the huggingface transformers guide to contributing.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to contribute","text":"<p>There are several ways you can contribute to <code>nearai</code>:</p> <ul> <li>Fix outstanding issues with the existing code.</li> <li>Submit issues related to bugs or desired new features.</li> <li>Implement new features (including but not limited to solvers, agents, or benchmarks).</li> <li>Contribute to the examples or to the documentation.</li> </ul>"},{"location":"contributing/#fixing-outstanding-issues","title":"Fixing outstanding issues","text":"<p>If you notice an issue with the existing code and have a fix in mind, feel free to start contributing and open a Pull Request!</p>"},{"location":"contributing/#submitting-a-bug-related-issue-or-feature-request","title":"Submitting a bug-related issue or feature request","text":"<p>Do your best to follow these guidelines when submitting a bug-related issue or a feature request. It will make it easier for us to come back to you quickly and with good feedback.</p>"},{"location":"contributing/#did-you-find-a-bug","title":"Did you find a bug?","text":"<p><code>nearai</code> is alpha software. This means there is a possibility of encountering issues in the code. With help from users like you who report problems, we can make it more robust and reliable.</p> <p>Before you report an issue, we would really appreciate it if you could make sure the bug was not already reported (use the search bar on GitHub under Issues). Your issue should also be related to bugs in the library itself, and not your code.</p> <p>Once you've confirmed the bug hasn't already been reported, please include the following information in your issue so we can quickly resolve it:</p> <ul> <li>What did you do?</li> <li>What did you expect to happen?</li> <li>What happened instead?</li> <li>Your OS type and version and Python, PyTorch and versions where applicable.</li> <li>A short, self-contained, code snippet that allows us to reproduce the bug in   less than 30s.</li> <li>The full traceback if an exception is raised.</li> <li>Attach any other additional information, like screenshots, you think may help.</li> </ul> <p>To get the OS and software versions automatically, run the following command:</p> <pre><code>uname -a\n</code></pre>"},{"location":"contributing/#do-you-want-a-new-feature","title":"Do you want a new feature?","text":"<p>If there is a new feature you'd like to see in <code>nearai</code>, please open an issue and describe:</p> <ol> <li>What is the motivation behind this feature? Is it related to a problem or frustration with the library? Is it a feature related to something you need for a project? Is it something you worked on and think it could benefit the community?</li> </ol> <p>Whatever it is, we'd love to hear about it!</p> <ol> <li>Describe your requested feature in as much detail as possible. The more you can tell us about it, the better we'll be able to help you.</li> <li>Provide a code snippet that demonstrates the feature usage.</li> <li>If the feature is related to a paper, please include a link.</li> </ol>"},{"location":"contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Before writing any code, we strongly advise you to search through the existing PRs or issues to make sure nobody is already working on the same thing. If you are unsure, it is always a good idea to open an issue to get some feedback.</p> <p>You will need basic <code>git</code> proficiency to contribute to <code>nearai</code>. While <code>git</code> is not the easiest tool to use, it has the greatest manual. Type <code>git --help</code> in a shell and enjoy! If you prefer books, Pro Git is a very good reference. We also recommend asking any available AGI to help you with <code>git</code>.</p> <p>Follow the steps below to start contributing:</p> <ol> <li> <p>Fork the repository by    clicking on the Fork button on the repository's page. This creates a copy of the code    under your GitHub user account.</p> </li> <li> <p>Clone your fork to your local disk, and add the base repository as a remote:</p> </li> </ol> <pre><code>git clone git@github.com:&lt;your Github handle&gt;/nearai.git\ncd nearai\ngit remote add upstream https://github.com/nearai/nearai.git\n</code></pre> <ol> <li>Create a new branch to hold your development changes:</li> </ol> <pre><code>git checkout -b a-descriptive-name-for-my-changes\n</code></pre> <p>\ud83d\udea8 Do not work on the <code>main</code> branch!</p> <ol> <li> <p>Set up a development environment (follow steps in the README):</p> </li> <li> <p>Develop the features in your branch.</p> </li> </ol> <p>As you work on your code, you should make sure it functions as intended.</p> <p><code>nearai</code> relies on <code>ruff</code> and <code>mypy</code> to format and type check its source code    consistently. After you make your changes and are ready to PR them, ensure that    your code is formatted and type-checked by running:</p> <pre><code>./scripts/lint_format.sh\n</code></pre> <pre><code>./scripts/typecheck.sh\n</code></pre> <p>Once you're happy with your changes, add the changed files with <code>git add</code> and    record your changes locally with <code>git commit</code>:</p> <pre><code>git add modified_file.py\ngit commit\n</code></pre> <p>Please remember to write good commit    messages to clearly communicate the changes you made!</p> <p>To keep your copy of the code up to date with the original    repository, rebase your branch on <code>upstream/branch</code> before you open a pull request or if requested by a maintainer:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> <p>Push your changes to your branch:</p> <pre><code>git push -u origin a-descriptive-name-for-my-changes\n</code></pre> <p>If you've already opened a pull request, you'll need to force push with the <code>--force</code> flag. Otherwise, if the pull request hasn't been opened yet, you can just push your changes normally.</p> <ol> <li> <p>Now you can go to your fork of the repository on GitHub and click on Pull Request to open a pull request. Make sure you tick off all the boxes on our checklist below. When you're ready, you can send your changes to the project maintainers for review.</p> </li> <li> <p>It's ok if maintainers request changes, it happens to our core contributors    too! So everyone can see the changes in the pull request, work in your local    branch and push the changes to your fork. They will automatically appear in    the pull request.</p> </li> </ol>"},{"location":"contributing/#pull-request-checklist","title":"Pull request checklist","text":"<ul> <li>The pull request title should summarize your contribution.</li> <li>If your pull request addresses an issue, please mention the issue number in the pull request description to make sure they are linked (and people viewing the issue know you are working on it).</li> <li>To indicate a work in progress please prefix the title with <code>[WIP]</code>. These are useful to avoid duplicated work, and to differentiate it from PRs ready to be merged.</li> <li>Don't add any images, videos and other non-text files that'll significantly weigh down the repository. Instead, reference them by URL.</li> </ul>"},{"location":"contributing/#sync-a-forked-repository-with-upstream-main","title":"Sync a forked repository with upstream main","text":"<p>When updating the main branch of a forked repository, please follow these steps to avoid pinging the upstream repository which adds reference notes to each upstream PR, and sends unnecessary notifications to the developers involved in these PRs.</p> <ol> <li>When possible, avoid syncing with the upstream using a branch and PR on the forked repository. Instead, merge directly into the forked main.</li> <li>If a PR is absolutely necessary, use the following steps after checking out your branch:</li> </ol> <pre><code>git checkout -b your-branch-for-syncing\ngit pull --squash --no-commit upstream main\ngit commit -m '&lt;your message without GitHub references&gt;'\ngit push --set-upstream origin your-branch-for-syncing\n</code></pre>"},{"location":"fine_tuning/","title":"<code>nearai</code> fine-tuning guide","text":"<p>As a part of the <code>nearai</code> project, we provide a collection of tools to fine-tune and evaluate models. Fine-tuning is a set of techniques to tune model parameters in a parameter-efficient way to improve model performance on specific tasks. More commonly, fine-tuning is used to modify the behavior of a pre-trained model. Some examples of this are to produce structured output (JSON, XLM, etc), to produce stylized output (poetic, neutral, etc), or to respond properly to instruction based prompts.</p> <p>In this guide, we will walk through the process of fine-tuning <code>llama-3-8b-instruct</code> on the orca-math-word-problems-200k dataset to improve its performance on the gsm8k benchmark.</p>"},{"location":"fine_tuning/#step-1-create-the-dataset","title":"Step 1: Create the dataset","text":"<p>The two datasets we will be using are orca-math-word-problems-200k and gsm8k. Both datasets are a collection of word based math problems + answers. For convenience, we will download the datasets from huggingface, save it to disk, and then upload it into the <code>nearai</code> registry.</p> <pre><code>import re\nfrom textwrap import dedent\nfrom datasets import load_dataset, concatenate_datasets, DatasetDict\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n\nds_math_word_problems = load_dataset(\"HuggingFaceH4/orca-math-word-problems-200k\")\nds_gsm8k = load_dataset(\"openai/gsm8k\", \"main\")['train']\n\n## create new column by concatenating the 'question' and 'answer' columns\ndef to_q_a(x):\n    q_n_a = tokenizer.apply_chat_template(\n        [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant. Please answer the math question.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": x[\"question\"]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": x[\"answer\"]\n            }\n        ],\n        tokenize=False\n    )\n    return {\n        \"question_and_answer\": q_n_a\n    }\nds_math_word_problems = ds_math_word_problems.map(to_q_a)\n\ndef to_q_a_gsm8k(x):\n    q_n_a = tokenizer.apply_chat_template(\n        [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant. Please answer the math question.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": x[\"question\"]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": re.sub(r\"&lt;&lt;.*?&gt;&gt;\", \"\", x[\"answer\"])\n            }\n        ],\n        tokenize=False\n    )\n    return {\n        \"question_and_answer\": q_n_a\n    }\nds_gsm8k = ds_gsm8k.map(to_q_a_gsm8k)\n\n## combine the datasets\nds_combined = concatenate_datasets([ds_math_word_problems['train_sft'], ds_gsm8k])\nds_combined = ds_combined.remove_columns([col for col in ds_combined.column_names if col != \"question_and_answer\"])\n\n# Add a split on 'train'\nds_combined = ds_combined.train_test_split(test_size=0.0001, seed=42)\nds_dict = DatasetDict({\n    'train': ds_combined['train'],\n    'validation': ds_combined['test']\n})\nds_dict.save_to_disk(\"orca_math_gsm8k_train\")\n</code></pre> <pre><code>nearai registry upload ./orca_math_gsm8k_train\n</code></pre>"},{"location":"fine_tuning/#step-2-fine-tune-the-model","title":"Step 2: Fine-tune the model","text":"<p>Under the hood, <code>nearai</code> uses torchtune to manage the fine-tuning process. To launch a fine-tuning job you can use <code>nearai finetune</code>.</p> <p>Here is the command we used to fine-tune <code>llama-3-8b-instruct</code> on our combined <code>orca-math-word-problems-200k</code> and <code>gsm8k</code> dataset on an 8-GPU machine:</p> <pre><code>poetry run python3 -m nearai finetune start \\\n    --model llama-3-8b-instruct \\\n    --format llama3-8b \\\n    --tokenizer llama-3-8b-instruct/tokenizer.model \\\n    --dataset ./orca_math_gsm8k_train \\\n    --method nearai.finetune.text_completion.dataset \\\n    --column question_and_answer \\\n    --split train \\\n    --num_procs 8\n</code></pre> <p>To change the configuration of the fine-tuning job, edit <code>etc/finetune/llama3-8b.yml</code>.</p> <p>Included in the output of the command is the path to the fine-tuned model checkpoint. In this case, the path was <code>~.nearai/finetune/job-2024-08-29_20-58-08-207756662/checkpoint_output</code>. The path may/will be different based on the time you run the command.</p>"},{"location":"fine_tuning/#step-3-serve-the-fine-tuned-model","title":"Step 3: Serve the fine-tuned model","text":"<p>To serve fine-tuned models, we use vllm. Once we serve the fine-tuned model + the baseline model, we will benchmark it against both.</p> <pre><code>poetry run python3 -m vllm.entrypoints.openai.api_server \\\n    --model meta-llama/Meta-Llama-3-8B-Instruct \\\n    --enable-lora \\\n    --lora-modules mynewlora=&lt;path_to_checkpoint&gt; \\\n    --tensor-parallel 8\n</code></pre> <p>Now we will run the <code>gsm8k</code> benchmark on both the baseline model and the fine-tuned model using <code>nearai benchmark</code>. The solvers will call our fine-tuned model and the baseline model through the vllm server.</p> <pre><code>python3 -m nearai benchmark run \\\n    cmrfrd.near/gsm8k/0.0.2 \\\n    GSM8KSolverStrategy \\\n    --subset test \\\n    --model local::meta-llama/Meta-Llama-3-8B-Instruct\n\npython3 -m nearai benchmark run \\\n    cmrfrd.near/gsm8k/0.0.2 \\\n    GSM8KSolverStrategy \\\n    --subset test \\\n    --model local::mynewlora\n</code></pre> <p>And we can see the results of the benchmark. And we can see that the fine-tuned model performs better than the baseline model.</p> <pre><code># meta-llama/Meta-Llama-3-8B-Instruct\nCorrect/Seen - 1061/1319 - 80.44%\n\n# fine tuned llama3-8b-instruct\nCorrect/Seen - 966/1319 - 73.24%\n</code></pre> <p>From these results, we can see that our fine-tuned model needs improvement to perform better than the baseline model.</p>"},{"location":"inference/","title":"NEAR.AI Inference API (OpenAI Compatible)","text":"<p>NEAR.AI provides an OpenAI-compatible API for inference, allowing you to easily integrate powerful language models into your applications. This guide covers the basic endpoints and how to use them.</p> <p>Other examples available here: examples</p>"},{"location":"inference/#getting-started","title":"Getting Started","text":"<ol> <li>Install all dependencies</li> </ol> <p>a. using <code>pip</code>:</p> <pre><code># Create a virtual environment\npython -m venv nearai_env\n\n# Activate the virtual environment\n# On Windows:\n# nearai_env\\Scripts\\activate\n# On macOS and Linux:\nsource nearai_env/bin/activate\n\n# Install the package in editable mode\npip install -e .\n</code></pre> <p>b. using poetry:</p> <pre><code>poetry install\n</code></pre> <ol> <li> <p>Set up authentication:</p> </li> <li> <p>Log in to NEAR AI using the CLI: <code>nearai login</code></p> </li> <li> <p>The auth object will be saved in <code>~/.nearai/config.json</code></p> </li> <li> <p>Import the required libraries and set up the client</p> </li> </ol> <pre><code>import openai\nimport json\nimport os\nimport nearai\n\nhub_url = \"https://api.near.ai/v1\"\n\n# Login to NEAR AI Hub using nearai CLI.\n# Read the auth object from ~/.nearai/config.json\nauth = nearai.config.load_config_file()[\"auth\"]\nsignature = json.dumps(auth)\n\nclient = openai.OpenAI(base_url=hub_url, api_key=signature)\n</code></pre>"},{"location":"inference/#list-models","title":"List Models","text":"<p>To list available models, use the <code>models.list()</code> method:</p> <pre><code>models = client.models.list()\nprint(models)\n</code></pre> <p>Different providers have different models. The format is <code>provider::account/model_name/model_version</code>. To get all unique providers, do:</p> <pre><code>providers = set([model.id.split(\"::\")[0] for model in models])\nprint(providers)\n</code></pre>"},{"location":"inference/#create-a-chat-completion","title":"Create a Chat Completion","text":"<p>To create a chat completion, use the <code>chat.completions.create()</code> method. Here's an example:</p> <pre><code>completion = client.chat.completions.create(\n  model=\"fireworks::accounts/fireworks/models/llama-v3p1-405b-instruct-long\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n</code></pre> <p>This will send a request to the specified model with the given messages and return the model's response. The response can be accessed through the <code>choices</code> array in the returned object.</p>"},{"location":"inference/#error-handling","title":"Error Handling","text":"<p>When using the API, it's important to handle potential errors. Here's an example of how to implement basic error handling:</p> <pre><code>try:\n  completion = client.chat.completions.create(\n    model=\"fireworks::accounts/fireworks/models/llama-v3p1-405b-instruct-long\",\n    messages=[\n      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n      {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n    ]\n  )\n  print(completion.choices[0].message.content)\nexcept openai.APIError as e:\n  print(f\"An API error occurred: {e}\")\nexcept Exception as e:\n  print(f\"An unexpected error occurred: {e}\")\n</code></pre>"},{"location":"inference/#additional-features","title":"Additional Features","text":"<p>The NEAR.AI Inference API also supports other features such as:</p> <ol> <li>Streaming responses</li> <li>Function calling</li> <li>Custom parameters (temperature, max_tokens, etc.)</li> </ol> <p>For more information on these features, please refer to the full API documentation.</p>"},{"location":"inference/#conclusion","title":"Conclusion","text":"<p>This guide covers the basics of using the NEAR.AI Inference API. By following these steps, you should be able to authenticate, list models, and create chat completions. For more advanced usage and detailed information, please refer to the complete API documentation or explore the provided examples.</p>"},{"location":"login/","title":"NEAR Login","text":"<p>The NEAR Login feature accommodates various authentication scenarios, simplifying the process of signing NearAI requests using your NEAR Account.</p>"},{"location":"login/#scenarios","title":"Scenarios","text":""},{"location":"login/#1-web-login","title":"1. Web Login","text":"<p>This scenario sets up a local server on the user's machine. A <code>callbackUrl</code> is created to handle the response, and the user is redirected to <code>auth.near.ai</code>. The authentication signature is then saved upon receiving the callback. This is the simplest option for logging in from a machine where you are already signed in with your NEAR account, such as in a web browser.</p> <p>Command: <pre><code>nearai login\n</code></pre></p>"},{"location":"login/#2-remote-web-login","title":"2. Remote Web Login","text":"<p>In this scenario, a login link to <code>auth.near.ai</code> is generated without a callbackUrl. The NearAI CLI will display instructions to complete the login process. This option is convenient if you haven't used your NEAR account on the current machine but can copy the authorization link, complete the authorization on another machine, and then return to the original machine to execute the command for finalizing the login.</p> <p>Command: <pre><code>nearai login --remote\n</code></pre></p>"},{"location":"login/#3-login-with-near-account-id-only","title":"3. Login with NEAR Account ID Only","text":"<p>If you have previously logged in with a NEAR account using near-cli and have NEAR account credentials stored in the <code>~/.near-credentials/mainnet directory</code>, you can generate a signature and save the authentication data based on the stored NEAR keys.</p> <p>Command:: <pre><code>nearai login --accountId name.near\n</code></pre></p>"},{"location":"login/#4-login-with-account-id-and-private-key","title":"4. Login with Account ID and Private Key","text":"<p>Similar to the previous scenario, but allows for manual entry of the private key. This is useful if you want to authenticate without relying on stored credentials.</p> <p>Command::</p> <pre><code>nearai login --accountId name.near --privateKey key\n</code></pre>"},{"location":"login/#getting-started","title":"Getting Started","text":"<ul> <li> <p>Install the NearAI CLI: you can install it by following the instructions in the NearAI CLI documentation.</p> </li> <li> <p>Choose Your Login Scenario: Depending on your needs, use one of the commands above to Login with NEAR.</p> </li> <li> <p>Follow the Prompts: Follow any additional prompts or instructions provided by the NearAI CLI during the authentication process.</p> </li> </ul>"},{"location":"login/#login-status","title":"Login Status","text":"<p>To verify the current login status, you can use the following command:</p> <pre><code>nearai login status\n</code></pre>"},{"location":"login/#logout","title":"Logout","text":"<p>Clear NEAR account auth data from NearAI config file:</p> <pre><code>nearai logout \n</code></pre>"}]}