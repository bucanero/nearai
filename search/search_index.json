{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Near AI","text":"<p>See the Near AI website for more information about how we will achieve Open Source and User-owned AGI..</p>"},{"location":"#warning-alpha-software","title":"\u26a0\ufe0f Warning: Alpha software","text":"<p>NearAI is alpha software. This means that it is not yet ready for production use. We are actively working on improving the software and would love your help.</p> <p>If you would like to help build our future, please see our contributing guide.</p>"},{"location":"#about","title":"About","text":"<p>The NearAI project is a toolkit to help build, measure, and deploy AI systems focused on agents.</p> <p>NearAI consists of:</p> <ol> <li>A CLI tool to interact with the NearAI registry, download agents, run them in environments, and more.</li> <li>A library with access to the same tools as the CLI, but to be used programmatically.</li> <li><code>nearai</code> hub, a place to share agents, environments, and datasets.</li> </ol> <p>This intro is split into two parts:</p> <ol> <li>CLI Usage Guide</li> <li>Web Usage Guide</li> <li>Library Usage Guide</li> </ol>"},{"location":"#cli-usage-guide","title":"CLI Usage Guide","text":""},{"location":"#benchmarking","title":"Benchmarking","text":"<p><code>nearai</code> includes a benchmarking tool to compare different agents and solvers on sets of reference evals (like <code>mpbb</code>).</p> Requirements for benchmarking with <code>nearai</code> <p>To create a benchmark, you need two things:</p> <ol> <li>A dataset in your <code>nearai</code> dataset registry.</li> <li>A solver for the dataset implemented in the <code>nearai</code> library for said dataset.</li> </ol> <p>If you have a dataset and a solver, you can run a benchmark.</p> <p>To run a benchmark, you can use the <code>nearai benchmark</code> command. For example, to run the <code>mpbb</code> benchmark on the <code>llama-v3-70b-instruct</code>, you can use:</p> <pre><code>nearai benchmark run mbpp MBPPSolverStrategy \\\n    --model llama-v3-70b-instruct \\\n    --subset=train \\\n    --max_concurrent=1\n</code></pre>"},{"location":"#registry","title":"Registry","text":"<p>The registry is a place to store models, datasets, agents, and environments (more types to come). You can upload and download items from the registry using the <code>nearai registry</code> command.</p> <p>About the registry</p> <p>The registry is backed by an S3 bucket with metadata stored in a database.</p> <p>To upload an item to the registry, you need a directory containing a metadata.json file. The metadata.json file describes the item, and all the other files in the directory make up the item. For an agent that is one <code>agent.py</code> file, for a  dataset it may be hundreds of files.</p> <p>The metadata_template command will create a template for you to fill in. <pre><code>nearai registry metadata_template &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> Fill in name, version, category and any other fields for which you have values.  The current categories are: <code>model</code>, <code>dataset</code>, <code>agent</code>, <code>environment</code>.</p> <pre><code>{\n  \"category\": \"agent\",\n  \"description\": \"An example agent\",\n  \"tags\": [\n    \"python\"\n  ],\n  \"details\": {},\n  \"show_entry\": true,\n  \"name\": \"example-agent\",\n  \"version\": \"1\"\n}\n</code></pre> <p>Upload an element to the registry using:</p> <pre><code>nearai registry upload &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> <p>Check the item is available by listing all elements in the registry of that category:</p> <pre><code>nearai registry list --category agent\n</code></pre> <p>Show only items with the tag <code>quine</code> and <code>python</code>:</p> <pre><code>nearai registry list --tags quine,python\n</code></pre> <p>Download this element locally. To download refer to the item by //. Trying to download an item that was previously downloaded is a no-op. <pre><code>nearai registry download zavodil.near/hello-world-agent/1\n</code></pre> <p>Tip</p> <p>If you start downloading and item, and cancel the download midway, you should delete the folder at <code>~/.nearai/registry/</code> to trigger a new download.</p> <p>Update the metadata of an item with the registry update command <pre><code>nearai registry update &lt;ITEM_LOCAL_DIRECTORY_PATH&gt;\n</code></pre> View info about an item with the registry info command <pre><code>nearai registry info &lt;ITEM_FULL_NAME&gt;\n</code></pre> <pre><code>nearai registry info zavodil.near/hello-world-agent/1\n</code></pre></p>"},{"location":"#agents","title":"Agents","text":"<p>Agents are a python file in the local registry. Existing agents can be fetched with the download command:</p> <pre><code>nearai agents download &lt;AGENT_NAME&gt;\n</code></pre> <p>Local agent files that have not yet been uploaded can also be run.</p> <p>When uploading an agent, multiple versions can be stored by appending a version to the s3 path. The <code>--name</code> flag allows the latest agent to be fetched that matches that name.</p> <p>To upload an agent:</p> <pre><code>nearai agents upload --name langgraph-min-example ~/.nearai/registry/agents/langgraph-min-example/v1 agents/langgraph-min-example/v1 \"A minimal example\"\n</code></pre>"},{"location":"#running-environment-interactively","title":"Running environment interactively","text":"<p>You can run an agent (or a set of agents) inside a local environment that lives in a specific folder.</p> <p>Agents can be run interactively. The environment_path should be a folder where the agent chat record (chat.txt) and other files can be written, usually <code>~/tmp/test-agents/&lt;AGENT_NAME&gt;</code>.</p> <p>Environments can be run like so:</p> <pre><code>nearai environment interactive &lt;AGENT&gt; &lt;ENVIRONMENT_PATH&gt;\n</code></pre> <p>Example calling a local agent:</p> <pre><code>nearai environment interactive agent/my-agent/v1 ~/tmp/test-agents/my-agent-v1/env0\n</code></pre> <p>Example calling a downloaded agent:</p> <pre><code>nearai environment interactive xela-agent ~/tmp/test-agents/xela-agent-v2/env0\n</code></pre>"},{"location":"#running-environment-task","title":"Running environment task","text":"<p>To run without user interaction pass the task input to the task  * command <code>nearai environment task &lt;AGENT&gt; &lt;INPUT&gt; &lt;ENVIRONMENT_PATH&gt;</code>.  * example <code>nearai environment task xela-agent \"Build a command line chess engine\" ~/tmp/test-agents/chess-engine/env0</code>.</p>"},{"location":"#saving-and-loading-environment-runs","title":"Saving and loading environment runs","text":"<p>By default each environment run is saved to the registry. You can disable this by adding the flag <code>--record_run=False</code>.</p> <p>An environment run can be loaded by using the <code>--load_env</code> flag and passing it a registry identifier <code>--load_env=61</code>.</p> <p>To list environment identifiers use the command <code>nearai registry list --tags=environment</code>.</p> <p>A run can be named by passing a name to the record_run flag <code>--record_run=\"my special run\"</code>.</p> <p>Environment runs can be loaded by passing the name of a previous run to the --load_env flag like <code>--load_env=\"my special run\"</code>.</p>"},{"location":"#fine-tuning","title":"Fine tuning","text":"<p>We use <code>torchtune</code> for fine tuning models. The following command will start a fine tuning process using the <code>llama-3-8b-instruct</code> model and the <code>llama3</code> tokenizer.</p> <pre><code>poetry run python3 -m nearai finetune start \\\n    --model llama-3-8b-instruct \\\n    --format llama3-8b \\\n    --tokenizer tokenizers/llama-3 \\\n    --dataset &lt;your-dataset&gt; \\\n    --method nearai.finetune.text_completion.dataset \\\n    --column text \\\n    --split train \\\n    --num_procs 8\n</code></pre>"},{"location":"#submit-an-experiment","title":"Submit an experiment","text":"<p>To submit a new experiment run:</p> <pre><code>nearai submit --command &lt;COMMAND&gt; --name &lt;EXPERIMENT_NAME&gt; [--nodes &lt;NUMBER_OF_NODES&gt;] [--cluster &lt;CLUSTER&gt;]\n</code></pre> <p>This will submit a new experiment. The command must be executed from a folder that is a git repository (public github repositories, and private github repositories on the same organization as nearai are supported). The current commit will be used for running the command so make sure it is already available online. The diff with respect to the current commit will be applied remotely (new files are not included in the diff).</p> <p>On each node the environment variable <code>ASSIGNED_SUPERVISORS</code> will be available with a comma separated list of supervisors that are running the experiment. The current supervisor can be accessed via <code>nearai.CONFIG.supervisor_id</code>. See examples/prepare_data.py for an example.</p>"},{"location":"#web-usage-guide","title":"Web Usage Guide","text":"<p>https://app.near.ai allows you to use NEAR AI Hub directly from your broweser. It currently offers a subset of the features available from the Hub.</p> <p>Features:</p> <ul> <li>NEAR AI Login</li> <li>Login with your NEAR account using your favourite wallet provider.</li> <li>Inference using the provider of your choice</li> <li>Chose between the best open source models.</li> <li>Read the registry:</li> <li>Datasets - https://app.near.ai/datasets</li> <li>Benchmarks - https://app.near.ai/benchmarks</li> <li>Models - https://app.near.ai/models</li> <li>Agents - https://app.near.ai/agents</li> <li> <p>View and manage your NEAR AI access keys.</p> </li> <li> <p>https://app.near.ai/settings</p> </li> </ul> <p>Source code in: demo</p>"},{"location":"#library-usage-guide","title":"Library Usage Guide","text":"<p>You can import <code>nearai</code> as a library in your python code. The main features are:</p> <ul> <li>Download/upload models and datasets from the registry. See examples/prepare_data.py.</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nearai.cli.CLI","title":"<code>nearai.cli.CLI</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class CLI:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.registry = RegistryCli()\n        self.login = LoginCLI()\n        self.hub = HubCLI()\n\n        self.config = ConfigCli()\n        self.benchmark = BenchmarkCli()\n        self.environment = EnvironmentCli()\n        self.finetune = FinetuneCli()\n        self.tensorboard = TensorboardCli()\n        self.vllm = VllmCli()\n\n    def inference(self) -&gt; None:\n        \"\"\"Submit inference task.\"\"\"\n        raise NotImplementedError()\n\n    def location(self) -&gt; None:  # noqa: D102\n        from nearai import cli_path\n\n        print(cli_path())\n\n    def version(self) -&gt; None:  # noqa: D102\n        # TODO: Show current commit or tag\n        print(pkg_resources.get_distribution(\"nearai\").version)\n\n    def update(self) -&gt; None:\n        \"\"\"Update nearai version.\"\"\"\n        from nearai import cli_path\n\n        path = DATA_FOLDER / \"nearai\"\n\n        if path.absolute() != cli_path().absolute():\n            print()\n            print(f\"Updating nearai version installed in {path}\")\n            print(f\"The invoked nearai is in {cli_path()}\")\n            print()\n\n        if path.exists():\n            run([\"git\", \"pull\"], cwd=path)\n</code></pre>"},{"location":"api/#nearai.cli.CLI.inference","title":"<code>inference()</code>","text":"<p>Submit inference task.</p> Source code in <code>nearai/cli.py</code> <pre><code>def inference(self) -&gt; None:\n    \"\"\"Submit inference task.\"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/#nearai.cli.CLI.update","title":"<code>update()</code>","text":"<p>Update nearai version.</p> Source code in <code>nearai/cli.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"Update nearai version.\"\"\"\n    from nearai import cli_path\n\n    path = DATA_FOLDER / \"nearai\"\n\n    if path.absolute() != cli_path().absolute():\n        print()\n        print(f\"Updating nearai version installed in {path}\")\n        print(f\"The invoked nearai is in {cli_path()}\")\n        print()\n\n    if path.exists():\n        run([\"git\", \"pull\"], cwd=path)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli","title":"<code>nearai.cli.RegistryCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class RegistryCli:\n    def info(self, entry: str) -&gt; None:\n        \"\"\"Show information about an item.\"\"\"\n        entry_location = parse_location(entry)\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            print(f\"Entry {entry} not found.\")\n            return\n\n        print(metadata.model_dump_json(indent=2))\n\n    def metadata_template(self, local_path: str = \".\"):\n        \"\"\"Create a metadata template.\"\"\"\n        path = Path(local_path)\n\n        metadata_path = path / \"metadata.json\"\n\n        with open(metadata_path, \"w\") as f:\n            json.dump(\n                {\n                    \"name\": \"foobar\",\n                    \"version\": \"0.0.1\",\n                    \"description\": \"Template metadata\",\n                    \"category\": \"model\",\n                    \"tags\": [\"foo\", \"bar\"],\n                    \"details\": {},\n                    \"show_entry\": True,\n                },\n                f,\n                indent=2,\n            )\n\n    def list(\n        self,\n        category: str = \"\",\n        tags: str = \"\",\n        total: int = 32,\n        show_all: bool = False,\n    ) -&gt; None:\n        \"\"\"List available items.\"\"\"\n        # Make sure tags is a comma-separated list of tags\n        tags_l = parse_tags(tags)\n        tags = \",\".join(tags_l)\n\n        entries = registry.list(category, tags, total, show_all)\n\n        for entry in entries:\n            print(entry)\n\n    def update(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Update metadata of a registry item.\"\"\"\n        path = Path(local_path)\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n        _check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.account_id\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=metadata.pop(\"name\"),\n                version=metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(metadata)\n        result = registry.update(entry_location, entry_metadata)\n        print(json.dumps(result, indent=2))\n\n    def upload(self, local_path: str = \".\") -&gt; None:\n        \"\"\"Upload item to the registry.\"\"\"\n        registry.upload(Path(local_path).absolute(), show_progress=True)\n\n    def download(self, entry_location: str, force: bool = False) -&gt; None:\n        \"\"\"Download item.\"\"\"\n        registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.download","title":"<code>download(entry_location, force=False)</code>","text":"<p>Download item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def download(self, entry_location: str, force: bool = False) -&gt; None:\n    \"\"\"Download item.\"\"\"\n    registry.download(entry_location, force=force, show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.info","title":"<code>info(entry)</code>","text":"<p>Show information about an item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def info(self, entry: str) -&gt; None:\n    \"\"\"Show information about an item.\"\"\"\n    entry_location = parse_location(entry)\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        print(f\"Entry {entry} not found.\")\n        return\n\n    print(metadata.model_dump_json(indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.list","title":"<code>list(category='', tags='', total=32, show_all=False)</code>","text":"<p>List available items.</p> Source code in <code>nearai/cli.py</code> <pre><code>def list(\n    self,\n    category: str = \"\",\n    tags: str = \"\",\n    total: int = 32,\n    show_all: bool = False,\n) -&gt; None:\n    \"\"\"List available items.\"\"\"\n    # Make sure tags is a comma-separated list of tags\n    tags_l = parse_tags(tags)\n    tags = \",\".join(tags_l)\n\n    entries = registry.list(category, tags, total, show_all)\n\n    for entry in entries:\n        print(entry)\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.metadata_template","title":"<code>metadata_template(local_path='.')</code>","text":"<p>Create a metadata template.</p> Source code in <code>nearai/cli.py</code> <pre><code>def metadata_template(self, local_path: str = \".\"):\n    \"\"\"Create a metadata template.\"\"\"\n    path = Path(local_path)\n\n    metadata_path = path / \"metadata.json\"\n\n    with open(metadata_path, \"w\") as f:\n        json.dump(\n            {\n                \"name\": \"foobar\",\n                \"version\": \"0.0.1\",\n                \"description\": \"Template metadata\",\n                \"category\": \"model\",\n                \"tags\": [\"foo\", \"bar\"],\n                \"details\": {},\n                \"show_entry\": True,\n            },\n            f,\n            indent=2,\n        )\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.update","title":"<code>update(local_path='.')</code>","text":"<p>Update metadata of a registry item.</p> Source code in <code>nearai/cli.py</code> <pre><code>def update(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Update metadata of a registry item.\"\"\"\n    path = Path(local_path)\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n    _check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.account_id\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=metadata.pop(\"name\"),\n            version=metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(metadata)\n    result = registry.update(entry_location, entry_metadata)\n    print(json.dumps(result, indent=2))\n</code></pre>"},{"location":"api/#nearai.cli.RegistryCli.upload","title":"<code>upload(local_path='.')</code>","text":"<p>Upload item to the registry.</p> Source code in <code>nearai/cli.py</code> <pre><code>def upload(self, local_path: str = \".\") -&gt; None:\n    \"\"\"Upload item to the registry.\"\"\"\n    registry.upload(Path(local_path).absolute(), show_progress=True)\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli","title":"<code>nearai.cli.ConfigCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class ConfigCli:\n    def set(self, key: str, value: str, local: bool = False) -&gt; None:\n        \"\"\"Add key-value pair to the config file.\"\"\"\n        update_config(key, value, local)\n\n    def get(self, key: str) -&gt; None:\n        \"\"\"Get value of a key in the config file.\"\"\"\n        print(CONFIG.get(key))\n\n    def show(self) -&gt; None:  # noqa: D102\n        for key, value in asdict(CONFIG).items():\n            print(f\"{key}: {value}\")\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.get","title":"<code>get(key)</code>","text":"<p>Get value of a key in the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def get(self, key: str) -&gt; None:\n    \"\"\"Get value of a key in the config file.\"\"\"\n    print(CONFIG.get(key))\n</code></pre>"},{"location":"api/#nearai.cli.ConfigCli.set","title":"<code>set(key, value, local=False)</code>","text":"<p>Add key-value pair to the config file.</p> Source code in <code>nearai/cli.py</code> <pre><code>def set(self, key: str, value: str, local: bool = False) -&gt; None:\n    \"\"\"Add key-value pair to the config file.\"\"\"\n    update_config(key, value, local)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli","title":"<code>nearai.cli.BenchmarkCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class BenchmarkCli:\n    def run(\n        self,\n        dataset: str,\n        solver_strategy: str,\n        max_concurrent: int = -1,\n        force: bool = False,\n        subset: Optional[str] = None,\n        **solver_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Run benchmark on a dataset with a solver strategy.\n\n        It will cache the results in the database and subsequent runs will pull the results from the cache.\n        If force is set to True, it will run the benchmark again and update the cache.\n        \"\"\"\n        from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n        from nearai.dataset import load_dataset\n        from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n        # TODO(db-api): Expose an interface to cache the result of the benchmarks\n        # benchmark_id = db.get_benchmark_id(dataset, solver_strategy, force, subset=subset, **solver_kwargs)\n        benchmark_id = -1\n\n        name, subset, dataset = dataset, subset, load_dataset(dataset)\n\n        solver_strategy_: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n        assert (\n            solver_strategy\n        ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n        solver_strategy_obj: SolverStrategy = solver_strategy_(dataset_ref=dataset, **solver_kwargs)  # type: ignore\n        assert (\n            name in solver_strategy_obj.compatible_datasets()\n        ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n        be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n        cpu_count = os.cpu_count()\n        max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n        be.run(max_concurrent=max_concurrent)\n</code></pre>"},{"location":"api/#nearai.cli.BenchmarkCli.run","title":"<code>run(dataset, solver_strategy, max_concurrent=-1, force=False, subset=None, **solver_kwargs)</code>","text":"<p>Run benchmark on a dataset with a solver strategy.</p> <p>It will cache the results in the database and subsequent runs will pull the results from the cache. If force is set to True, it will run the benchmark again and update the cache.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run(\n    self,\n    dataset: str,\n    solver_strategy: str,\n    max_concurrent: int = -1,\n    force: bool = False,\n    subset: Optional[str] = None,\n    **solver_kwargs: Any,\n) -&gt; None:\n    \"\"\"Run benchmark on a dataset with a solver strategy.\n\n    It will cache the results in the database and subsequent runs will pull the results from the cache.\n    If force is set to True, it will run the benchmark again and update the cache.\n    \"\"\"\n    from nearai.benchmark import BenchmarkExecutor, DatasetInfo\n    from nearai.dataset import load_dataset\n    from nearai.solvers import SolverStrategy, SolverStrategyRegistry\n\n    # TODO(db-api): Expose an interface to cache the result of the benchmarks\n    # benchmark_id = db.get_benchmark_id(dataset, solver_strategy, force, subset=subset, **solver_kwargs)\n    benchmark_id = -1\n\n    name, subset, dataset = dataset, subset, load_dataset(dataset)\n\n    solver_strategy_: SolverStrategy | None = SolverStrategyRegistry.get(solver_strategy, None)\n    assert (\n        solver_strategy\n    ), f\"Solver strategy {solver_strategy} not found. Available strategies: {list(SolverStrategyRegistry.keys())}\"\n    solver_strategy_obj: SolverStrategy = solver_strategy_(dataset_ref=dataset, **solver_kwargs)  # type: ignore\n    assert (\n        name in solver_strategy_obj.compatible_datasets()\n    ), f\"Solver strategy {solver_strategy} is not compatible with dataset {name}\"\n\n    be = BenchmarkExecutor(DatasetInfo(name, subset, dataset), solver_strategy_obj, benchmark_id=benchmark_id)\n\n    cpu_count = os.cpu_count()\n    max_concurrent = (cpu_count if cpu_count is not None else 1) if max_concurrent &lt; 0 else max_concurrent\n    be.run(max_concurrent=max_concurrent)\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli","title":"<code>nearai.cli.EnvironmentCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class EnvironmentCli:\n    def setup(self, dataset: str, task_id: int) -&gt; None:\n        \"\"\"Setup environment with given task from the dataset.\"\"\"\n        pass\n\n    def inspect(self, path: str) -&gt; None:\n        \"\"\"Inspect environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.inspect()\n\n    def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n        \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n        from nearai.environment import Environment\n\n        env = Environment(path, [], CONFIG, create_files=False)\n        env.save_folder(name)\n\n    def save_from_history(self, name: Optional[str] = None) -&gt; None:\n        \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai environment save_from_history --help.\n\n        This command:\n        1. Finds agent task runs (must contain non-empty chat.txt)\n        2. Writes start_command.log files\n        3. Saves to registry\n\n        Only 'interactive' is supported.\n        Assumes format:\n        ' &lt;line_number&gt;  &lt;program_name&gt; environment interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n        Run:\n        $ history | grep \"environment interactive\" | sed \"s:~:$HOME:g\" | nearai environment save_from_history environment_interactive_runs_from_lambda_00\n        \"\"\"  # noqa: E501\n        from nearai.environment import Environment\n\n        env = Environment(\"/\", [], CONFIG, create_files=False)\n        # Read from stdin (piped input)\n        lines = sys.stdin.readlines()\n        env.save_from_history(lines, name)\n\n    def interactive(\n        self, agents: str, path: Optional[str] = \"\", record_run: str = \"true\", load_env: str = \"\", local: bool = False\n    ) -&gt; None:\n        \"\"\"Runs agent interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n        if not path:\n            if len(_agents) == 1:\n                path = _agents[0].path\n            else:\n                raise ValueError(\"Local path is required when running multiple agents\")\n        env = Environment(path, _agents, CONFIG)\n        env.run_interactive(record_run, load_env)\n\n    def task(\n        self,\n        agents: str,\n        task: str,\n        path: str,\n        max_iterations: int = 10,\n        record_run: str = \"true\",\n        load_env: str = \"\",\n    ) -&gt; None:\n        \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent) for agent in agents.split(\",\")]\n        env = Environment(path, _agents, CONFIG)\n        env.run_task(task, record_run, load_env, max_iterations)\n\n    def run(self, agents: str, task: str, path: str) -&gt; None:\n        \"\"\"Runs agent in the current environment.\"\"\"\n        from nearai.environment import Environment\n\n        _agents = [load_agent(agent) for agent in agents.split(\",\")]\n        env = Environment(path, [], CONFIG)\n        env.exec_command(\"sleep 10\")\n        # TODO: Setup server that will allow to interact with agents and environment\n\n    def run_on_aws_lambda(self, agents: str, environment_id: str, auth: str, new_message: str = \"\"):\n        \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n        wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n        wrapper.invoke_function(\n            \"agent-runner-docker\",\n            {\"agents\": agents, \"environment_id\": environment_id, \"auth\": json.dumps(auth), \"new_message\": new_message},\n        )\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.inspect","title":"<code>inspect(path)</code>","text":"<p>Inspect environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def inspect(self, path: str) -&gt; None:\n    \"\"\"Inspect environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.inspect()\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.interactive","title":"<code>interactive(agents, path='', record_run='true', load_env='', local=False)</code>","text":"<p>Runs agent interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def interactive(\n    self, agents: str, path: Optional[str] = \"\", record_run: str = \"true\", load_env: str = \"\", local: bool = False\n) -&gt; None:\n    \"\"\"Runs agent interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent, local) for agent in agents.split(\",\")]\n    if not path:\n        if len(_agents) == 1:\n            path = _agents[0].path\n        else:\n            raise ValueError(\"Local path is required when running multiple agents\")\n    env = Environment(path, _agents, CONFIG)\n    env.run_interactive(record_run, load_env)\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.run","title":"<code>run(agents, task, path)</code>","text":"<p>Runs agent in the current environment.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run(self, agents: str, task: str, path: str) -&gt; None:\n    \"\"\"Runs agent in the current environment.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent) for agent in agents.split(\",\")]\n    env = Environment(path, [], CONFIG)\n    env.exec_command(\"sleep 10\")\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.run_on_aws_lambda","title":"<code>run_on_aws_lambda(agents, environment_id, auth, new_message='')</code>","text":"<p>Invoke a Container based AWS lambda function to run agents on a given environment.</p> Source code in <code>nearai/cli.py</code> <pre><code>def run_on_aws_lambda(self, agents: str, environment_id: str, auth: str, new_message: str = \"\"):\n    \"\"\"Invoke a Container based AWS lambda function to run agents on a given environment.\"\"\"\n    wrapper = LambdaWrapper(boto3.client(\"lambda\", region_name=\"us-east-2\"))\n    wrapper.invoke_function(\n        \"agent-runner-docker\",\n        {\"agents\": agents, \"environment_id\": environment_id, \"auth\": json.dumps(auth), \"new_message\": new_message},\n    )\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.save_folder","title":"<code>save_folder(path, name=None)</code>","text":"<p>Saves all subfolders with agent task runs (must contain non-empty chat.txt).</p> Source code in <code>nearai/cli.py</code> <pre><code>def save_folder(self, path: str, name: Optional[str] = None) -&gt; None:\n    \"\"\"Saves all subfolders with agent task runs (must contain non-empty chat.txt).\"\"\"\n    from nearai.environment import Environment\n\n    env = Environment(path, [], CONFIG, create_files=False)\n    env.save_folder(name)\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.save_from_history","title":"<code>save_from_history(name=None)</code>","text":"<p>Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai environment save_from_history --help.</p> <p>This command: 1. Finds agent task runs (must contain non-empty chat.txt) 2. Writes start_command.log files 3. Saves to registry</p> <p>Only 'interactive' is supported. Assumes format: '   environment interactive  ' Run: $ history | grep \"environment interactive\" | sed \"s:~:$HOME:g\" | nearai environment save_from_history environment_interactive_runs_from_lambda_00 Source code in <code>nearai/cli.py</code> <pre><code>def save_from_history(self, name: Optional[str] = None) -&gt; None:\n    \"\"\"Reads piped history, finds agent task runs, writes start_command.log files, and saves to registry. For detailed usage, run: nearai environment save_from_history --help.\n\n    This command:\n    1. Finds agent task runs (must contain non-empty chat.txt)\n    2. Writes start_command.log files\n    3. Saves to registry\n\n    Only 'interactive' is supported.\n    Assumes format:\n    ' &lt;line_number&gt;  &lt;program_name&gt; environment interactive &lt;comma_separated_agents&gt; &lt;path&gt; &lt;other_args&gt;'\n    Run:\n    $ history | grep \"environment interactive\" | sed \"s:~:$HOME:g\" | nearai environment save_from_history environment_interactive_runs_from_lambda_00\n    \"\"\"  # noqa: E501\n    from nearai.environment import Environment\n\n    env = Environment(\"/\", [], CONFIG, create_files=False)\n    # Read from stdin (piped input)\n    lines = sys.stdin.readlines()\n    env.save_from_history(lines, name)\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.setup","title":"<code>setup(dataset, task_id)</code>","text":"<p>Setup environment with given task from the dataset.</p> Source code in <code>nearai/cli.py</code> <pre><code>def setup(self, dataset: str, task_id: int) -&gt; None:\n    \"\"\"Setup environment with given task from the dataset.\"\"\"\n    pass\n</code></pre>"},{"location":"api/#nearai.cli.EnvironmentCli.task","title":"<code>task(agents, task, path, max_iterations=10, record_run='true', load_env='')</code>","text":"<p>Runs agent non interactively with environment from given path.</p> Source code in <code>nearai/cli.py</code> <pre><code>def task(\n    self,\n    agents: str,\n    task: str,\n    path: str,\n    max_iterations: int = 10,\n    record_run: str = \"true\",\n    load_env: str = \"\",\n) -&gt; None:\n    \"\"\"Runs agent non interactively with environment from given path.\"\"\"\n    from nearai.environment import Environment\n\n    _agents = [load_agent(agent) for agent in agents.split(\",\")]\n    env = Environment(path, _agents, CONFIG)\n    env.run_task(task, record_run, load_env, max_iterations)\n</code></pre>"},{"location":"api/#nearai.cli.VllmCli","title":"<code>nearai.cli.VllmCli</code>","text":"Source code in <code>nearai/cli.py</code> <pre><code>class VllmCli:\n    def run(self, *args: Any, **kwargs: Any) -&gt; None:  # noqa: D102\n        original_argv = sys.argv.copy()\n        sys.argv = [\n            sys.argv[0],\n        ]\n        for key, value in kwargs.items():\n            sys.argv.extend([f\"--{key.replace('_', '-')}\", str(value)])\n        print(sys.argv)\n\n        try:\n            runpy.run_module(\"vllm.entrypoints.openai.api_server\", run_name=\"__main__\", alter_sys=True)\n        finally:\n            sys.argv = original_argv\n</code></pre>"},{"location":"api/#nearai.tensorboard_feed.TensorboardCli","title":"<code>nearai.tensorboard_feed.TensorboardCli</code>","text":"Source code in <code>nearai/tensorboard_feed.py</code> <pre><code>class TensorboardCli:\n    def start(self, logdir: str, limit: int = 100, timeout: int = 1) -&gt; None:  # noqa: D102\n        import tensorboardX\n\n        experiments: Dict[str, tensorboardX.SummaryWriter] = {}\n\n        logdir_path = Path(logdir)\n        logdir_path.mkdir(parents=True, exist_ok=True)\n        next_id_path = logdir_path / \".next_id\"\n\n        if not next_id_path.exists():\n            next_id_path.write_text(\"0\")\n\n        while True:\n            next_id = int(next_id_path.read_text())\n            result = get_logs(\"tensorboard\", next_id, limit)\n\n            if not result:\n                time.sleep(timeout)\n                continue\n\n            for row in result:\n                when = row.time.timestamp()\n                content = json.loads(row.content)\n\n                experiment_id = content.pop(\"experiment_id\", None)\n                step = content.pop(\"step\", None)\n\n                if experiment_id is None or step is None:\n                    continue\n\n                if experiment_id not in experiments:\n                    experiments[experiment_id] = tensorboardX.SummaryWriter(logdir_path / experiment_id)\n\n                writer = experiments[experiment_id]\n\n                for key, value in content.items():\n                    writer.add_scalar(key, value, step, walltime=when)\n\n                next_id = max(next_id, row.id + 1)\n\n            new_num_logs = len(result)\n            print(f\"Downloaded {new_num_logs} new logs\")\n            next_id_path.write_text(str(next_id))\n</code></pre>"},{"location":"api/#nearai.agent.Agent","title":"<code>nearai.agent.Agent</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/agent.py</code> <pre><code>class Agent(object):\n    def __init__(self, name: str, version: str, path: str, code: str):  # noqa: D107\n        self.name = name\n        self.version = version\n        self.path = path\n        self.code = code\n\n    @staticmethod\n    def from_disk(path: str) -&gt; \"Agent\":\n        \"\"\"Path must contain alias and version.\n\n        .../agents/&lt;alias&gt;/&lt;version&gt;/agent.py\n        \"\"\"\n        parts = path.split(\"/\")\n        with open(os.path.join(path, AGENT_FILENAME)) as f:\n            return Agent(parts[-2], parts[-1], path, f.read())\n\n    def run(self, env: Any, task: Optional[str] = None) -&gt; None:  # noqa: D102\n        d = {\"env\": env, \"agent\": self, \"task\": task}\n        exec(self.code, d, d)\n</code></pre>"},{"location":"api/#nearai.agent.Agent.from_disk","title":"<code>from_disk(path)</code>  <code>staticmethod</code>","text":"<p>Path must contain alias and version.</p> <p>.../agents///agent.py Source code in <code>nearai/agent.py</code> <pre><code>@staticmethod\ndef from_disk(path: str) -&gt; \"Agent\":\n    \"\"\"Path must contain alias and version.\n\n    .../agents/&lt;alias&gt;/&lt;version&gt;/agent.py\n    \"\"\"\n    parts = path.split(\"/\")\n    with open(os.path.join(path, AGENT_FILENAME)) as f:\n        return Agent(parts[-2], parts[-1], path, f.read())\n</code></pre>"},{"location":"api/#nearai.benchmark.DatasetInfo","title":"<code>nearai.benchmark.DatasetInfo</code>  <code>dataclass</code>","text":"Source code in <code>nearai/benchmark.py</code> <pre><code>@dataclass\nclass DatasetInfo:\n    name: str\n    subset: Optional[str]\n    dataset: Union[Dataset, DatasetDict]\n\n    def get_dataset(self) -&gt; Dataset:  # noqa: D102\n        if isinstance(self.dataset, DatasetDict):\n            assert self.subset is not None, f\"Subset must be: {', '.join(self.dataset.keys())}\"\n            return self.dataset[self.subset]\n        elif isinstance(self.dataset, Dataset):\n            return self.dataset\n        else:\n            raise ValueError(f\"Expected a Dataset or DatasetDict, got {type(self.dataset)}\")\n</code></pre>"},{"location":"api/#nearai.benchmark.BenchmarkExecutor","title":"<code>nearai.benchmark.BenchmarkExecutor</code>","text":"Source code in <code>nearai/benchmark.py</code> <pre><code>class BenchmarkExecutor:\n    def __init__(self, dataset_info: DatasetInfo, solver_strategy: SolverStrategy, benchmark_id: int):  # noqa: D107\n        self.dataset_info = dataset_info\n        self.solver_strategy = solver_strategy\n        self.benchmark_id = benchmark_id\n\n    def run(self, progress: bool = True, max_concurrent: int = 32) -&gt; None:  # noqa: D102\n        dataset = self.dataset_info.get_dataset()\n\n        # TODO(db-api): Fetch the cache from the API\n        # cache = db.get_benchmark_status(self.benchmark_id)\n        cache: Dict[int, bool] = {}\n\n        correct = 0\n        remaining = len(dataset)\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            task_ctor = partial(\n                solve_task, benchmark_id=self.benchmark_id, cache=cache, solve_fn=self.solver_strategy.solve\n            )\n            tasks = iter(executor.submit(task_ctor, index=index, datum=datum) for index, datum in enumerate(dataset))\n\n            total = len(dataset)\n            bar = tqdm(total=total, disable=not progress)\n            futures = list(islice(tasks, max_concurrent))\n            while futures:\n                completed, ongoing_futures = concurrent.futures.wait(\n                    futures, return_when=concurrent.futures.FIRST_COMPLETED\n                )\n                futures = list(ongoing_futures)\n                for completed_future in completed:\n                    bar.update(1)\n                    remaining -= 1\n\n                    result = completed_future.result()\n                    if result:\n                        correct += 1\n                    bar.set_description(\n                        f\"Correct/Seen - {correct}/{total - remaining} - {correct/(total - remaining):.2%}\"\n                    )\n\n                    try:\n                        next_task = next(tasks)\n                        futures.append(next_task)\n                    except StopIteration:\n                        continue\n\n        print(f\"Final score: {correct}/{total} - {correct/total:.2%}\")\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter","title":"<code>nearai.completion.InferenceRouter</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/completion.py</code> <pre><code>class InferenceRouter(object):\n    def __init__(self, config: Config) -&gt; None:  # noqa: D107\n        self._config = config\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n        self._endpoint: Any\n\n    def completions(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        stream: bool = False,\n        temperature: Optional[float] = None,\n        **kwargs: Any,\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Takes a model `provider:model_name` and a list of messages and returns all completions.\"\"\"\n        if self._config.nearai_hub is None:\n            raise ValueError(\"Missing NearAI Hub config\")\n        provider, model = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n        auth = self._config.auth\n        bearer_data = {\n            key: getattr(auth, key)\n            for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n        }\n        auth_bearer_token = json.dumps(bearer_data)\n\n        self._endpoint = lambda model, messages, stream, temperature, **kwargs: litellm_completion(\n            model,\n            messages,\n            stream=stream,\n            custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n            input_cost_per_token=0,\n            output_cost_per_token=0,\n            temperature=temperature,\n            base_url=self._config.nearai_hub.base_url,\n            provider=provider,\n            api_key=auth_bearer_token,\n            **kwargs,\n        )\n\n        result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n            model=model, messages=messages, stream=stream, temperature=temperature, **kwargs\n        )\n        return result\n</code></pre>"},{"location":"api/#nearai.completion.InferenceRouter.completions","title":"<code>completions(model, messages, stream=False, temperature=None, **kwargs)</code>","text":"<p>Takes a model <code>provider:model_name</code> and a list of messages and returns all completions.</p> Source code in <code>nearai/completion.py</code> <pre><code>def completions(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    stream: bool = False,\n    temperature: Optional[float] = None,\n    **kwargs: Any,\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Takes a model `provider:model_name` and a list of messages and returns all completions.\"\"\"\n    if self._config.nearai_hub is None:\n        raise ValueError(\"Missing NearAI Hub config\")\n    provider, model = get_provider_model(self._config.nearai_hub.default_provider, model)\n\n    auth = self._config.auth\n    bearer_data = {\n        key: getattr(auth, key)\n        for key in [\"account_id\", \"public_key\", \"signature\", \"callback_url\", \"message\", \"nonce\", \"recipient\"]\n    }\n    auth_bearer_token = json.dumps(bearer_data)\n\n    self._endpoint = lambda model, messages, stream, temperature, **kwargs: litellm_completion(\n        model,\n        messages,\n        stream=stream,\n        custom_llm_provider=self._config.nearai_hub.custom_llm_provider,\n        input_cost_per_token=0,\n        output_cost_per_token=0,\n        temperature=temperature,\n        base_url=self._config.nearai_hub.base_url,\n        provider=provider,\n        api_key=auth_bearer_token,\n        **kwargs,\n    )\n\n    result: Union[ModelResponse, CustomStreamWrapper] = self._endpoint(\n        model=model, messages=messages, stream=stream, temperature=temperature, **kwargs\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.tool_registry.ToolRegistry","title":"<code>nearai.tool_registry.ToolRegistry</code>","text":"Source code in <code>nearai/tool_registry.py</code> <pre><code>class ToolRegistry:\n    def __init__(self) -&gt; None:  # noqa: D107\n        self.tools: Dict[str, Callable] = {}\n\n    def register_tool(self, tool: Callable) -&gt; None:  # noqa: D102\n        self.tools[tool.__name__] = tool\n\n    def get_tool(self, name: str) -&gt; Optional[Callable]:  # noqa: D102\n        return self.tools.get(name)\n\n    def get_all_tools(self) -&gt; Dict[str, Callable]:  # noqa: D102\n        return self.tools\n\n    def call_tool(self, name: str, **kwargs: Any) -&gt; Any:  # noqa: D102\n        tool = self.get_tool(name)\n        if tool is None:\n            raise ValueError(f\"Tool '{name}' not found.\")\n        return tool(**kwargs)\n\n    def get_tool_definition(self, name: str) -&gt; Optional[Dict]:  # noqa: D102\n        tool = self.get_tool(name)\n        if tool is None:\n            return None\n\n        assert tool.__doc__ is not None, f\"Docstring missing for tool '{name}'.\"\n        docstring = tool.__doc__.strip().split(\"\\n\")\n\n        # The first line of the docstring is the function description\n        function_description = docstring[0].strip()\n\n        # The rest of the lines contain parameter descriptions\n        param_descriptions = docstring[1:]\n\n        # Extract parameter names and types\n        signature = inspect.signature(tool)\n        type_hints = get_type_hints(tool)\n\n        parameters: Dict[str, Any] = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n\n        # Iterate through function parameters\n        for param in signature.parameters.values():\n            param_name = param.name\n            param_type = type_hints.get(param_name, str)  # Default to str if type hint is missing\n            param_description = \"\"\n\n            # Find the parameter description in the docstring\n            for line in param_descriptions:\n                if line.strip().startswith(param_name):\n                    param_description = line.strip().split(\":\", 1)[1].strip()\n                    break\n\n            # Convert type hint to JSON Schema type\n            if isinstance(param_type, _GenericAlias) and param_type.__origin__ is Literal:\n                json_type = \"string\"\n            else:\n                json_type = param_type.__name__.lower()\n\n            json_type = {\"int\": \"integer\", \"float\": \"number\", \"str\": \"string\", \"bool\": \"boolean\"}.get(\n                json_type, json_type\n            )\n\n            # Add parameter to the definition\n            parameters[\"properties\"][param_name] = {\"description\": param_description, \"type\": json_type}\n\n            # Params without default values are required params\n            if param.default == inspect.Parameter.empty:\n                parameters[\"required\"].append(param_name)\n\n        return {\n            \"type\": \"function\",\n            \"function\": {\"name\": tool.__name__, \"description\": function_description, \"parameters\": parameters},\n        }\n\n    def get_all_tool_definitions(self) -&gt; list[Dict]:  # noqa: D102\n        definitions = []\n        for tool_name, _tool in self.tools.items():\n            definition = self.get_tool_definition(tool_name)\n            if definition is not None:\n                definitions.append(definition)\n        return definitions\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment","title":"<code>nearai.solvers.ddot_v0_solver.DDOTSEnvironment</code>","text":"<p>               Bases: <code>Environment</code></p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSEnvironment(Environment):\n    def __init__(self, agents: List[Agent], problem_id: str, description: str, config: Config):  # noqa: D107\n        self.tdir = TemporaryDirectory()\n        super().__init__(self.tdir.name, agents, config)\n\n        self.problem_id = problem_id\n        self.solved = False\n\n        files = {\n            \".id\": problem_id,\n            \"PROBLEM.txt\": description,\n            \"solution.py\": \"\",\n            \"test.in\": \"\",\n            \"test.sh\": \"#!/bin/bash\\npython3 solution.py &lt; test.in\",\n        }\n        for fname, content in files.items():\n            with open(self.tdir.name + \"/\" + fname, \"w\") as f:\n                f.write(content)\n\n    async def async_submit(self, code: str) -&gt; Tuple[bool, str]:  # noqa: D102\n        submission_id = await submit_problem(self.problem_id, code, Extensions.PYTHON)\n\n        try:\n            await is_output_ready(submission_id)\n        except Exception:\n            print(\"WARNING: Submission took too long to execute on DDOTS\")\n            self.mark_done()\n            return False, \"Submission took too long to execute on the platform\"\n\n        ok = await submission_accepted(submission_id)\n\n        if ok:\n            self.solved = True\n            self.mark_done()\n            return True, \"\"\n\n        output = await get_output(submission_id)\n\n        return False, output\n\n    def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n        \"\"\"Returns True if the submission was accepted, False otherwise.\n\n        The second element of the tuple is the output of the checker if the submission was rejected.\n        \"\"\"\n        return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSEnvironment.submit_python","title":"<code>submit_python(code)</code>","text":"<p>Returns True if the submission was accepted, False otherwise.</p> <p>The second element of the tuple is the output of the checker if the submission was rejected.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>def submit_python(self, code: str) -&gt; Tuple[bool, str]:\n    \"\"\"Returns True if the submission was accepted, False otherwise.\n\n    The second element of the tuple is the output of the checker if the submission was rejected.\n    \"\"\"\n    return asyncio.run(self.async_submit(code))\n</code></pre>"},{"location":"api/#nearai.solvers.ddot_v0_solver.DDOTSV0Solver","title":"<code>nearai.solvers.ddot_v0_solver.DDOTSV0Solver</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for competitive programming problems live on DDOTS.</p> <p>This dataset will run agents in an Agent environment previously prepared.</p> <p>workspace/     .id             -- Id of the problem     PROBLEM.txt     -- Description of the problem</p> <p>The agent should call env.submit_python(code) to submit the code to the DDOTS server.</p> Source code in <code>nearai/solvers/ddot_v0_solver.py</code> <pre><code>class DDOTSV0Solver(SolverStrategy):\n    \"\"\"Solver strategy for competitive programming problems live on DDOTS.\n\n    This dataset will run agents in an Agent environment previously prepared.\n\n    workspace/\n        .id             -- Id of the problem\n        PROBLEM.txt     -- Description of the problem\n\n    The agent should call env.submit_python(code) to submit the code to the DDOTS server.\n\n    \"\"\"\n\n    def __init__(self, dataset_ref: Dataset, agents: str, max_iterations: int, save_snapshots: bool = False):  # noqa: D107\n        self.agents = [load_agent(agent) for agent in agents.split(\",\")]\n        self.max_iterations = max_iterations\n\n        date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        rnd_id = random.randint(10**8, 10**9 - 1)\n        self._saved_trajectories = DATA_FOLDER / \"data\" / \"ddots_v0_trajectories\" / f\"{date}_{rnd_id}\"\n        self._saved_trajectories.mkdir(parents=True, exist_ok=True)\n\n        self.save_snapshots = save_snapshots\n        print(\"Saving trajectories to\", self._saved_trajectories)\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"ddots_codeforces_small/v0\", \"datasets/ddots_codeforces_medium_A_B/v0\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        problem_id = datum[\"problem_id\"]\n        description = datum[\"description\"]\n\n        config = deepcopy(CONFIG)\n        config.confirm_commands = False\n\n        env = DDOTSEnvironment(self.agents, problem_id, description, config)\n        env.write_file(\".solved\", str(False))\n\n        try:\n            env.run_task(description, max_iterations=self.max_iterations)\n            env.write_file(\".solved\", str(env.solved))\n\n        except Exception as e:\n            print(f\"Error running task: {e}\")\n\n        finally:\n            if self.save_snapshots:\n                snapshot = env.create_snapshot()\n                with open(self._saved_trajectories / f\"{problem_id}.tar.gz\", \"wb\") as f:\n                    f.write(snapshot)\n\n        return env.solved\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_agent_solver.MBPPSolverAgent","title":"<code>nearai.solvers.mbpp_agent_solver.MBPPSolverAgent</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_agent_solver.py</code> <pre><code>class MBPPSolverAgent(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    def __init__(  # noqa: D107\n        self, dataset_ref: Union[Dataset, DatasetDict], agent: str, num_iterations: int = 16, verbose: bool = False\n    ) -&gt; None:\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.agent = load_agent(agent)\n        self.verbose = verbose\n        self.num_iterations = num_iterations\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n        function_name = get_function_name(datum[\"code\"])\n\n        path = os.path.join(\n            \"/tmp\",\n            \"mbpp\",\n            str(datum[\"task_id\"]),\n            str(int(time.time() * 1000)),\n            str(random.randint(0, 1000)),\n        )\n        CONFIG.confirm_commands = False\n        env = Environment(path, [self.agent], CONFIG)\n\n        new_line = \"\\n\"\n        task = f\"\"\"{datum[\"text\"]}\nWrite a single file with python function named `{function_name}` that solves the above problem and satisfied the following tests:\n```python\\n{new_line.join(datum[\"test_list\"])}\\n```\"\"\"  # noqa: E501\n        if self.verbose:\n            print(task)\n            print(path)\n        env.run_task(task, max_iterations=self.num_iterations)\n\n        code = \"\"\n        for filename in env.list_files(\".\"):\n            if filename.endswith(\".py\"):\n                code += env.read_file(filename) + \"\\n\"\n\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code, {}, {})\n            return True\n        except Exception as e:\n            if self.verbose:\n                print(e)\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver.MBPPDatum","title":"<code>nearai.solvers.mbpp_solver.MBPPDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPDatum(BaseModel):\n    task_id: int\n    text: str\n    code: str\n    test_list: List[str]\n    challenge_test_list: List[str]\n</code></pre>"},{"location":"api/#nearai.solvers.mbpp_solver.MBPPSolverStrategy","title":"<code>nearai.solvers.mbpp_solver.MBPPSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MBPP dataset.</p> Source code in <code>nearai/solvers/mbpp_solver.py</code> <pre><code>class MBPPSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MBPP dataset.\"\"\"\n\n    SHOTS = 3\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mbpp\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MBPPDatum(**datum).model_dump()\n\n        ## Allow LLM to think \"out loud\" for it's answer\n        function_name = get_function_name(datum[\"code\"])\n        example_problems = list(islice(self.dataset_ref[\"prompt\"], self.SHOTS))\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mbpp_verbose_answer.j2\").read(), trim_blocks=True).render(\n            function_name=function_name,\n            example_problems=example_problems,\n            challenge_problem=datum,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mbpp_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            function_name=function_name,\n            answer_text=response,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Parse the python code\n        python_code_blocks = parse_python_code_block(response) + parse_code_block(response)\n        code = \"\"\n        if len(python_code_blocks) == 0:\n            code = response\n        else:\n            code = python_code_blocks[0]\n\n        ## Evaluate the code\n        try:\n            for test in datum[\"test_list\"] + datum[\"challenge_test_list\"]:\n                test_code = code + \"\\n\" + test\n                exec(test_code)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver.MMLUDatum","title":"<code>nearai.solvers.mmlu_solver.MMLUDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUDatum(BaseModel):\n    question: str\n    subject: str\n    choices: List[str]\n    answer: int\n</code></pre>"},{"location":"api/#nearai.solvers.mmlu_solver.MMLUSolverStrategy","title":"<code>nearai.solvers.mmlu_solver.MMLUSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/mmlu_solver.py</code> <pre><code>class MMLUSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"mmlu\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = MMLUDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: MMLUDatum(**d).model_dump(),\n                [self.dataset_ref[\"dev\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(open(PROMPTS_FOLDER / \"mmlu_verbose_answer.j2\").read(), trim_blocks=True).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.2,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"mmlu_extract_answer.j2\").read(), trim_blocks=True\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == datum[\"answer\"])\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagDatum","title":"<code>nearai.solvers.hellaswag_solver.HellaswagDatum</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagDatum(BaseModel):\n    activity_label: str\n    ctx: str\n    ctx_a: str\n    ctx_b: str\n    endings: List[str]\n    ind: int\n    label: str\n    source_id: str\n    split: str\n    split_type: str\n</code></pre>"},{"location":"api/#nearai.solvers.hellaswag_solver.HellaswagSolverStrategy","title":"<code>nearai.solvers.hellaswag_solver.HellaswagSolverStrategy</code>","text":"<p>               Bases: <code>SolverStrategy</code></p> <p>Solver strategy for the MMLU dataset.</p> Source code in <code>nearai/solvers/hellaswag_solver.py</code> <pre><code>class HellaswagSolverStrategy(SolverStrategy):\n    \"\"\"Solver strategy for the MMLU dataset.\"\"\"\n\n    SHOTS = 8\n\n    def __init__(self, dataset_ref: Union[Dataset, DatasetDict], model: str) -&gt; None:  # noqa: D107\n        super().__init__()\n        self.dataset_ref = dataset_ref\n        self.completion_fn = InferenceRouter(CONFIG).completions\n        self.model = model\n\n    def compatible_datasets(self) -&gt; List[str]:  # noqa: D102\n        return [\"hellaswag\"]\n\n    def solve(self, datum: dict) -&gt; bool:  # noqa: D102\n        datum = HellaswagDatum(**datum).model_dump()\n\n        choices = [\"A\", \"B\", \"C\", \"D\"]\n        example_problems_indices = list(range(0, 5 * self.SHOTS, 5))\n        example_problems = list(\n            map(\n                lambda d: HellaswagDatum(**d).model_dump(),\n                [self.dataset_ref[\"validation\"][i] for i in example_problems_indices],\n            )\n        )\n        base_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_verbose_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            example_problems=example_problems,\n            challenge_problem=datum,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": base_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        ## Extract the answer from the response\n        extract_answer_prompt = Template(\n            open(PROMPTS_FOLDER / \"hellaswag_extract_answer.j2\").read(),\n            trim_blocks=True,\n        ).render(\n            challenge_problem=datum,\n            answer_text=response,\n            choices=choices,\n        )\n        completion_response = cast(\n            ModelResponse,\n            self.completion_fn(\n                self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": extract_answer_prompt},\n                ],\n                temperature=0.0,\n            ),\n        )\n        response = str(cast(List[Choices], completion_response.choices)[0].message.content)\n\n        try:\n            answer = choices.index(response)\n            return bool(answer == int(datum[\"label\"]))\n        except Exception:\n            print(\"Failed to parse answer\")\n            return False\n</code></pre>"},{"location":"api/#nearai.registry.Registry","title":"<code>nearai.registry.Registry</code>","text":"Source code in <code>nearai/registry.py</code> <pre><code>class Registry:\n    def __init__(self):\n        \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n        self.download_folder = DATA_FOLDER / \"registry\"\n        self.api = RegistryApi()\n\n        if not self.download_folder.exists():\n            self.download_folder.mkdir(parents=True, exist_ok=True)\n\n    def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n        \"\"\"Update metadata of a entry in the registry.\"\"\"\n        result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n            BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n        )\n        return result\n\n    def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n        \"\"\"Get metadata of a entry in the registry.\"\"\"\n        try:\n            return self.api.download_metadata_v1_registry_download_metadata_post(\n                BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n            )\n        except NotFoundException:\n            return None\n\n    def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n        \"\"\"Upload a file to the registry.\"\"\"\n        with open(local_path, \"rb\") as file:\n            data = file.read()\n\n            try:\n                self.api.upload_file_v1_registry_upload_file_post(\n                    path=str(path),\n                    file=data,\n                    namespace=entry_location.namespace,\n                    name=entry_location.name,\n                    version=entry_location.version,\n                )\n                return True\n            except BadRequestException as e:\n                if isinstance(e.body, str) and \"already exists\" in e.body:\n                    return False\n\n                raise e\n\n    def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n        \"\"\"Download a file from the registry.\"\"\"\n        result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n            BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n                dict(\n                    entry_location=entry_location,\n                    path=str(path),\n                )\n            )\n        )\n\n        local_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(local_path, \"wb\") as f:\n            copyfileobj(result, f)\n\n    def download(\n        self, entry_location: Union[str, EntryLocation], force: bool = False, show_progress: bool = False\n    ) -&gt; Path:\n        \"\"\"Download entry from the registry locally.\"\"\"\n        if isinstance(entry_location, str):\n            entry_location = parse_location(entry_location)\n\n        download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n        if download_path.exists():\n            if not force:\n                print(f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\")\n                return download_path\n\n        files = registry.list_files(entry_location)\n\n        download_path.mkdir(parents=True, exist_ok=True)\n\n        metadata = registry.info(entry_location)\n\n        if metadata is None:\n            raise ValueError(f\"Entry {entry_location} not found.\")\n\n        metadata_path = download_path / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n        for file in (pbar := tqdm(files, disable=not show_progress)):\n            pbar.set_description(file)\n            registry.download_file(entry_location, file, download_path / file)\n\n        return download_path\n\n    def upload(\n        self,\n        local_path: Path,\n        metadata: Optional[EntryMetadata] = None,\n        show_progress: bool = False,\n    ) -&gt; EntryLocation:\n        \"\"\"Upload entry to the registry.\n\n        If metadata is provided it will overwrite the metadata in the directory,\n        otherwise it will use the metadata.json found on the root of the directory.\n        \"\"\"\n        path = Path(local_path).absolute()\n\n        if CONFIG.auth is None:\n            print(\"Please login with `nearai login`\")\n            exit(1)\n\n        metadata_path = path / \"metadata.json\"\n\n        if metadata is not None:\n            with open(metadata_path, \"w\") as f:\n                f.write(metadata.model_dump_json(indent=2))\n\n        _check_metadata(metadata_path)\n\n        with open(metadata_path) as f:\n            plain_metadata: Dict[str, Any] = json.load(f)\n\n        namespace = CONFIG.auth.account_id\n\n        entry_location = EntryLocation.model_validate(\n            dict(\n                namespace=namespace,\n                name=plain_metadata.pop(\"name\"),\n                version=plain_metadata.pop(\"version\"),\n            )\n        )\n\n        entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n        registry.update(entry_location, entry_metadata)\n\n        all_files = []\n        total_size = 0\n\n        # Traverse all files in the directory `path`\n        for file in path.rglob(\"*\"):\n            if not file.is_file():\n                continue\n\n            relative = file.relative_to(path)\n\n            # Don't upload metadata file.\n            if file == metadata_path:\n                continue\n\n            # Don't upload backup files.\n            if file.name.endswith(\"~\"):\n                continue\n\n            # Don't upload configuration files.\n            if relative.parts[0] == \".nearai\":\n                continue\n\n            size = file.stat().st_size\n            total_size += size\n\n            all_files.append((file, relative, size))\n\n        pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n        for file, relative, size in all_files:\n            registry.upload_file(entry_location, file, relative)\n            pbar.update(size)\n\n        return entry_location\n\n    def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n        \"\"\"List files in from an entry in the registry.\n\n        Return the relative paths to all files with respect to the root of the entry.\n        \"\"\"\n        return self.api.list_files_v1_registry_list_files_post(\n            BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n        )\n\n    def list(\n        self,\n        category: str,\n        tags: str,\n        total: int,\n        show_hidden: bool,\n    ) -&gt; List[EntryLocation]:\n        \"\"\"List and filter entries in the registry.\"\"\"\n        return self.api.list_entries_v1_registry_list_entries_post(\n            category=category,\n            tags=tags,\n            total=total,\n            show_hidden=show_hidden,\n        )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.__init__","title":"<code>__init__()</code>","text":"<p>Create Registry object to interact with the registry programmatically.</p> Source code in <code>nearai/registry.py</code> <pre><code>def __init__(self):\n    \"\"\"Create Registry object to interact with the registry programmatically.\"\"\"\n    self.download_folder = DATA_FOLDER / \"registry\"\n    self.api = RegistryApi()\n\n    if not self.download_folder.exists():\n        self.download_folder.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download","title":"<code>download(entry_location, force=False, show_progress=False)</code>","text":"<p>Download entry from the registry locally.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download(\n    self, entry_location: Union[str, EntryLocation], force: bool = False, show_progress: bool = False\n) -&gt; Path:\n    \"\"\"Download entry from the registry locally.\"\"\"\n    if isinstance(entry_location, str):\n        entry_location = parse_location(entry_location)\n\n    download_path = get_registry_folder() / entry_location.namespace / entry_location.name / entry_location.version\n\n    if download_path.exists():\n        if not force:\n            print(f\"Entry {entry_location} already exists at {download_path}. Use --force to overwrite the entry.\")\n            return download_path\n\n    files = registry.list_files(entry_location)\n\n    download_path.mkdir(parents=True, exist_ok=True)\n\n    metadata = registry.info(entry_location)\n\n    if metadata is None:\n        raise ValueError(f\"Entry {entry_location} not found.\")\n\n    metadata_path = download_path / \"metadata.json\"\n    with open(metadata_path, \"w\") as f:\n        f.write(metadata.model_dump_json(indent=2))\n\n    for file in (pbar := tqdm(files, disable=not show_progress)):\n        pbar.set_description(file)\n        registry.download_file(entry_location, file, download_path / file)\n\n    return download_path\n</code></pre>"},{"location":"api/#nearai.registry.Registry.download_file","title":"<code>download_file(entry_location, path, local_path)</code>","text":"<p>Download a file from the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def download_file(self, entry_location: EntryLocation, path: Path, local_path: Path):\n    \"\"\"Download a file from the registry.\"\"\"\n    result = self.api.download_file_v1_registry_download_file_post_without_preload_content(\n        BodyDownloadFileV1RegistryDownloadFilePost.from_dict(\n            dict(\n                entry_location=entry_location,\n                path=str(path),\n            )\n        )\n    )\n\n    local_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(local_path, \"wb\") as f:\n        copyfileobj(result, f)\n</code></pre>"},{"location":"api/#nearai.registry.Registry.info","title":"<code>info(entry_location)</code>","text":"<p>Get metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def info(self, entry_location: EntryLocation) -&gt; Optional[EntryMetadata]:\n    \"\"\"Get metadata of a entry in the registry.\"\"\"\n    try:\n        return self.api.download_metadata_v1_registry_download_metadata_post(\n            BodyDownloadMetadataV1RegistryDownloadMetadataPost.from_dict(dict(entry_location=entry_location))\n        )\n    except NotFoundException:\n        return None\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list","title":"<code>list(category, tags, total, show_hidden)</code>","text":"<p>List and filter entries in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list(\n    self,\n    category: str,\n    tags: str,\n    total: int,\n    show_hidden: bool,\n) -&gt; List[EntryLocation]:\n    \"\"\"List and filter entries in the registry.\"\"\"\n    return self.api.list_entries_v1_registry_list_entries_post(\n        category=category,\n        tags=tags,\n        total=total,\n        show_hidden=show_hidden,\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.list_files","title":"<code>list_files(entry_location)</code>","text":"<p>List files in from an entry in the registry.</p> <p>Return the relative paths to all files with respect to the root of the entry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def list_files(self, entry_location: EntryLocation) -&gt; List[str]:\n    \"\"\"List files in from an entry in the registry.\n\n    Return the relative paths to all files with respect to the root of the entry.\n    \"\"\"\n    return self.api.list_files_v1_registry_list_files_post(\n        BodyListFilesV1RegistryListFilesPost.from_dict(dict(entry_location=entry_location))\n    )\n</code></pre>"},{"location":"api/#nearai.registry.Registry.update","title":"<code>update(entry_location, metadata)</code>","text":"<p>Update metadata of a entry in the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def update(self, entry_location: EntryLocation, metadata: EntryMetadataInput) -&gt; Dict[str, Any]:\n    \"\"\"Update metadata of a entry in the registry.\"\"\"\n    result = self.api.upload_metadata_v1_registry_upload_metadata_post(\n        BodyUploadMetadataV1RegistryUploadMetadataPost(metadata=metadata, entry_location=entry_location)\n    )\n    return result\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload","title":"<code>upload(local_path, metadata=None, show_progress=False)</code>","text":"<p>Upload entry to the registry.</p> <p>If metadata is provided it will overwrite the metadata in the directory, otherwise it will use the metadata.json found on the root of the directory.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload(\n    self,\n    local_path: Path,\n    metadata: Optional[EntryMetadata] = None,\n    show_progress: bool = False,\n) -&gt; EntryLocation:\n    \"\"\"Upload entry to the registry.\n\n    If metadata is provided it will overwrite the metadata in the directory,\n    otherwise it will use the metadata.json found on the root of the directory.\n    \"\"\"\n    path = Path(local_path).absolute()\n\n    if CONFIG.auth is None:\n        print(\"Please login with `nearai login`\")\n        exit(1)\n\n    metadata_path = path / \"metadata.json\"\n\n    if metadata is not None:\n        with open(metadata_path, \"w\") as f:\n            f.write(metadata.model_dump_json(indent=2))\n\n    _check_metadata(metadata_path)\n\n    with open(metadata_path) as f:\n        plain_metadata: Dict[str, Any] = json.load(f)\n\n    namespace = CONFIG.auth.account_id\n\n    entry_location = EntryLocation.model_validate(\n        dict(\n            namespace=namespace,\n            name=plain_metadata.pop(\"name\"),\n            version=plain_metadata.pop(\"version\"),\n        )\n    )\n\n    entry_metadata = EntryMetadataInput.model_validate(plain_metadata)\n    registry.update(entry_location, entry_metadata)\n\n    all_files = []\n    total_size = 0\n\n    # Traverse all files in the directory `path`\n    for file in path.rglob(\"*\"):\n        if not file.is_file():\n            continue\n\n        relative = file.relative_to(path)\n\n        # Don't upload metadata file.\n        if file == metadata_path:\n            continue\n\n        # Don't upload backup files.\n        if file.name.endswith(\"~\"):\n            continue\n\n        # Don't upload configuration files.\n        if relative.parts[0] == \".nearai\":\n            continue\n\n        size = file.stat().st_size\n        total_size += size\n\n        all_files.append((file, relative, size))\n\n    pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, disable=not show_progress)\n    for file, relative, size in all_files:\n        registry.upload_file(entry_location, file, relative)\n        pbar.update(size)\n\n    return entry_location\n</code></pre>"},{"location":"api/#nearai.registry.Registry.upload_file","title":"<code>upload_file(entry_location, local_path, path)</code>","text":"<p>Upload a file to the registry.</p> Source code in <code>nearai/registry.py</code> <pre><code>def upload_file(self, entry_location: EntryLocation, local_path: Path, path: Path) -&gt; bool:\n    \"\"\"Upload a file to the registry.\"\"\"\n    with open(local_path, \"rb\") as file:\n        data = file.read()\n\n        try:\n            self.api.upload_file_v1_registry_upload_file_post(\n                path=str(path),\n                file=data,\n                namespace=entry_location.namespace,\n                name=entry_location.name,\n                version=entry_location.version,\n            )\n            return True\n        except BadRequestException as e:\n            if isinstance(e.body, str) and \"already exists\" in e.body:\n                return False\n\n            raise e\n</code></pre>"},{"location":"api/#nearai.environment.Environment","title":"<code>nearai.environment.Environment</code>","text":"<p>               Bases: <code>object</code></p> Source code in <code>nearai/environment.py</code> <pre><code>class Environment(object):\n    def __init__(  # noqa: D107\n        self, path: str, agents: List[Agent], config: Config, create_files: bool = True\n    ) -&gt; None:\n        self._path = path\n        self._agents = agents\n        self._done = False\n        self._config = config\n        self._inference = InferenceRouter(config)\n        self._user_name = config.user_name\n        self._tools = ToolRegistry()\n        self.register_standard_tools()\n\n        if self._config.nearai_hub is None:\n            self._config.nearai_hub = NearAiHubConfig()\n\n        if create_files:\n            os.makedirs(self._path, exist_ok=True)\n            open(os.path.join(self._path, CHAT_FILENAME), \"a\").close()\n        os.chdir(self._path)\n\n    @staticmethod\n    def _generate_run_id() -&gt; str:\n        return uuid.uuid4().hex\n\n    def get_tool_registry(self) -&gt; ToolRegistry:  # noqa: D102\n        return self._tools\n\n    def register_standard_tools(self) -&gt; None:  # noqa: D102\n        reg = self.get_tool_registry()\n        reg.register_tool(self.exec_command)\n        reg.register_tool(self.read_file)\n        reg.register_tool(self.write_file)\n        reg.register_tool(self.request_user_input)\n        reg.register_tool(self.list_files)\n\n    def add_message(self, role: str, message: str, filename: str = CHAT_FILENAME, **kwargs: Any) -&gt; None:  # noqa: D102\n        with open(os.path.join(self._path, filename), \"a\") as f:\n            f.write(json.dumps({\"role\": role, \"content\": message, **kwargs}) + DELIMITER)\n\n    def list_terminal_commands(self, filename: str = TERMINAL_FILENAME) -&gt; List[Any]:  # noqa: D102\n        return self.list_messages(filename)\n\n    def list_messages(self, filename: str = CHAT_FILENAME) -&gt; List[Any]:  # noqa: D102\n        path = os.path.join(self._path, filename)\n\n        if not os.path.exists(path):\n            return []\n\n        with open(path, \"r\") as f:\n            return [json.loads(message) for message in f.read().split(DELIMITER) if message]\n\n    def list_files(self, path: str) -&gt; List[str]:\n        \"\"\"Lists files in the environment.\n\n        path: The path to list files from.\n        \"\"\"\n        return os.listdir(os.path.join(self._path, path))\n\n    def get_path(self) -&gt; str:  # noqa: D102\n        return self._path\n\n    def read_file(self, filename: str) -&gt; str:\n        \"\"\"Read a file from the environment.\n\n        filename: The name of the file to read.\n        \"\"\"\n        if not os.path.exists(os.path.join(self._path, filename)):\n            return \"\"\n        try:\n            with open(os.path.join(self._path, filename), \"r\") as f:\n                return f.read()\n        except Exception as e:\n            return f\"failed to read file: {e}\"\n\n    def write_file(self, filename: str, content: str) -&gt; str:\n        \"\"\"Writes a file to the environment.\n\n        filename: The name of the file to write to\n        content: The content to write to the file.\n        \"\"\"\n        path = Path(self._path) / filename\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with open(path, \"w\") as f:\n            f.write(content)\n        return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n\n    def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"Executes a command in the environment and logs the output.\n\n        The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n        command: The command to execute, like 'ls -l' or 'python3 tests.py'\n        \"\"\"  # noqa: E501\n        if self._config.get(\"confirm_commands\", True):\n            yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n            if yes_no != \"\" and yes_no.lower() != \"y\":\n                return {\n                    \"command\": command,\n                    \"returncode\": 999,\n                    \"stdout\": \"\",\n                    \"stderr\": \"declined by user\",\n                }\n\n        try:\n            process = subprocess.Popen(\n                shlex.split(command),\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                bufsize=0,\n                universal_newlines=True,\n                cwd=self._path,\n            )\n        except Exception as e:\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"Failed to execute: \" + str(e),\n            }\n\n        msg = \"\"\n\n        def kill_process_tree(p: Any) -&gt; None:\n            nonlocal msg\n            msg = \"Killing process due to timeout\"\n\n            process = psutil.Process(p.pid)\n            for proc in process.children(recursive=True):\n                proc.kill()\n            process.kill()\n\n        timer = threading.Timer(2, kill_process_tree, (process,))\n        timer.start()\n        process.wait()\n        timer.cancel()\n\n        result = {\n            \"command\": command,\n            \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n            \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n            \"returncode\": process.returncode,\n            \"msg\": msg,\n        }\n        with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n            f.write(json.dumps(result) + DELIMITER)\n        return result\n\n    def completions(\n        self, model: str, messages: Iterable[ChatCompletionMessageParam], stream: bool = False, **kwargs: Any\n    ) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n        \"\"\"Returns all completions for given messages using the given model.\"\"\"\n        return self._inference.completions(model, messages, stream=stream, **kwargs)\n\n    def completions_and_run_tools(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; ModelResponse:\n        \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n        raw_response = self._inference.completions(model, messages, stream=False, tools=tools, **kwargs)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message\n        if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n            for tool_call in response_message.tool_calls:\n                function_name = tool_call.function.name\n                assert function_name, \"Tool call must have a function name\"\n                function_args = json.loads(tool_call.function.arguments)\n                function_response = self._tools.call_tool(function_name, **function_args)\n\n                if function_response:\n                    function_response_json = json.dumps(function_response) if function_response else \"\"\n                    self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n        return response\n\n    def completion(self, model: str, messages: Iterable[ChatCompletionMessageParam]) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n        raw_response = self.completions(model, messages)\n        assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n        response: ModelResponse = raw_response\n        assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n        choices: List[Choices] = response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def completion_and_run_tools(\n        self,\n        model: str,\n        messages: Iterable[ChatCompletionMessageParam],\n        tools: Optional[List] = None,\n        **kwargs: Any,\n    ) -&gt; str:\n        \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n        completion_tools_response = self.completions_and_run_tools(model, messages, tools, **kwargs)\n        assert all(\n            map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n        ), \"Expected Choices\"\n        choices: List[Choices] = completion_tools_response.choices  # type: ignore\n        response_message = choices[0].message.content\n        assert response_message, \"No completions returned\"\n        return response_message\n\n    def call_agent(self, agent_path: int, task: str) -&gt; None:\n        \"\"\"Calls agent with given task.\"\"\"\n        self._agents[agent_path].run(self, task=task)\n\n    def get_agents(self) -&gt; List[Agent]:\n        \"\"\"Returns list of agents available in environment.\"\"\"\n        return self._agents\n\n    def is_done(self) -&gt; bool:  # noqa: D102\n        return self._done\n\n    def mark_done(self) -&gt; None:  # noqa: D102\n        self._done = True\n\n    def create_snapshot(self) -&gt; bytes:\n        \"\"\"Create an in memory snapshot.\"\"\"\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(self._path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n        return snapshot\n\n    def save_to_registry(\n        self,\n        path: str,\n        run_type: str,\n        run_id: str,\n        base_id: Optional[Union[str, int]] = None,\n        run_name: Optional[str] = None,\n    ) -&gt; Optional[bytes]:\n        \"\"\"Save Environment to Registry.\"\"\"\n        author = self._user_name\n        if not author:\n            print(\n                \"Warning: No author specified in config. Run not saved to registry.\"\n                \" To set an author run `nearai config set user_name &lt;YOUR_NAME&gt;`\"\n            )\n            return None\n\n        agent_name = self._agents[0].name if self._agents else \"unknown\"\n        generated_name = f\"environment_run_{agent_name}_{run_id}\"\n        name = run_name or generated_name\n\n        tempdir = Path(tempfile.mkdtemp())\n\n        with open(tempdir / \"environment.tar.gz\", \"r+b\") as f:\n            with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n                tar.add(path, arcname=\".\")\n            f.flush()\n            f.seek(0)\n            snapshot = f.read()\n            tar_filename = f.name\n\n            timestamp = datetime.now(timezone.utc).isoformat()\n\n            entry_location = registry.upload(\n                tempdir,\n                EntryMetadata.from_dict(\n                    {\n                        \"name\": name,\n                        \"version\": \"0.0.1\",\n                        \"description\": f\"Agent {run_type} run {agent_name}\",\n                        \"category\": \"environment\",\n                        \"tags\": [\"environment\"],\n                        \"details\": {\n                            \"base_id\": base_id,\n                            \"timestamp\": timestamp,\n                            \"agents\": [agent.name for agent in self._agents],\n                            \"run_id\": run_id,\n                            \"run_type\": run_type,\n                            \"filename\": tar_filename,\n                        },\n                        \"show_entry\": True,\n                    }\n                ),\n                show_progress=True,\n            )\n\n            location_str = plain_location(entry_location)\n\n            print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n        rmtree(tempdir)\n\n        return snapshot\n\n    def load_snapshot(self, snapshot: bytes) -&gt; None:\n        \"\"\"Load Environment from Snapshot.\"\"\"\n        shutil.rmtree(self._path, ignore_errors=True)\n\n        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n            f.write(snapshot)\n            f.flush()\n            f.seek(0)\n\n            with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n                tar.extractall(self._path)\n\n    def load_from_registry(self, load_env: str) -&gt; str:  # noqa: D102\n        print(f\"Loading environment from {load_env} to {self._path}\")\n\n        directory = registry.download(load_env)\n        assert directory is not None, \"Failed to download environment\"\n\n        files = os.listdir(directory)\n        tarfile_file = next(f for f in files if f.endswith(\".tar.gz\"))\n\n        with tarfile.open(directory / tarfile_file, \"r\") as tar:\n            tar.extractall(self._path)\n        return directory.name\n\n    def __str__(self) -&gt; str:  # noqa: D105\n        return f\"Environment({self._path})\"\n\n    def run_agent(self, task: Optional[str]) -&gt; None:  # noqa: D102\n        self._agents[0].run(self, task=task)\n\n    def request_user_input(self) -&gt; None:\n        \"\"\"Must be called to request input from the user.\"\"\"\n        self.set_next_actor(\"user\")\n\n    def set_next_actor(self, who: str) -&gt; None:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        with open(next_action_fn, \"w\") as f:\n            f.write(who)\n\n    def get_next_actor(self) -&gt; str:  # noqa: D102\n        next_action_fn = os.path.join(self._path, \".next_action\")\n\n        if os.path.exists(next_action_fn):\n            with open(next_action_fn) as f:\n                return f.read().strip(\" \\n\")\n        else:\n            # By default the user starts the conversation.\n            return \"user\"\n\n    def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n        \"\"\"Run an interactive session within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        last_message_idx = 0\n\n        def print_messages(last_message_idx: int) -&gt; int:\n            messages = self.list_messages()\n            for item in messages[last_message_idx:]:\n                print(f\"[{item['role']}]: {item['content']}\", flush=True)\n            return len(messages)\n\n        last_message_idx = print_messages(last_message_idx)\n\n        iteration_count = 0\n        while True:\n            if self.get_next_actor() != \"user\":\n                messages = self.list_messages()\n                new_message = None if not messages else messages[-1][\"content\"]\n\n                iteration_count += 1\n                self.run_agent(new_message)\n\n                last_message_idx = print_messages(last_message_idx)\n                if self.is_done():\n                    break\n\n            else:\n                new_message = input(\"&gt; \")\n                if new_message == \"exit\":\n                    break\n                self.add_message(\"user\", new_message)\n\n                self.set_next_actor(\"agent\")\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n\n    def run_task(\n        self,\n        task: str,\n        record_run: str = \"\",\n        load_env: str = \"\",\n        max_iterations: int = 10,\n    ) -&gt; None:\n        \"\"\"Runs a task within the given environment.\"\"\"\n        run_id = self._generate_run_id()\n        if load_env:\n            base_id = self.load_from_registry(load_env)\n        else:\n            base_id = None\n        iteration = 0\n\n        if task:\n            self.add_message(\"user\", task)\n\n        while iteration &lt; max_iterations and not self.is_done():\n            iteration += 1\n            self._agents[0].run(self, task=task)\n\n        if record_run:\n            run_name = record_run if record_run and record_run != \"true\" else None\n            self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n\n    def inspect(self) -&gt; None:  # noqa: D102\n        filename = Path(os.path.abspath(__file__)).parent / \"streamlit_inspect.py\"\n        subprocess.call([\"streamlit\", \"run\", filename, \"--\", self._path])\n\n    def contains_non_empty_chat_txt(self, directory: str) -&gt; bool:  # noqa: D102\n        chat_txt_path = os.path.join(directory, \"chat.txt\")\n        return os.path.isfile(chat_txt_path) and os.path.getsize(chat_txt_path) &gt; 0\n\n    def save_folder(self, name: Optional[str] = None) -&gt; None:  # noqa: D102\n        path = self._path\n        temp_dir = None\n\n        def copy_relevant_folders(src: str, dest: str) -&gt; None:\n            for item in os.listdir(src):\n                s = os.path.join(src, item)\n                d = os.path.join(dest, item)\n                if os.path.isdir(s):\n                    if self.contains_non_empty_chat_txt(s):\n                        shutil.copytree(s, d)\n                    else:\n                        os.makedirs(d, exist_ok=True)\n                        copy_relevant_folders(s, d)\n                        if not os.listdir(d):\n                            os.rmdir(d)\n\n        if not self.contains_non_empty_chat_txt(path):\n            temp_dir = tempfile.mkdtemp()\n            copy_relevant_folders(path, temp_dir)\n            path = temp_dir\n\n        try:\n            if not os.listdir(path):\n                raise ValueError(f\"No files found in {path}\")\n\n            self.save_to_registry(\n                path, \"folders\" if temp_dir else \"folder\", self.generate_folder_hash_id(path), None, name\n            )\n        finally:\n            if temp_dir:\n                shutil.rmtree(temp_dir)\n\n    def save_from_history(self, lines: List[str], name: Optional[str] = None) -&gt; None:  # noqa: D102\n        # Parse lines and extract relevant information\n        pattern = r\"^\\s*(?:\\d+\\s+)?(\\S+)\\s+environment\\s+interactive\\s+(\\S+)\\s+(\\S+)(.*?)$\"\n        relevant_paths = {}\n        for line in lines:\n            match = re.match(pattern, line)\n            if match:\n                program_name, agents, path, other_args = match.groups()\n                path = path.strip(\"/\")\n                if self.contains_non_empty_chat_txt(path):\n                    command = f\"{program_name} environment interactive {agents} {path} {other_args}\"\n                    relevant_paths[path] = {\"command\": command.strip()}\n\n        if not relevant_paths:\n            raise ValueError(\"No relevant paths with non-empty chat.txt files found in history\")\n\n        for path, info in relevant_paths.items():\n            print(path)\n            # Write start_command.log\n            with open(os.path.join(path, \"start_command.log\"), \"w\") as f:\n                f.write(info[\"command\"])\n\n        # Create temporary directory and copy relevant folders\n        temp_dir = tempfile.mkdtemp()\n        try:\n            for path, _info in relevant_paths.items():\n                dest = os.path.join(temp_dir, path.replace(\"/\", \"_\").strip(\"_\"))\n                shutil.copytree(path, dest)\n            self.save_to_registry(temp_dir, \"folders\", self.generate_folder_hash_id(temp_dir), None, name)\n\n        finally:\n            shutil.rmtree(temp_dir)\n\n    def generate_folder_hash_id(self, path: str) -&gt; str:\n        \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n        hash_obj = hashlib.md5()\n\n        for root, _dirs, files in os.walk(path):\n            for file in sorted(files):\n                file_path = os.path.join(root, file)\n                with open(file_path, \"rb\") as f:\n                    while chunk := f.read(8192):\n                        hash_obj.update(chunk)\n\n        return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.call_agent","title":"<code>call_agent(agent_path, task)</code>","text":"<p>Calls agent with given task.</p> Source code in <code>nearai/environment.py</code> <pre><code>def call_agent(self, agent_path: int, task: str) -&gt; None:\n    \"\"\"Calls agent with given task.\"\"\"\n    self._agents[agent_path].run(self, task=task)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion","title":"<code>completion(model, messages)</code>","text":"<p>Returns a completion for the given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion(self, model: str, messages: Iterable[ChatCompletionMessageParam]) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model.\"\"\"\n    raw_response = self.completions(model, messages)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completion_and_run_tools","title":"<code>completion_and_run_tools(model, messages, tools=None, **kwargs)</code>","text":"<p>Returns a completion for the given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completion_and_run_tools(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; str:\n    \"\"\"Returns a completion for the given messages using the given model and runs tools.\"\"\"\n    completion_tools_response = self.completions_and_run_tools(model, messages, tools, **kwargs)\n    assert all(\n        map(lambda choice: isinstance(choice, Choices), completion_tools_response.choices)\n    ), \"Expected Choices\"\n    choices: List[Choices] = completion_tools_response.choices  # type: ignore\n    response_message = choices[0].message.content\n    assert response_message, \"No completions returned\"\n    return response_message\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions","title":"<code>completions(model, messages, stream=False, **kwargs)</code>","text":"<p>Returns all completions for given messages using the given model.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions(\n    self, model: str, messages: Iterable[ChatCompletionMessageParam], stream: bool = False, **kwargs: Any\n) -&gt; Union[ModelResponse, CustomStreamWrapper]:\n    \"\"\"Returns all completions for given messages using the given model.\"\"\"\n    return self._inference.completions(model, messages, stream=stream, **kwargs)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.completions_and_run_tools","title":"<code>completions_and_run_tools(model, messages, tools=None, **kwargs)</code>","text":"<p>Returns all completions for given messages using the given model and runs tools.</p> Source code in <code>nearai/environment.py</code> <pre><code>def completions_and_run_tools(\n    self,\n    model: str,\n    messages: Iterable[ChatCompletionMessageParam],\n    tools: Optional[List] = None,\n    **kwargs: Any,\n) -&gt; ModelResponse:\n    \"\"\"Returns all completions for given messages using the given model and runs tools.\"\"\"\n    raw_response = self._inference.completions(model, messages, stream=False, tools=tools, **kwargs)\n    assert isinstance(raw_response, ModelResponse), \"Expected ModelResponse\"\n    response: ModelResponse = raw_response\n    assert all(map(lambda choice: isinstance(choice, Choices), response.choices)), \"Expected Choices\"\n    choices: List[Choices] = response.choices  # type: ignore\n    response_message = choices[0].message\n    if hasattr(response_message, \"tool_calls\") and response_message.tool_calls:\n        for tool_call in response_message.tool_calls:\n            function_name = tool_call.function.name\n            assert function_name, \"Tool call must have a function name\"\n            function_args = json.loads(tool_call.function.arguments)\n            function_response = self._tools.call_tool(function_name, **function_args)\n\n            if function_response:\n                function_response_json = json.dumps(function_response) if function_response else \"\"\n                self.add_message(\"tool\", function_response_json, tool_call_id=tool_call.id, name=function_name)\n    return response\n</code></pre>"},{"location":"api/#nearai.environment.Environment.create_snapshot","title":"<code>create_snapshot()</code>","text":"<p>Create an in memory snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def create_snapshot(self) -&gt; bytes:\n    \"\"\"Create an in memory snapshot.\"\"\"\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(self._path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.environment.Environment.exec_command","title":"<code>exec_command(command)</code>","text":"<p>Executes a command in the environment and logs the output.</p> <p>The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input. command: The command to execute, like 'ls -l' or 'python3 tests.py'</p> Source code in <code>nearai/environment.py</code> <pre><code>def exec_command(self, command: str) -&gt; Dict[str, Union[str, int]]:\n    \"\"\"Executes a command in the environment and logs the output.\n\n    The environment does not allow running interactive programs. It will run a program for 1 second then will interrupt it if it is still running or if it is waiting for user input.\n    command: The command to execute, like 'ls -l' or 'python3 tests.py'\n    \"\"\"  # noqa: E501\n    if self._config.get(\"confirm_commands\", True):\n        yes_no = input(\"&gt; Do you want to run the following command? (Y/n): \" + command)\n        if yes_no != \"\" and yes_no.lower() != \"y\":\n            return {\n                \"command\": command,\n                \"returncode\": 999,\n                \"stdout\": \"\",\n                \"stderr\": \"declined by user\",\n            }\n\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            bufsize=0,\n            universal_newlines=True,\n            cwd=self._path,\n        )\n    except Exception as e:\n        return {\n            \"command\": command,\n            \"returncode\": 999,\n            \"stdout\": \"\",\n            \"stderr\": \"Failed to execute: \" + str(e),\n        }\n\n    msg = \"\"\n\n    def kill_process_tree(p: Any) -&gt; None:\n        nonlocal msg\n        msg = \"Killing process due to timeout\"\n\n        process = psutil.Process(p.pid)\n        for proc in process.children(recursive=True):\n            proc.kill()\n        process.kill()\n\n    timer = threading.Timer(2, kill_process_tree, (process,))\n    timer.start()\n    process.wait()\n    timer.cancel()\n\n    result = {\n        \"command\": command,\n        \"stdout\": process.stdout.read() if process.stdout and hasattr(process.stdout, \"read\") else \"\",\n        \"stderr\": process.stderr.read() if process.stderr and hasattr(process.stderr, \"read\") else \"\",\n        \"returncode\": process.returncode,\n        \"msg\": msg,\n    }\n    with open(os.path.join(self._path, TERMINAL_FILENAME), \"a\") as f:\n        f.write(json.dumps(result) + DELIMITER)\n    return result\n</code></pre>"},{"location":"api/#nearai.environment.Environment.generate_folder_hash_id","title":"<code>generate_folder_hash_id(path)</code>","text":"<p>Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.</p> Source code in <code>nearai/environment.py</code> <pre><code>def generate_folder_hash_id(self, path: str) -&gt; str:\n    \"\"\"Returns id similar to _generate_run_id(), but based on files and their contents in path, including subfolders.\"\"\"  # noqa: E501\n    hash_obj = hashlib.md5()\n\n    for root, _dirs, files in os.walk(path):\n        for file in sorted(files):\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                while chunk := f.read(8192):\n                    hash_obj.update(chunk)\n\n    return hash_obj.hexdigest()\n</code></pre>"},{"location":"api/#nearai.environment.Environment.get_agents","title":"<code>get_agents()</code>","text":"<p>Returns list of agents available in environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def get_agents(self) -&gt; List[Agent]:\n    \"\"\"Returns list of agents available in environment.\"\"\"\n    return self._agents\n</code></pre>"},{"location":"api/#nearai.environment.Environment.list_files","title":"<code>list_files(path)</code>","text":"<p>Lists files in the environment.</p> <p>path: The path to list files from.</p> Source code in <code>nearai/environment.py</code> <pre><code>def list_files(self, path: str) -&gt; List[str]:\n    \"\"\"Lists files in the environment.\n\n    path: The path to list files from.\n    \"\"\"\n    return os.listdir(os.path.join(self._path, path))\n</code></pre>"},{"location":"api/#nearai.environment.Environment.load_snapshot","title":"<code>load_snapshot(snapshot)</code>","text":"<p>Load Environment from Snapshot.</p> Source code in <code>nearai/environment.py</code> <pre><code>def load_snapshot(self, snapshot: bytes) -&gt; None:\n    \"\"\"Load Environment from Snapshot.\"\"\"\n    shutil.rmtree(self._path, ignore_errors=True)\n\n    with tempfile.NamedTemporaryFile(suffix=\".tar.gz\") as f:\n        f.write(snapshot)\n        f.flush()\n        f.seek(0)\n\n        with tarfile.open(fileobj=f, mode=\"r:gz\") as tar:\n            tar.extractall(self._path)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.read_file","title":"<code>read_file(filename)</code>","text":"<p>Read a file from the environment.</p> <p>filename: The name of the file to read.</p> Source code in <code>nearai/environment.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n    \"\"\"Read a file from the environment.\n\n    filename: The name of the file to read.\n    \"\"\"\n    if not os.path.exists(os.path.join(self._path, filename)):\n        return \"\"\n    try:\n        with open(os.path.join(self._path, filename), \"r\") as f:\n            return f.read()\n    except Exception as e:\n        return f\"failed to read file: {e}\"\n</code></pre>"},{"location":"api/#nearai.environment.Environment.request_user_input","title":"<code>request_user_input()</code>","text":"<p>Must be called to request input from the user.</p> Source code in <code>nearai/environment.py</code> <pre><code>def request_user_input(self) -&gt; None:\n    \"\"\"Must be called to request input from the user.\"\"\"\n    self.set_next_actor(\"user\")\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_interactive","title":"<code>run_interactive(record_run='', load_env='')</code>","text":"<p>Run an interactive session within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_interactive(self, record_run: str = \"\", load_env: str = \"\") -&gt; None:\n    \"\"\"Run an interactive session within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    last_message_idx = 0\n\n    def print_messages(last_message_idx: int) -&gt; int:\n        messages = self.list_messages()\n        for item in messages[last_message_idx:]:\n            print(f\"[{item['role']}]: {item['content']}\", flush=True)\n        return len(messages)\n\n    last_message_idx = print_messages(last_message_idx)\n\n    iteration_count = 0\n    while True:\n        if self.get_next_actor() != \"user\":\n            messages = self.list_messages()\n            new_message = None if not messages else messages[-1][\"content\"]\n\n            iteration_count += 1\n            self.run_agent(new_message)\n\n            last_message_idx = print_messages(last_message_idx)\n            if self.is_done():\n                break\n\n        else:\n            new_message = input(\"&gt; \")\n            if new_message == \"exit\":\n                break\n            self.add_message(\"user\", new_message)\n\n            self.set_next_actor(\"agent\")\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"interactive\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.run_task","title":"<code>run_task(task, record_run='', load_env='', max_iterations=10)</code>","text":"<p>Runs a task within the given environment.</p> Source code in <code>nearai/environment.py</code> <pre><code>def run_task(\n    self,\n    task: str,\n    record_run: str = \"\",\n    load_env: str = \"\",\n    max_iterations: int = 10,\n) -&gt; None:\n    \"\"\"Runs a task within the given environment.\"\"\"\n    run_id = self._generate_run_id()\n    if load_env:\n        base_id = self.load_from_registry(load_env)\n    else:\n        base_id = None\n    iteration = 0\n\n    if task:\n        self.add_message(\"user\", task)\n\n    while iteration &lt; max_iterations and not self.is_done():\n        iteration += 1\n        self._agents[0].run(self, task=task)\n\n    if record_run:\n        run_name = record_run if record_run and record_run != \"true\" else None\n        self.save_to_registry(self._path, \"task\", run_id, base_id, run_name)\n</code></pre>"},{"location":"api/#nearai.environment.Environment.save_to_registry","title":"<code>save_to_registry(path, run_type, run_id, base_id=None, run_name=None)</code>","text":"<p>Save Environment to Registry.</p> Source code in <code>nearai/environment.py</code> <pre><code>def save_to_registry(\n    self,\n    path: str,\n    run_type: str,\n    run_id: str,\n    base_id: Optional[Union[str, int]] = None,\n    run_name: Optional[str] = None,\n) -&gt; Optional[bytes]:\n    \"\"\"Save Environment to Registry.\"\"\"\n    author = self._user_name\n    if not author:\n        print(\n            \"Warning: No author specified in config. Run not saved to registry.\"\n            \" To set an author run `nearai config set user_name &lt;YOUR_NAME&gt;`\"\n        )\n        return None\n\n    agent_name = self._agents[0].name if self._agents else \"unknown\"\n    generated_name = f\"environment_run_{agent_name}_{run_id}\"\n    name = run_name or generated_name\n\n    tempdir = Path(tempfile.mkdtemp())\n\n    with open(tempdir / \"environment.tar.gz\", \"r+b\") as f:\n        with tarfile.open(fileobj=f, mode=\"w:gz\") as tar:\n            tar.add(path, arcname=\".\")\n        f.flush()\n        f.seek(0)\n        snapshot = f.read()\n        tar_filename = f.name\n\n        timestamp = datetime.now(timezone.utc).isoformat()\n\n        entry_location = registry.upload(\n            tempdir,\n            EntryMetadata.from_dict(\n                {\n                    \"name\": name,\n                    \"version\": \"0.0.1\",\n                    \"description\": f\"Agent {run_type} run {agent_name}\",\n                    \"category\": \"environment\",\n                    \"tags\": [\"environment\"],\n                    \"details\": {\n                        \"base_id\": base_id,\n                        \"timestamp\": timestamp,\n                        \"agents\": [agent.name for agent in self._agents],\n                        \"run_id\": run_id,\n                        \"run_type\": run_type,\n                        \"filename\": tar_filename,\n                    },\n                    \"show_entry\": True,\n                }\n            ),\n            show_progress=True,\n        )\n\n        location_str = plain_location(entry_location)\n\n        print(f\"Saved environment {entry_location} to registry. To load use flag `--load-env={location_str}`.\")\n\n    rmtree(tempdir)\n\n    return snapshot\n</code></pre>"},{"location":"api/#nearai.environment.Environment.write_file","title":"<code>write_file(filename, content)</code>","text":"<p>Writes a file to the environment.</p> <p>filename: The name of the file to write to content: The content to write to the file.</p> Source code in <code>nearai/environment.py</code> <pre><code>def write_file(self, filename: str, content: str) -&gt; str:\n    \"\"\"Writes a file to the environment.\n\n    filename: The name of the file to write to\n    content: The content to write to the file.\n    \"\"\"\n    path = Path(self._path) / filename\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with open(path, \"w\") as f:\n        f.write(content)\n    return f\"Successfully wrote {len(content) if content else 0} characters to {filename}\"\n</code></pre>"},{"location":"api/#nearai.config.Config","title":"<code>nearai.config.Config</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>nearai/config.py</code> <pre><code>class Config(BaseModel):\n    origin: Optional[str] = None\n    user_name: Optional[str] = None\n    user_email: Optional[str] = None\n    api_url: Optional[str] = \"https://api.near.ai\"\n    inference_url: str = \"http://localhost:5000/v1/\"\n    inference_api_key: str = \"n/a\"\n    nearai_hub: Optional[NearAiHubConfig] = NearAiHubConfig()\n    confirm_commands: bool = True\n    auth: Optional[AuthData] = None\n\n    def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n        \"\"\"Update the config with the given dictionary.\"\"\"\n        dict_repr = self.model_dump()\n        keys = list(map(map_key, dict_repr.keys()))\n\n        for key in keys:\n            value = extra_config.get(key, None)\n\n            if value:\n                # This will skip empty values, even if they are set in the `extra_config`\n                dict_repr[key] = value\n\n        return Config.model_validate(dict_repr)\n\n    def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n        \"\"\"Get the value of a key in the config if it exists.\"\"\"\n        return getattr(self, key, default)\n\n    def get_user_name(self) -&gt; str:\n        \"\"\"Get the user name from the config.\n\n        Prompt the user to set the user name if it is not set.\n        \"\"\"\n        if self.user_name is None:\n            print(\"Please set user_name with `nearai config set user_name &lt;name&gt;`\")\n            exit(1)\n        return self.user_name\n</code></pre>"},{"location":"api/#nearai.config.Config.get","title":"<code>get(key, default=None)</code>","text":"<p>Get the value of a key in the config if it exists.</p> Source code in <code>nearai/config.py</code> <pre><code>def get(self, key: str, default: Optional[Any] = None) -&gt; Optional[Any]:\n    \"\"\"Get the value of a key in the config if it exists.\"\"\"\n    return getattr(self, key, default)\n</code></pre>"},{"location":"api/#nearai.config.Config.get_user_name","title":"<code>get_user_name()</code>","text":"<p>Get the user name from the config.</p> <p>Prompt the user to set the user name if it is not set.</p> Source code in <code>nearai/config.py</code> <pre><code>def get_user_name(self) -&gt; str:\n    \"\"\"Get the user name from the config.\n\n    Prompt the user to set the user name if it is not set.\n    \"\"\"\n    if self.user_name is None:\n        print(\"Please set user_name with `nearai config set user_name &lt;name&gt;`\")\n        exit(1)\n    return self.user_name\n</code></pre>"},{"location":"api/#nearai.config.Config.update_with","title":"<code>update_with(extra_config, map_key=lambda x: x)</code>","text":"<p>Update the config with the given dictionary.</p> Source code in <code>nearai/config.py</code> <pre><code>def update_with(self, extra_config: Dict[str, Any], map_key: Callable[[str], str] = lambda x: x) -&gt; \"Config\":\n    \"\"\"Update the config with the given dictionary.\"\"\"\n    dict_repr = self.model_dump()\n    keys = list(map(map_key, dict_repr.keys()))\n\n    for key in keys:\n        value = extra_config.get(key, None)\n\n        if value:\n            # This will skip empty values, even if they are set in the `extra_config`\n            dict_repr[key] = value\n\n    return Config.model_validate(dict_repr)\n</code></pre>"},{"location":"contributing/","title":"Contribute to <code>nearai</code>","text":"<p>Everyone is welcome to contribute, and we value everybody's contribution. Code contributions are not the only way to help the community. Answering questions, helping others, and improving documentation are also immensely valuable.</p> <p>It also helps us if you spread the word! Reference the library in blog posts about the awesome projects it made possible, or even simply \u2b50\ufe0f the repository to say thank you.</p> <p>This guide was heavily inspired by the huggingface transformers guide to contributing.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to contribute","text":"<p>There are several ways you can contribute to <code>nearai</code>:</p> <ul> <li>Fix outstanding issues with the existing code.</li> <li>Submit issues related to bugs or desired new features.</li> <li>Implement new features (including but not limited to solvers, agents, or benchmarks).</li> <li>Contribute to the examples or to the documentation.</li> </ul>"},{"location":"contributing/#fixing-outstanding-issues","title":"Fixing outstanding issues","text":"<p>If you notice an issue with the existing code and have a fix in mind, feel free to start contributing and open a Pull Request!</p>"},{"location":"contributing/#submitting-a-bug-related-issue-or-feature-request","title":"Submitting a bug-related issue or feature request","text":"<p>Do your best to follow these guidelines when submitting a bug-related issue or a feature request. It will make it easier for us to come back to you quickly and with good feedback.</p>"},{"location":"contributing/#did-you-find-a-bug","title":"Did you find a bug?","text":"<p><code>nearai</code> is alpha software. This means there is a possibility of encountering issues in the code. With help from users like you who report problems, we can make it more robust and reliable.</p> <p>Before you report an issue, we would really appreciate it if you could make sure the bug was not already reported (use the search bar on GitHub under Issues). Your issue should also be related to bugs in the library itself, and not your code.</p> <p>Once you've confirmed the bug hasn't already been reported, please include the following information in your issue so we can quickly resolve it:</p> <ul> <li>What did you do?</li> <li>What did you expect to happen?</li> <li>What happened instead?</li> <li>Your OS type and version and Python, PyTorch and versions where applicable.</li> <li>A short, self-contained, code snippet that allows us to reproduce the bug in   less than 30s.</li> <li>The full traceback if an exception is raised.</li> <li>Attach any other additional information, like screenshots, you think may help.</li> </ul> <p>To get the OS and software versions automatically, run the following command:</p> <pre><code>uname -a\n</code></pre>"},{"location":"contributing/#do-you-want-a-new-feature","title":"Do you want a new feature?","text":"<p>If there is a new feature you'd like to see in <code>nearai</code>, please open an issue and describe:</p> <ol> <li>What is the motivation behind this feature? Is it related to a problem or frustration with the library? Is it a feature related to something you need for a project? Is it something you worked on and think it could benefit the community?</li> </ol> <p>Whatever it is, we'd love to hear about it!</p> <ol> <li>Describe your requested feature in as much detail as possible. The more you can tell us about it, the better we'll be able to help you.</li> <li>Provide a code snippet that demonstrates the feature usage.</li> <li>If the feature is related to a paper, please include a link.</li> </ol>"},{"location":"contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Before writing any code, we strongly advise you to search through the existing PRs or issues to make sure nobody is already working on the same thing. If you are unsure, it is always a good idea to open an issue to get some feedback.</p> <p>You will need basic <code>git</code> proficiency to contribute to <code>nearai</code>. While <code>git</code> is not the easiest tool to use, it has the greatest manual. Type <code>git --help</code> in a shell and enjoy! If you prefer books, Pro Git is a very good reference. We also recommend asking any available AGI to help you with <code>git</code>.</p> <p>Follow the steps below to start contributing:</p> <ol> <li> <p>Fork the repository by    clicking on the Fork button on the repository's page. This creates a copy of the code    under your GitHub user account.</p> </li> <li> <p>Clone your fork to your local disk, and add the base repository as a remote:</p> </li> </ol> <pre><code>git clone git@github.com:&lt;your Github handle&gt;/nearai.git\ncd nearai\ngit remote add upstream https://github.com/nearai/nearai.git\n</code></pre> <ol> <li>Create a new branch to hold your development changes:</li> </ol> <pre><code>git checkout -b a-descriptive-name-for-my-changes\n</code></pre> <p>\ud83d\udea8 Do not work on the <code>main</code> branch!</p> <ol> <li> <p>Set up a development environment (follow steps in the README):</p> </li> <li> <p>Develop the features in your branch.</p> </li> </ol> <p>As you work on your code, you should make sure it functions as intended.</p> <p><code>nearai</code> relies on <code>ruff</code> and <code>mypy</code> to format and type check its source code    consistently. After you make your changes and are ready to PR them, ensure that    your code is formatted and type-checked by running:</p> <pre><code>./scripts/lint_format.sh\n</code></pre> <pre><code>./scripts/typecheck.sh\n</code></pre> <p>Once you're happy with your changes, add the changed files with <code>git add</code> and    record your changes locally with <code>git commit</code>:</p> <pre><code>git add modified_file.py\ngit commit\n</code></pre> <p>Please remember to write good commit    messages to clearly communicate the changes you made!</p> <p>To keep your copy of the code up to date with the original    repository, rebase your branch on <code>upstream/branch</code> before you open a pull request or if requested by a maintainer:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> <p>Push your changes to your branch:</p> <pre><code>git push -u origin a-descriptive-name-for-my-changes\n</code></pre> <p>If you've already opened a pull request, you'll need to force push with the <code>--force</code> flag. Otherwise, if the pull request hasn't been opened yet, you can just push your changes normally.</p> <ol> <li> <p>Now you can go to your fork of the repository on GitHub and click on Pull Request to open a pull request. Make sure you tick off all the boxes on our checklist below. When you're ready, you can send your changes to the project maintainers for review.</p> </li> <li> <p>It's ok if maintainers request changes, it happens to our core contributors    too! So everyone can see the changes in the pull request, work in your local    branch and push the changes to your fork. They will automatically appear in    the pull request.</p> </li> </ol>"},{"location":"contributing/#pull-request-checklist","title":"Pull request checklist","text":"<ul> <li>The pull request title should summarize your contribution.</li> <li>If your pull request addresses an issue, please mention the issue number in the pull request description to make sure they are linked (and people viewing the issue know you are working on it).</li> <li>To indicate a work in progress please prefix the title with <code>[WIP]</code>. These are useful to avoid duplicated work, and to differentiate it from PRs ready to be merged.</li> <li>Don't add any images, videos and other non-text files that'll significantly weigh down the repository. Instead, reference them by URL.</li> </ul>"},{"location":"contributing/#sync-a-forked-repository-with-upstream-main","title":"Sync a forked repository with upstream main","text":"<p>When updating the main branch of a forked repository, please follow these steps to avoid pinging the upstream repository which adds reference notes to each upstream PR, and sends unnecessary notifications to the developers involved in these PRs.</p> <ol> <li>When possible, avoid syncing with the upstream using a branch and PR on the forked repository. Instead, merge directly into the forked main.</li> <li>If a PR is absolutely necessary, use the following steps after checking out your branch:</li> </ol> <pre><code>git checkout -b your-branch-for-syncing\ngit pull --squash --no-commit upstream main\ngit commit -m '&lt;your message without GitHub references&gt;'\ngit push --set-upstream origin your-branch-for-syncing\n</code></pre>"}]}