services:
  nearai_base:
    image: nearai_base:latest
    build:
      context: ..
      dockerfile: .docker/Dockerfile.nearai_base

  scheduler:
    build:
      context: ..
      dockerfile: .docker/Dockerfile.scheduler
    container_name: scheduler
    networks:
      - internal_network
      - default
    environment:
      - WORKER_PORT=8000

  worker:
    build:
      context: ..
      dockerfile: .docker/Dockerfile.worker
    container_name: worker
    networks:
      - internal_network
    user: "1000:1000"
    ports:
      - "8000:8000"
    environment:
      - WORKER_PORT=8000
    volumes:
      - restricted-volume:/mnt/
    # read_only: true
    security_opt:
      - no-new-privileges:true
      - seccomp:unconfined
    cap_drop:
      - ALL
    restart: "no"
    privileged: false
    tty: false
    platform: linux/amd64
    shm_size: '2gb'
    deploy:
      resources:
        limits:
          cpus: "0.50"
          memory: "128M"
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

volumes:
  restricted-volume:
    driver: local
    driver_opts:
      type: tmpfs # Use tmpfs to create an in-memory volume
      device: tmpfs
      o: "size=100m" # Limit volume size to 100MB

networks:
  internal_network:
    internal: true
  default:
    external: false
